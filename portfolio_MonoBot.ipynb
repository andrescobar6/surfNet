{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2167d27",
   "metadata": {},
   "source": [
    "# LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97d5b9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import math\n",
    "import ccxt\n",
    "import time\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import configparser\n",
    "import pandas as pd\n",
    "import google.cloud\n",
    "from pandas_gbq import gbq\n",
    "import matplotlib.cm as cm\n",
    "from boruta import BorutaPy\n",
    "import statsmodels.api as sm\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from google.cloud import bigquery\n",
    "from sklearn import preprocessing\n",
    "from requests import Request, Session\n",
    "from IPython.display import clear_output\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from requests.exceptions import ConnectionError, Timeout, TooManyRedirects\n",
    "\n",
    "#_____\n",
    "\n",
    "pd.set_option('display.max_rows', 5000)\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b458185f",
   "metadata": {},
   "source": [
    "# FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dc1ac43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCIÓN QUE LEE EL ARCHIVO CONFIG\n",
    "def get_config(category, key):\n",
    "    \n",
    "    global config\n",
    "    return config[category][key]\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE GENERA CONEXIÓN CON ARCHIVO CONFIG\n",
    "def updateConfig(config_name):\n",
    "    \n",
    "    global config\n",
    "    \n",
    "    config = configparser.ConfigParser()\n",
    "    config.sections()\n",
    "    config.read(config_name)\n",
    "    \n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE GRAFICA POR COLORES SEGUN COMPRAS Y NO COMRPAS\n",
    "def plot_colourline(x,y,c):\n",
    "    c = c\n",
    "    ax = plt.gca()\n",
    "    for i in np.arange(len(x)-1):\n",
    "        ax.plot([x[i],x[i+1]], [y[i],y[i+1]], c=c[i])\n",
    "    return\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE ESCRIBE PICKLE DE VARIABLE\n",
    "def writePickleVariable(variable,variable_name):\n",
    "    pickle_out = open(variable_name+\".pickle\",\"wb\")\n",
    "    pickle.dump(variable, pickle_out)\n",
    "    pickle_out.close()\n",
    "    \n",
    "#_____\n",
    "    \n",
    "#FUNCIÓN QUE LEE PICKLE DE VARIABLE\n",
    "def readPickleVariable(variable_name):    \n",
    "    return pickle.load(open(variable_name+\".pickle\",\"rb\"))\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE REDONDEA FLOAT HACIA ABAJO SEGÚN DECIMALES\n",
    "def round_decimals_down(number:float, decimals:int=2):\n",
    "    \"\"\"\n",
    "    Returns a value rounded down to a specific number of decimal places.\n",
    "    \"\"\"\n",
    "    if not isinstance(decimals, int):\n",
    "        raise TypeError(\"decimal places must be an integer\")\n",
    "    elif decimals < 0:\n",
    "        raise ValueError(\"decimal places has to be 0 or more\")\n",
    "    elif decimals == 0:\n",
    "        return math.floor(number)\n",
    "\n",
    "    factor = 10 ** decimals\n",
    "    return math.floor(number * factor) / factor\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE REDONDEA FLOAT HACIA ARRIBA SEGÚN DECIMALES\n",
    "def round_decimals_up(number:float, decimals:int=2):\n",
    "    \"\"\"\n",
    "    Returns a value rounded down to a specific number of decimal places.\n",
    "    \"\"\"\n",
    "    if not isinstance(decimals, int):\n",
    "        raise TypeError(\"decimal places must be an integer\")\n",
    "    elif decimals < 0:\n",
    "        raise ValueError(\"decimal places has to be 0 or more\")\n",
    "    elif decimals == 0:\n",
    "        return math.ceil(number)\n",
    "\n",
    "    factor = 10 ** decimals\n",
    "    return math.ceil(number * factor) / factor\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE DESCARGA BASE DE DATOS DE MERCADO DE BIGQUERY\n",
    "def downloadDataBaseBigQuery(market_model,rows=None):\n",
    "    \n",
    "    #_____GOOGLE CLOUD CONECTION\n",
    "    os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"/home/ubuntu/SurfNet/predictionModels/bigQueryAccess.json\"\n",
    "\n",
    "    #_____SI NO SE DA UN NÚMERO ESPECÍFICO DE FILAS POR PARÁMETRO\n",
    "    if rows==None:\n",
    "    \n",
    "        #_____DESCARGAR BASE DE DATOS\n",
    "        candlesDataBase_BigQuery=gbq.read_gbq(\"SELECT * FROM [dogwood-terra-308100:surfNet.\"+market_model.replace(\"/\",\"_\")+\"] ORDER BY TIME DESC\",project_id=\"dogwood-terra-308100\",dialect=\"legacy\").sort_values(by=\"TIME\")\n",
    "        candlesDataBase_BigQuery.reset_index(inplace=True,drop=True)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        #_____DESCARGAR BASE DE DATOS\n",
    "        candlesDataBase_BigQuery=gbq.read_gbq(\"SELECT * FROM [dogwood-terra-308100:surfNet.\"+market_model.replace(\"/\",\"_\")+\"] ORDER BY TIME DESC LIMIT \"+str(rows),project_id=\"dogwood-terra-308100\",dialect=\"legacy\").sort_values(by=\"TIME\")\n",
    "        candlesDataBase_BigQuery.reset_index(inplace=True,drop=True)\n",
    "\n",
    "    candlesDataBase_BigQuery.OPEN=candlesDataBase_BigQuery.OPEN.astype(float)\n",
    "    candlesDataBase_BigQuery.HIGH=candlesDataBase_BigQuery.HIGH.astype(float)\n",
    "    candlesDataBase_BigQuery.LOW=candlesDataBase_BigQuery.LOW.astype(float)\n",
    "    candlesDataBase_BigQuery.CLOSE=candlesDataBase_BigQuery.CLOSE.astype(float)\n",
    "    candlesDataBase_BigQuery.VOLUME=candlesDataBase_BigQuery.VOLUME.astype(float)\n",
    "    \n",
    "    #_____REESTRUCTURAR BASE DE DATOS\n",
    "    candlesDataBase_BigQuery.reset_index(inplace=True,drop=True)\n",
    "    \n",
    "    #_____RETURN\n",
    "    return candlesDataBase_BigQuery\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE DEVUELVE EL RSI DADO UN PERIODO DETERMINADO\n",
    "def RSI(candlesDataBase_BigQuery):\n",
    "    \n",
    "    global config\n",
    "    updateConfig(\"/home/ubuntu/SurfNet/predictionModels/PREDICTION/predictionModels.ini\")\n",
    "    \n",
    "    series=pd.Series(list(candlesDataBase_BigQuery.CLOSE.values))\n",
    "    period=int(get_config(\"PARAMETERS\",\"RSI_LEN\"))\n",
    "    \n",
    "    delta = series.diff().dropna()\n",
    "    u = delta * 0\n",
    "    d = u.copy()\n",
    "    u[delta > 0] = delta[delta > 0]\n",
    "    d[delta < 0] = -delta[delta < 0]\n",
    "    u[u.index[period-1]] = np.mean( u[:period] ) #first value is sum of avg gains\n",
    "    u = u.drop(u.index[:(period-1)])\n",
    "    d[d.index[period-1]] = np.mean( d[:period] ) #first value is sum of avg losses\n",
    "    d = d.drop(d.index[:(period-1)])\n",
    "    rs = pd.DataFrame.ewm(u, com=period-1, adjust=False).mean() / \\\n",
    "         pd.DataFrame.ewm(d, com=period-1, adjust=False).mean()\n",
    "    \n",
    "    rsi=100 - 100 / (1 + rs)\n",
    "    \n",
    "    for i in list(rsi.index.values):\n",
    "        candlesDataBase_BigQuery.at[i,\"RSI\"]=rsi[i]\n",
    "                                        \n",
    "    return candlesDataBase_BigQuery\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE CALCULA MACD\n",
    "def MACD(candlesDataBase_BigQuery):\n",
    "    \n",
    "    global config\n",
    "    updateConfig(\"/home/ubuntu/SurfNet/predictionModels/PREDICTION/predictionModels.ini\")\n",
    "    \n",
    "    close_data_df=candlesDataBase_BigQuery.copy()\n",
    "    close_data_df.CLOSE=close_data_df.CLOSE.astype(float)\n",
    "    close_data_df=close_data_df[[\"CLOSE\"]]\n",
    "    \n",
    "    #_____CREAR VARIABLE MACD\n",
    "    macd_12 = close_data_df.ewm(span=int(get_config(\"PARAMETERS\",\"MACD_SHORT\")), adjust=False).mean()\n",
    "    macd_26 = close_data_df.ewm(span=int(get_config(\"PARAMETERS\",\"MACD_LONG\")), adjust=False).mean()\n",
    "    macd = macd_12 - macd_26\n",
    "    macd_9 = macd.ewm(span=int(get_config(\"PARAMETERS\",\"MACD_TRIGGER\")), adjust=False).mean()\n",
    "\n",
    "    #_____AGREGAR VARIABLES A LA BASE DE DATOS\n",
    "    candlesDataBase_BigQuery[\"MACD\"]=macd\n",
    "    candlesDataBase_BigQuery[\"MACD_\"+get_config(\"PARAMETERS\",\"MACD_SHORT\")]=macd_12\n",
    "    candlesDataBase_BigQuery[\"MACD_\"+get_config(\"PARAMETERS\",\"MACD_LONG\")]=macd_26\n",
    "    candlesDataBase_BigQuery[\"MACD_TRIGGER\"]=macd_9\n",
    "    \n",
    "    return candlesDataBase_BigQuery\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCIÓN SUPERTREND\n",
    "def superTrend(df, atr_period, multiplier):\n",
    "    \n",
    "    high = df['HIGH']\n",
    "    low = df['LOW']\n",
    "    close = df['CLOSE']\n",
    "    \n",
    "    # calculate ATR\n",
    "    price_diffs = [high - low, \n",
    "                   high - close.shift(), \n",
    "                   close.shift() - low]\n",
    "    true_range = pd.concat(price_diffs, axis=1)\n",
    "    true_range = true_range.abs().max(axis=1)\n",
    "    # default ATR calculation in supertrend indicator\n",
    "    atr = true_range.ewm(alpha=1/atr_period,min_periods=atr_period).mean() \n",
    "    # df['atr'] = df['tr'].rolling(atr_period).mean()\n",
    "    \n",
    "    # HL2 is simply the average of high and low prices\n",
    "    hl2 = (high + low) / 2\n",
    "    # upperband and lowerband calculation\n",
    "    # notice that final bands are set to be equal to the respective bands\n",
    "    final_upperband = upperband = hl2 + (multiplier * atr)\n",
    "    final_lowerband = lowerband = hl2 - (multiplier * atr)\n",
    "    \n",
    "    # initialize Supertrend column to True\n",
    "    supertrend = [True] * len(df)\n",
    "    \n",
    "    for i in range(1, len(df.index)):\n",
    "        curr, prev = i, i-1\n",
    "        \n",
    "        # if current close price crosses above upperband\n",
    "        if close[curr] > final_upperband[prev]:\n",
    "            supertrend[curr] = True\n",
    "        # if current close price crosses below lowerband\n",
    "        elif close[curr] < final_lowerband[prev]:\n",
    "            supertrend[curr] = False\n",
    "        # else, the trend continues\n",
    "        else:\n",
    "            supertrend[curr] = supertrend[prev]\n",
    "            \n",
    "            # adjustment to the final bands\n",
    "            if supertrend[curr] == True and final_lowerband[curr] < final_lowerband[prev]:\n",
    "                final_lowerband[curr] = final_lowerband[prev]\n",
    "            if supertrend[curr] == False and final_upperband[curr] > final_upperband[prev]:\n",
    "                final_upperband[curr] = final_upperband[prev]\n",
    "\n",
    "        # to remove bands according to the trend direction\n",
    "        if supertrend[curr] == True:\n",
    "            final_upperband[curr] = np.nan\n",
    "        else:\n",
    "            final_lowerband[curr] = np.nan\n",
    "    \n",
    "    #return pd.DataFrame({\n",
    "    #    'Supertrend': supertrend,\n",
    "    #    'Final Lowerband': final_lowerband,\n",
    "    #    'Final Upperband': final_upperband\n",
    "    #}, index=df.index)\n",
    "\n",
    "    df[\"SUPERTREND\"]=supertrend\n",
    "\n",
    "    return df\n",
    "\n",
    "#_____\n",
    "\n",
    "#CREATE VARIABLES\n",
    "def variableCreation(candlesDataBase_BigQuery):\n",
    "    \n",
    "    global fractal\n",
    "    updateConfig(\"/home/ubuntu/SurfNet/predictionModels/PREDICTION/predictionModels.ini\")\n",
    "    \n",
    "    candlesDataBase_BigQuery=RSI(candlesDataBase_BigQuery)\n",
    "#     candlesDataBase_BigQuery=MACD(candlesDataBase_BigQuery)\n",
    "#     candlesDataBase_BigQuery=fibonacciLevels(candlesDataBase_BigQuery)\n",
    "#     candlesDataBase_BigQuery=newVariables(candlesDataBase_BigQuery)\n",
    "#     candlesDataBase_BigQuery=superTrend(candlesDataBase_BigQuery, int(get_config(\"PARAMETERS\",\"ATR_PERIOD\")), int(get_config(\"PARAMETERS\",\"ATR_MULTIP\")))\n",
    "#     candlesDataBase_BigQuery=suaviPlusDerivates(candlesDataBase_BigQuery)\n",
    "#     candlesDataBase_BigQuery=LAGS(candlesDataBase_BigQuery)\n",
    "    \n",
    "    candlesDataBase_BigQuery.dropna(inplace=True)\n",
    "    candlesDataBase_BigQuery.reset_index(inplace=True,drop=True)\n",
    "    \n",
    "    return candlesDataBase_BigQuery\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE ESCALA LAS VARIABLES CONTINUAS DE LA BASE DE DATOS\n",
    "def scaleVariables(candlesDataBase_BigQuery):\n",
    "    \n",
    "    #_____ESCALAR VARIABLES\n",
    "    continuous_variables=list(candlesDataBase_BigQuery.columns)[3:-1]\n",
    "\n",
    "    scaler=preprocessing.StandardScaler(with_mean=True).fit(np.array(candlesDataBase_BigQuery[continuous_variables]))\n",
    "    scaled_data=pd.DataFrame(scaler.transform(candlesDataBase_BigQuery[continuous_variables]))\n",
    "    scaled_data.columns=continuous_variables\n",
    "\n",
    "    for var in continuous_variables:\n",
    "        candlesDataBase_BigQuery[str(var)] = scaled_data[str(var)]\n",
    "    \n",
    "    #_____RETURN\n",
    "    return candlesDataBase_BigQuery\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE CALCULA LÍMITE MÍNIMO DE EJECUCIÓN SEGÚN MINMAX SEMANAL, AYER, Y HOY\n",
    "def portfolio_minmax(symbol):\n",
    "    \n",
    "    #_____ACTUALIZAR ARCHIVO CONFIG\n",
    "    updateConfig('config_surfNet_MonoBot.ini')\n",
    "    \n",
    "    #_____PARAMETERS\n",
    "    t_frame = '1d'\n",
    "    \n",
    "    #_____CREATE DATAFRAME\n",
    "    datos = ccxt.binance().fetch_ohlcv(symbol, t_frame)\n",
    "    header = ['Timestamp', 'Open', 'High', 'Low', 'Close', 'Volume']\n",
    "    df = pd.DataFrame(datos, columns=header).set_index('Timestamp')\n",
    "    df.index = df.index/1000\n",
    "    df['Date'] = pd.to_datetime(df.index,unit='s')\n",
    "    data =df.sort_values('Date',ascending=False)\n",
    "    \n",
    "    #_____CREATE TIME PARTITIONS\n",
    "    semana = data.head(n=7)\n",
    "    hoy = data.head(n=1)\n",
    "    ayer= data.iloc[1]\n",
    "\n",
    "    #_____CREATE INDICATORS (MEAN & LOW & CHANGE)\n",
    "    mean_s = semana['High'].mean()\n",
    "    mean_h = hoy['High'].mean()\n",
    "    mean_a = ayer['High'].mean()\n",
    "    Low_h = hoy['Low'].mean()\n",
    "    Low_a = ayer['Low'].mean()\n",
    "    change_a = mean_a/Low_a-1\n",
    "    change_h = mean_h/Low_h-1\n",
    "    \n",
    "    #_____CREATE ALPHA BASED ON CHANGE\n",
    "    change_variation_threshold = float(get_config('PORTFOLIO', 'CHANGE_VARIATION_THRESHOLD'))\n",
    "    alpha_variation=float(get_config('PORTFOLIO', 'ALPHA_VARIATION'))\n",
    "    if (change_a > change_variation_threshold) or (change_h>change_variation_threshold):\n",
    "        por_debajo = 1-alpha_variation*float(get_config('PORTFOLIO', 'ALPHA_MULTIPLIER'))\n",
    "    else:\n",
    "        por_debajo = 1-alpha_variation\n",
    "    \n",
    "    #_____CREATE LIMIT BASED ON MEAN + ALPHA\n",
    "    if mean_h < mean_a and mean_h < mean_s:\n",
    "        limite = mean_h*por_debajo\n",
    "    elif mean_a < mean_h and mean_a < mean_s:\n",
    "        limite = mean_a*por_debajo\n",
    "    else:\n",
    "        limite = mean_s*por_debajo\n",
    "        \n",
    "    #_____HOW FAR IS PRICE FROM LIMIT\n",
    "    closeValue=hoy[\"Close\"].values[0]\n",
    "    limite=limite/closeValue-1\n",
    "        \n",
    "    return limite\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE CALCULA LA RENTABILIDAD DE LAS HOLAS TOMANDO LAS VELAS DE X TIMEPO\n",
    "def rentabilidad_promedio(symbol):\n",
    "    \n",
    "    #_____ACTUALIZAR ARCHIVO CONFIG\n",
    "    updateConfig('config_surfNet_MonoBot.ini')\n",
    "\n",
    "    datos = ccxt.binance().fetch_ohlcv(symbol, get_config('PORTFOLIO', 'RETURN_EVALUATION_PERIOD'),limit=int(get_config('PORTFOLIO', 'RETURN_EVALUATION_PERIOD_LIMIT')))\n",
    "    header = ['Timestamp', 'Open', 'High', 'Low', 'Close', 'Volume']\n",
    "    df = pd.DataFrame(datos, columns=header).set_index('Timestamp')\n",
    "    df.index = df.index/1000\n",
    "    df['Date'] = pd.to_datetime(df.index,unit='s')\n",
    "\n",
    "    return np.mean(df.Close.pct_change().dropna().values)\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE CALCULA LA RENTABILIDAD PROMEDIO DE LAS VELAS TOMANDO EN X TIEMPO EN VELAS DE X\n",
    "def amplitud_promedio(symbol):\n",
    "    \n",
    "    #_____ACTUALIZAR ARCHIVO CONFIG\n",
    "    updateConfig('config_surfNet_MonoBot.ini')\n",
    "    \n",
    "    #_____PARAMETERS\n",
    "    amplitud = list()\n",
    "    \n",
    "    #_____CREATE DATABASE\n",
    "    datos = ccxt.binance().fetch_ohlcv(symbol, get_config('PORTFOLIO', 'AMPLITUD_PERIOD_EVALUATION'))\n",
    "    header = ['Timestamp', 'Open', 'High', 'Low', 'Close', 'Volume']\n",
    "    df = pd.DataFrame(datos, columns=header).set_index('Timestamp')\n",
    "    df.index = df.index/1000\n",
    "    df['Date'] = pd.to_datetime(df.index,unit='s')\n",
    "    data =df.sort_values('Date',ascending=False)\n",
    "    \n",
    "    data.Close.pct_change()\n",
    "    \n",
    "    #_____CALCULATE AMPLITUDE\n",
    "    mediahora = data.head(n=int(get_config('PORTFOLIO', 'AMPLITUD_PERIOD_EVALUATION_LAG')))\n",
    "    for i in range(0,int(get_config('PORTFOLIO', 'AMPLITUD_PERIOD_EVALUATION_LAG'))):\n",
    "        high = mediahora.iloc[i, 1]\n",
    "        low = mediahora.iloc[i, 2]\n",
    "        amplitud.append(high/low-1)\n",
    "    amplitudP = np.mean(amplitud)\n",
    "    \n",
    "    return amplitudP\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE MIRA LA TENDENCIA DE LAS ÚLTIMAS X HORAS DE UN MERCADO\n",
    "def marketTrend(market):\n",
    "    \n",
    "    #_____ACTUALIZAR ARCHIVO CONFIG\n",
    "    updateConfig('config_surfNet_MonoBot.ini')\n",
    "\n",
    "    #_____CREATE DATABASE\n",
    "    datos = ccxt.binance().fetch_ohlcv(market, get_config('PORTFOLIO', 'TREND_EVALUATION_PERIOD'),limit=int(get_config('PORTFOLIO', 'TREND_EVALUATION_PERIOD_LIMIT')))\n",
    "    header = ['Timestamp', 'Open', 'High', 'Low', 'Close', 'Volume']\n",
    "    df = pd.DataFrame(datos, columns=header)\n",
    "    df.Timestamp = df.Timestamp/1000\n",
    "    df['Timestamp'] = pd.to_datetime(df.Timestamp,unit='s')\n",
    "    df['Index']=df.index\n",
    "\n",
    "    #_____CREATE TRENDLINE\n",
    "    # fig, ax = plt.subplots()\n",
    "    # df.plot(x='Index', y='Close', ax=ax)\n",
    "    model = sm.formula.ols(formula='Close ~ Index', data=df[[\"Index\",\"Close\"]])\n",
    "    res = model.fit()\n",
    "    # df.assign(fit=res.fittedvalues).plot(x='Index', y='fit', ax=ax)\n",
    "    marketTrend=res.fittedvalues.values[-1]/res.fittedvalues.values[0]-1\n",
    "    \n",
    "    return marketTrend\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE MIRA LA TENDENCIA DE LAS ÚLTIMAS X HORAS DE UN MERCADO\n",
    "def volumenPromedio(market):\n",
    "    \n",
    "    #_____ACTUALIZAR ARCHIVO CONFIG\n",
    "    updateConfig('config_surfNet_MonoBot.ini')\n",
    "\n",
    "    #_____CREATE DATABASE\n",
    "    datos = ccxt.binance().fetch_ohlcv(market, get_config('PORTFOLIO', 'VOLUME_EVALUATION_PERIOD'),limit=int(get_config('PORTFOLIO', 'VOLUME_EVALUATION_PERIOD_LIMIT')))\n",
    "    header = ['Timestamp', 'Open', 'High', 'Low', 'Close', 'Volume']\n",
    "    df = pd.DataFrame(datos, columns=header)\n",
    "    df.Timestamp = df.Timestamp/1000\n",
    "    df['Timestamp'] = pd.to_datetime(df.Timestamp,unit='s')\n",
    "    df['Index']=df.index\n",
    "    df[\"Vol_Price\"]=df[\"Volume\"]*df[\"Close\"]\n",
    "\n",
    "    return np.mean(list(df.Vol_Price.values))\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE CREA PORTAFOLIO SEGÚN LÍNEA DE EFICIENCIA DE PARETO\n",
    "def is_pareto_efficient(costs, return_mask = True):\n",
    "    \"\"\"\n",
    "    Find the pareto-efficient points\n",
    "    :param costs: An (n_points, n_costs) array\n",
    "    :param return_mask: True to return a mask\n",
    "    :return: An array of indices of pareto-efficient points.\n",
    "        If return_mask is True, this will be an (n_points, ) boolean array\n",
    "        Otherwise it will be a (n_efficient_points, ) integer array of indices.\n",
    "    \"\"\"\n",
    "    is_efficient = np.arange(costs.shape[0])\n",
    "    n_points = costs.shape[0]\n",
    "    next_point_index = 0  # Next index in the is_efficient array to search for\n",
    "    while next_point_index<len(costs):\n",
    "        nondominated_point_mask = np.any(costs>costs[next_point_index], axis=1)\n",
    "        nondominated_point_mask[next_point_index] = True\n",
    "        is_efficient = is_efficient[nondominated_point_mask]  # Remove dominated points\n",
    "        costs = costs[nondominated_point_mask]\n",
    "        next_point_index = np.sum(nondominated_point_mask[:next_point_index])+1\n",
    "    if return_mask:\n",
    "        is_efficient_mask = np.zeros(n_points, dtype = bool)\n",
    "        is_efficient_mask[is_efficient] = True\n",
    "        return is_efficient_mask\n",
    "    else:\n",
    "        return is_efficient\n",
    "    \n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE DEVUELVE EL TOG X DE MERCADOS\n",
    "def topCoinMarketCap():\n",
    "    \n",
    "    updateConfig(\"semiManual.ini\")\n",
    "    \n",
    "    API_KEY_CAP=\"8edb78ea-b23d-4b23-8a6f-5ece6b703720\"\n",
    "    url = 'https://pro-api.coinmarketcap.com/v1/cryptocurrency/listings/latest'\n",
    "    parameters = {\n",
    "      'start':'1',\n",
    "      'limit': get_config(\"MARKETS\",\"TOP_CMC\"),\n",
    "      'convert':'USD'\n",
    "    }\n",
    "    headers = {\n",
    "      'Accepts': 'application/json',\n",
    "      'X-CMC_PRO_API_KEY': API_KEY_CAP,\n",
    "    }\n",
    "\n",
    "    session = Session()\n",
    "    session.headers.update(headers)\n",
    "\n",
    "    try:\n",
    "      response = session.get(url, params=parameters)\n",
    "      data = json.loads(response.text)\n",
    "      #print(data)\n",
    "    except (ConnectionError, Timeout, TooManyRedirects) as e:\n",
    "      print(e)\n",
    "    \n",
    "    response = pd.DataFrame(data[\"data\"])\n",
    "    \n",
    "    return list(response.symbol.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27a3028",
   "metadata": {},
   "source": [
    "# CHECKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00555860",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05e41241",
   "metadata": {},
   "source": [
    "# RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc45c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pareto_df=pd.DataFrame(columns=[\"MARKET\",\"TREND\",\"AMPLITUD\",\"RENTABILIDAD\",\"LIMIT\",\"VOLUME\",\"RSI\"])\n",
    "writePickleVariable(Pareto_df,\"portfolio\")\n",
    "\n",
    "#_____LOOP INFINITO\n",
    "while True:\n",
    "    \n",
    "    #_____TRY DE CONTINGENCIA\n",
    "    try:\n",
    "\n",
    "        #_____ACTUALIZAR ARCHIVO CONFIG\n",
    "        updateConfig('config_surfNet_MonoBot.ini')\n",
    "\n",
    "        #_____ACTUALIZAR CREDENCIALES\n",
    "        binance = ccxt.binance()\n",
    "        binance.apiKey = get_config('BINANCE_PORTFOLIO', 'API_KEY')\n",
    "        binance.secret = get_config('BINANCE_PORTFOLIO', 'API_SECRET')\n",
    "\n",
    "        #_____NUEVA LISTA DE MERCADOS\n",
    "        mercados=list(readPickleVariable(\"/home/ubuntu/SurfNet/predictionModels/PREDICTION/marketDict\").keys())\n",
    "            \n",
    "        #_____UPDATE CONFIG PREDICTION\n",
    "        updateConfig(\"/home/ubuntu/SurfNet/predictionModels/PREDICTION/predictionModels.ini\")\n",
    "\n",
    "        #_____CREAR PORTAFOLIO CON MERCADOS EXISTENTES\n",
    "        mercados_Portafolio_Neto=[]\n",
    "        for i in mercados:\n",
    "            #_____ITERAR SOBRE FRACTAL\n",
    "            for fractal in ast.literal_eval(get_config(\"PARAMETERS\",\"FRACTAL_BUY\")):\n",
    "                try:\n",
    "                    #_____DESCARGAR PARÁMETROS DE CORRECCIÓN\n",
    "                    market_Parameters=readPickleVariable(\"/home/ubuntu/SurfNet/predictionModels/MODELS/\"+i.replace(\"/\",\"_\")+\"_PARAMETERS\"+\"_\"+fractal)\n",
    "                    if market_Parameters.at[0,\"NET_UTILITY\"]!=0:\n",
    "                        mercados_Portafolio_Neto.append(i)\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "        #_____ACTUALIZAR ARCHIVO CONFIG\n",
    "        updateConfig('config_surfNet_MonoBot.ini')\n",
    "            \n",
    "        #_____REMOVER BNB POR TEMA DE PAGO DE COMISIONES\n",
    "        try:\n",
    "            mercados_Portafolio_Neto.remove(\"BNB/USDT\")\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "        #_____SI LISTA DE MERCADOS CONTIENE VALORES\n",
    "        if len(mercados_Portafolio_Neto) >= 1:\n",
    "            \n",
    "            #_____NUEVA LISTA DE MERCADOS\n",
    "            topMarketList=[]\n",
    "            \n",
    "            #_____CRUZAR MERCADOS CON TOP EN COINMARKETCAP\n",
    "            for market in topCoinMarketCap():\n",
    "                if market+\"/USDT\" in mercados_Portafolio_Neto:\n",
    "                    topMarketList.append(market+\"/USDT\")\n",
    "                \n",
    "            #_____ACTUALIZAR ARCHIVO CONFIG\n",
    "            updateConfig('config_surfNet_MonoBot.ini')\n",
    "\n",
    "            #_____PORTAFOLIO GENERAL\n",
    "            marketPortfolioDataFrame=pd.DataFrame()\n",
    "            marketPortfolioDataFrame_contador=0\n",
    "            \n",
    "            for i in topMarketList:\n",
    "                marketPortfolioDataFrame.at[marketPortfolioDataFrame_contador,\"MARKET\"]=i\n",
    "                \n",
    "                if int(get_config(\"PORTFOLIO\",\"TREND\"))==1:\n",
    "                    marketPortfolioDataFrame.at[marketPortfolioDataFrame_contador,\"TREND\"]=marketTrend(i)\n",
    "                    time.sleep(5)\n",
    "                if int(get_config(\"PORTFOLIO\",\"AMPLITUD\"))==1:\n",
    "                    marketPortfolioDataFrame.at[marketPortfolioDataFrame_contador,\"AMPLITUD\"]=amplitud_promedio(i)\n",
    "                    time.sleep(5)\n",
    "                if int(get_config(\"PORTFOLIO\",\"RENTABILIDAD\"))==1:\n",
    "                    marketPortfolioDataFrame.at[marketPortfolioDataFrame_contador,\"RENTABILIDAD\"]=rentabilidad_promedio(i)\n",
    "                    time.sleep(5)\n",
    "                if int(get_config(\"PORTFOLIO\",\"LIMIT\"))==1:\n",
    "                    marketPortfolioDataFrame.at[marketPortfolioDataFrame_contador,\"LIMIT\"]=portfolio_minmax(i)\n",
    "                    time.sleep(5)\n",
    "                if int(get_config(\"PORTFOLIO\",\"VOLUME\"))==1:\n",
    "                    marketPortfolioDataFrame.at[marketPortfolioDataFrame_contador,\"VOLUME\"]=volumenPromedio(i)\n",
    "                    time.sleep(5)\n",
    "                \n",
    "                marketPortfolioDataFrame_contador=marketPortfolioDataFrame_contador+1\n",
    "\n",
    "            #_____RELEVANT VARIABLES\n",
    "            contador=0\n",
    "            for market_model in list(marketPortfolioDataFrame.MARKET.values):\n",
    "\n",
    "                #_____CARGAR BASE DE DATOS\n",
    "                myData = binance.fetch_ohlcv(market_model,\"15\"+\"m\",limit=1000)\n",
    "                time.sleep(5)\n",
    "                candlesDataBase_BigQuery =pd.DataFrame(columns=[\"ID\",\"TIME\",\"MARKET\",\"OPEN\",\"HIGH\",\"LOW\",\"CLOSE\",\"VOLUME\"])\n",
    "\n",
    "                for i in range(0,len(myData)):\n",
    "                    candlesDataBase_BigQuery.at[i,\"ID\"]=myData[i][0]\n",
    "                    candlesDataBase_BigQuery.at[i,\"TIME\"]=datetime.fromtimestamp(myData[i][0]/1000.0)\n",
    "                    candlesDataBase_BigQuery.at[i,\"MARKET\"]=market_model\n",
    "                    candlesDataBase_BigQuery.at[i,\"OPEN\"]=myData[i][1]\n",
    "                    candlesDataBase_BigQuery.at[i,\"HIGH\"]=myData[i][2]\n",
    "                    candlesDataBase_BigQuery.at[i,\"LOW\"]=myData[i][3]\n",
    "                    candlesDataBase_BigQuery.at[i,\"CLOSE\"]=myData[i][4]\n",
    "                    candlesDataBase_BigQuery.at[i,\"VOLUME\"]=myData[i][5]\n",
    "\n",
    "                #_____GUARDAR BASE DE DATOS PARA BACKTESTING FUTURO\n",
    "                backtestingDataFrame=candlesDataBase_BigQuery.copy()\n",
    "\n",
    "                #_____CREAR VARIABLES INPUT\n",
    "                candlesDataBase_BigQuery=variableCreation(candlesDataBase_BigQuery)\n",
    "\n",
    "                #####\n",
    "\n",
    "                marketPortfolioDataFrame.at[contador,\"RSI\"]=(candlesDataBase_BigQuery.at[len(candlesDataBase_BigQuery)-1,\"RSI\"])*(-1)\n",
    "                \n",
    "                #####\n",
    "\n",
    "                contador+=1\n",
    "                \n",
    "\n",
    "            #_____PORTAFOLIO JERÁRQUICO\n",
    "            Pareto_df=marketPortfolioDataFrame.copy()\n",
    "            Pareto_df.reset_index(inplace=True,drop=True)\n",
    "            Pareto_df_numpy=Pareto_df.drop(['MARKET'], axis=1)\n",
    "\n",
    "            Efficient_market=is_pareto_efficient(np.array(Pareto_df_numpy), return_mask = False)\n",
    "            Pareto_df=Pareto_df.loc[list(Efficient_market),:]\n",
    "\n",
    "            writePickleVariable(Pareto_df,\"portfolio\")\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            Pareto_df=pd.DataFrame(columns=[\"MARKET\",\"TREND\",\"AMPLITUD\",\"RENTABILIDAD\",\"LIMIT\",\"VOLUME\"])\n",
    "            writePickleVariable(Pareto_df,\"portfolio\")\n",
    "        \n",
    "        #_____CLEAR\n",
    "        clear_output()\n",
    "        \n",
    "        #_____SLEEP\n",
    "        time.sleep(300)\n",
    "        \n",
    "    #_____EXCEPT\n",
    "    except:\n",
    "        \n",
    "        #_____PRINT\n",
    "        print(\"[[ERROR]]\")\n",
    "        \n",
    "        #_____SLEEP\n",
    "        time.sleep(300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
