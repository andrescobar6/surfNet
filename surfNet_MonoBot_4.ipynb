{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4067e6f3",
   "metadata": {},
   "source": [
    "# LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5afb2570",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import math\n",
    "import ccxt\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import configparser\n",
    "import pandas as pd\n",
    "import google.cloud\n",
    "from pandas_gbq import gbq\n",
    "import matplotlib.cm as cm\n",
    "from boruta import BorutaPy\n",
    "import statsmodels.api as sm\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from google.cloud import bigquery\n",
    "from sklearn import preprocessing\n",
    "from IPython.display import clear_output\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#_____\n",
    "\n",
    "pd.set_option('display.max_rows', 5000)\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bcb702",
   "metadata": {},
   "source": [
    "# FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2340e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCIÓN QUE LEE EL ARCHIVO CONFIG\n",
    "def get_config(category, key):\n",
    "    \n",
    "    global config\n",
    "    return config[category][key]\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE GENERA CONEXIÓN CON ARCHIVO CONFIG\n",
    "def updateConfig(config_name):\n",
    "    \n",
    "    global config\n",
    "    \n",
    "    config = configparser.ConfigParser()\n",
    "    config.sections()\n",
    "    config.read(config_name)\n",
    "    \n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE GRAFICA POR COLORES SEGUN COMPRAS Y NO COMRPAS\n",
    "def plot_colourline(x,y,c):\n",
    "    c = c\n",
    "    ax = plt.gca()\n",
    "    for i in np.arange(len(x)-1):\n",
    "        ax.plot([x[i],x[i+1]], [y[i],y[i+1]], c=c[i])\n",
    "    return\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE ESCRIBE PICKLE DE VARIABLE\n",
    "def writePickleVariable(variable,variable_name):\n",
    "    pickle_out = open(variable_name+\".pickle\",\"wb\")\n",
    "    pickle.dump(variable, pickle_out)\n",
    "    pickle_out.close()\n",
    "    \n",
    "#_____\n",
    "    \n",
    "#FUNCIÓN QUE LEE PICKLE DE VARIABLE\n",
    "def readPickleVariable(variable_name):\n",
    "    while True:\n",
    "        try:\n",
    "            return pickle.load(open(variable_name+\".pickle\",\"rb\"))\n",
    "            break\n",
    "        except:\n",
    "            time.sleep(1)\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE REDONDEA FLOAT HACIA ABAJO SEGÚN DECIMALES\n",
    "def round_decimals_down(number:float, decimals:int=2):\n",
    "    \"\"\"\n",
    "    Returns a value rounded down to a specific number of decimal places.\n",
    "    \"\"\"\n",
    "    if not isinstance(decimals, int):\n",
    "        raise TypeError(\"decimal places must be an integer\")\n",
    "    elif decimals < 0:\n",
    "        raise ValueError(\"decimal places has to be 0 or more\")\n",
    "    elif decimals == 0:\n",
    "        return math.floor(number)\n",
    "\n",
    "    factor = 10 ** decimals\n",
    "    return math.floor(number * factor) / factorho,\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE REDONDEA FLOAT HACIA ARRIBA SEGÚN DECIMALES\n",
    "def round_decimals_up(number:float, decimals:int=2):\n",
    "    \"\"\"\n",
    "    Returns a value rounded down to a specific number of decimal places.\n",
    "    \"\"\"\n",
    "    if not isinstance(decimals, int):\n",
    "        raise TypeError(\"decimal places must be an integer\")\n",
    "    elif decimals < 0:\n",
    "        raise ValueError(\"decimal places has to be 0 or more\")\n",
    "    elif decimals == 0:\n",
    "        return math.ceil(number)\n",
    "\n",
    "    factor = 10 ** decimals\n",
    "    return math.ceil(number * factor) / factor\n",
    "\n",
    "#_____\n",
    "\n",
    "def cargarPortafolio():\n",
    "\n",
    "    #_____ACTUALIZAR ARCHIVO CONFIG\n",
    "    updateConfig('config_surfNet_MonoBot.ini')\n",
    "\n",
    "    #_____CREAR PORTAFOLIO\n",
    "    portfolio=readPickleVariable(\"portfolio\")\n",
    "    portfolio.reset_index(inplace=True,drop=True)\n",
    "    portfolio.RSI=portfolio.RSI*(-1)\n",
    "    \n",
    "    if int(get_config(\"ITERATION\",\"TREND\"))==1:\n",
    "        try:\n",
    "            portfolio=portfolio.loc[(portfolio.TREND>0)]\n",
    "            portfolio.reset_index(inplace=True,drop=True)\n",
    "        except:\n",
    "            pass\n",
    "    if int(get_config(\"ITERATION\",\"AMPLITUD\"))==1:\n",
    "        try:\n",
    "            portfolio=portfolio.loc[(portfolio.AMPLITUD>0)]\n",
    "            portfolio.reset_index(inplace=True,drop=True)\n",
    "        except:\n",
    "            pass\n",
    "    if int(get_config(\"ITERATION\",\"RENTABILIDAD\"))==1:\n",
    "        try:\n",
    "            portfolio=portfolio.loc[(portfolio.RENTABILIDAD>0)]\n",
    "            portfolio.reset_index(inplace=True,drop=True)\n",
    "        except:\n",
    "            pass\n",
    "    if int(get_config(\"ITERATION\",\"LIMIT\"))==1:\n",
    "        try:\n",
    "            portfolio=portfolio.loc[(portfolio.LIMIT>0)]\n",
    "            portfolio.reset_index(inplace=True,drop=True)\n",
    "        except:\n",
    "            pass\n",
    "    if int(get_config(\"ITERATION\",\"VOLUME\"))==1:\n",
    "        try:\n",
    "            portfolio=portfolio.loc[(portfolio.VOLUME>0)]\n",
    "            portfolio.reset_index(inplace=True,drop=True)\n",
    "        except:\n",
    "            pass\n",
    "    try:\n",
    "        portfolio=portfolio.loc[(portfolio.RSI<=int(get_config(\"ITERATION\",\"RSI\")))]\n",
    "        portfolio.reset_index(inplace=True,drop=True)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    #_____PORTAFOLIO\n",
    "    return portfolio\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE RETORNA BALANCE USDC EN BINANCE\n",
    "def getUsdtBinance():\n",
    "    global binance\n",
    "    while True:\n",
    "        try:\n",
    "            return float(binance.fetch_balance()[\"USDT\"][\"total\"])\n",
    "            break\n",
    "        except:\n",
    "            print(\"ERROR: getUsdtBinance()\")\n",
    "            time.sleep(1)\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE DESCARGA BASE DE DATOS DE MERCADO DE BIGQUERY\n",
    "def downloadDataBaseBigQuery(market_model,time,rows=None):\n",
    "    \n",
    "    #_____GOOGLE CLOUD CONECTION\n",
    "    os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"/home/ubuntu/SurfNet/predictionModels/PREDICTION/bigQueryAccess.json\"\n",
    "\n",
    "    #_____SI NO SE DA UN NÚMERO ESPECÍFICO DE FILAS POR PARÁMETRO\n",
    "    if rows==None:\n",
    "\n",
    "        #_____DESCARGAR BASE DE DATOS\n",
    "        candlesDataBase_BigQuery=gbq.read_gbq(\"SELECT * FROM [dogwood-terra-308100:surfNet.\"+market_model.replace(\"/\",\"_\")+\"] ORDER BY TIME DESC\",project_id=\"dogwood-terra-308100\",dialect=\"legacy\").sort_values(by=\"TIME\")\n",
    "        candlesDataBase_BigQuery.reset_index(inplace=True,drop=True)\n",
    "\n",
    "    else:\n",
    "\n",
    "        #_____DESCARGAR BASE DE DATOS\n",
    "        candlesDataBase_BigQuery=gbq.read_gbq(\"SELECT * FROM [dogwood-terra-308100:surfNet.\"+market_model.replace(\"/\",\"_\")+\"] ORDER BY TIME DESC LIMIT \"+str(rows),project_id=\"dogwood-terra-308100\",dialect=\"legacy\").sort_values(by=\"TIME\")\n",
    "        candlesDataBase_BigQuery.reset_index(inplace=True,drop=True)\n",
    "\n",
    "    candlesDataBase_BigQuery.OPEN=candlesDataBase_BigQuery.OPEN.astype(float)\n",
    "    candlesDataBase_BigQuery.HIGH=candlesDataBase_BigQuery.HIGH.astype(float)\n",
    "    candlesDataBase_BigQuery.LOW=candlesDataBase_BigQuery.LOW.astype(float)\n",
    "    candlesDataBase_BigQuery.CLOSE=candlesDataBase_BigQuery.CLOSE.astype(float)\n",
    "    candlesDataBase_BigQuery.VOLUME=candlesDataBase_BigQuery.VOLUME.astype(float)\n",
    "\n",
    "    #_____REESTRUCTURAR BASE DE DATOS\n",
    "    candlesDataBase_BigQuery.reset_index(inplace=True,drop=True)\n",
    "\n",
    "    if time != \"1\":\n",
    "\n",
    "        #_____UPDATE CONFIG PREDICTION\n",
    "        updateConfig('/home/ubuntu/SurfNet/predictionModels/PREDICTION/predictionModels.ini')\n",
    "\n",
    "        #_____CREAR COLUMNAS\n",
    "        candlesDataBase_BigQuery_copy=candlesDataBase_BigQuery.copy()\n",
    "        candlesDataBase_BigQuery_copy=candlesDataBase_BigQuery_copy.set_index('TIME')\n",
    "        candlesDataBase_BigQuery_copy_total=candlesDataBase_BigQuery_copy[[\"ID\"]].groupby(pd.Grouper(freq=time+'min', offset=time+'min')).min()\n",
    "        candlesDataBase_BigQuery_copy_total=candlesDataBase_BigQuery_copy_total.join(candlesDataBase_BigQuery_copy[[\"VOLUME\"]].groupby(pd.Grouper(freq=time+'min', offset=time+'min')).sum())\n",
    "        candlesDataBase_BigQuery_copy_total=candlesDataBase_BigQuery_copy_total.join(candlesDataBase_BigQuery_copy[[\"LOW\"]].groupby(pd.Grouper(freq=time+'min', offset=time+'min')).min())\n",
    "        candlesDataBase_BigQuery_copy_total=candlesDataBase_BigQuery_copy_total.join(candlesDataBase_BigQuery_copy[[\"HIGH\"]].groupby(pd.Grouper(freq=time+'min', offset=time+'min')).max())\n",
    "\n",
    "        #_____AGREAR DATOS\n",
    "        for i in list(candlesDataBase_BigQuery_copy_total.index.values):\n",
    "            try:\n",
    "                candlesDataBase_BigQuery_copy_total.at[i,\"OPEN\"]=candlesDataBase_BigQuery.loc[candlesDataBase_BigQuery.TIME==i][\"OPEN\"].values[0]\n",
    "                final_time = i + np.timedelta64(int(time),'m')\n",
    "                if final_time in list(candlesDataBase_BigQuery_copy_total.index.values):\n",
    "                    candlesDataBase_BigQuery_copy_total.at[i,\"CLOSE\"]=candlesDataBase_BigQuery.loc[candlesDataBase_BigQuery.TIME==final_time][\"OPEN\"].values[0]\n",
    "                else:\n",
    "                    candlesDataBase_BigQuery_copy_total.at[i,\"CLOSE\"]=candlesDataBase_BigQuery.at[len(candlesDataBase_BigQuery)-1,\"CLOSE\"]\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        #_____RESET INDEX\n",
    "        candlesDataBase_BigQuery_copy_total.reset_index(level=['TIME'],inplace=True)\n",
    "\n",
    "        #_____COLUMNA MARKET\n",
    "        for i in range(0,len(candlesDataBase_BigQuery_copy_total)):\n",
    "            candlesDataBase_BigQuery_copy_total.at[i,\"MARKET\"]=candlesDataBase_BigQuery.MARKET.values[0]\n",
    "\n",
    "        #_____ORDENAR COLUMNAS\n",
    "        column_names = list(candlesDataBase_BigQuery.columns)\n",
    "        candlesDataBase_BigQuery_copy_total = candlesDataBase_BigQuery_copy_total.reindex(columns=column_names)\n",
    "        candlesDataBase_BigQuery_copy_total.dropna(inplace=True)\n",
    "        candlesDataBase_BigQuery=candlesDataBase_BigQuery_copy_total.copy()\n",
    "\n",
    "    #_____RETURN\n",
    "    return candlesDataBase_BigQuery\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE DEVUELVE EL RSI DADO UN PERIODO DETERMINADO\n",
    "def RSI(candlesDataBase_BigQuery):\n",
    "    \n",
    "    global config\n",
    "    updateConfig(\"/home/ubuntu/SurfNet/predictionModels/PREDICTION/predictionModels.ini\")\n",
    "    \n",
    "    series=pd.Series(list(candlesDataBase_BigQuery.CLOSE.values))\n",
    "    period=int(get_config(\"PARAMETERS\",\"RSI_LEN\"))\n",
    "    \n",
    "    delta = series.diff().dropna()\n",
    "    u = delta * 0\n",
    "    d = u.copy()\n",
    "    u[delta > 0] = delta[delta > 0]\n",
    "    d[delta < 0] = -delta[delta < 0]\n",
    "    u[u.index[period-1]] = np.mean( u[:period] ) #first value is sum of avg gains\n",
    "    u = u.drop(u.index[:(period-1)])\n",
    "    d[d.index[period-1]] = np.mean( d[:period] ) #first value is sum of avg losses\n",
    "    d = d.drop(d.index[:(period-1)])\n",
    "    rs = pd.DataFrame.ewm(u, com=period-1, adjust=False).mean() / \\\n",
    "         pd.DataFrame.ewm(d, com=period-1, adjust=False).mean()\n",
    "    \n",
    "    rsi=100 - 100 / (1 + rs)\n",
    "    \n",
    "    for i in list(rsi.index.values):\n",
    "        candlesDataBase_BigQuery.at[i,\"RSI\"]=rsi[i]\n",
    "                                        \n",
    "    return candlesDataBase_BigQuery\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE DEVUELVE EL RSI DADO UN PERIODO DETERMINADO\n",
    "def RSI_GENERAL(series, period):\n",
    "    delta = series.diff().dropna()\n",
    "    u = delta * 0\n",
    "    d = u.copy()\n",
    "    u[delta > 0] = delta[delta > 0]\n",
    "    d[delta < 0] = -delta[delta < 0]\n",
    "    u[u.index[period-1]] = np.mean( u[:period] ) #first value is sum of avg gains\n",
    "    u = u.drop(u.index[:(period-1)])\n",
    "    d[d.index[period-1]] = np.mean( d[:period] ) #first value is sum of avg losses\n",
    "    d = d.drop(d.index[:(period-1)])\n",
    "    rs = pd.DataFrame.ewm(u, com=period-1, adjust=False).mean() / \\\n",
    "         pd.DataFrame.ewm(d, com=period-1, adjust=False).mean()\n",
    "    return 100 - 100 / (1 + rs)\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE CALCULA MACD\n",
    "def MACD(candlesDataBase_BigQuery):\n",
    "    \n",
    "    global config\n",
    "    updateConfig(\"/home/ubuntu/SurfNet/predictionModels/PREDICTION/predictionModels.ini\")\n",
    "    \n",
    "    close_data_df=candlesDataBase_BigQuery.copy()\n",
    "    close_data_df.CLOSE=close_data_df.CLOSE.astype(float)\n",
    "    close_data_df=close_data_df[[\"CLOSE\"]]\n",
    "    \n",
    "    #_____CREAR VARIABLE MACD\n",
    "    macd_12 = close_data_df.ewm(span=int(get_config(\"PARAMETERS\",\"MACD_SHORT\")), adjust=False).mean()\n",
    "    macd_26 = close_data_df.ewm(span=int(get_config(\"PARAMETERS\",\"MACD_LONG\")), adjust=False).mean()\n",
    "    macd = macd_12 - macd_26\n",
    "    macd_9 = macd.ewm(span=int(get_config(\"PARAMETERS\",\"MACD_TRIGGER\")), adjust=False).mean()\n",
    "\n",
    "    #_____AGREGAR VARIABLES A LA BASE DE DATOS\n",
    "    candlesDataBase_BigQuery[\"MACD\"]=macd\n",
    "    #candlesDataBase_BigQuery[\"MACD_\"+get_config(\"PARAMETERS\",\"MACD_SHORT\")]=macd_12\n",
    "    #candlesDataBase_BigQuery[\"MACD_\"+get_config(\"PARAMETERS\",\"MACD_LONG\")]=macd_26\n",
    "    candlesDataBase_BigQuery[\"MACD_TRIGGER\"]=macd_9\n",
    "    \n",
    "    return candlesDataBase_BigQuery\n",
    "\n",
    "#_____\n",
    "\n",
    "\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE BRINDA LOS NIVELES DE FIBONACCI\n",
    "def fibonacciLevels(candlesDataBase_BigQuery):\n",
    "    \n",
    "    global config\n",
    "    global fractal\n",
    "    \n",
    "    #_____UPDATE CONFIG PREDICTION\n",
    "    updateConfig(\"/home/ubuntu/SurfNet/predictionModels/PREDICTION/predictionModels.ini\")\n",
    "    \n",
    "    #_____ACTUALIZAR PARÁMETROS\n",
    "    FIBONACCI_PERIOD=int(int(get_config(\"PARAMETERS\",\"FIBONACCI_PERIOD\"))/int(fractal))\n",
    "\n",
    "    #_____RECORRER DATOS DE TEST\n",
    "    for i in range(FIBONACCI_PERIOD,len(candlesDataBase_BigQuery)):\n",
    "        \n",
    "        #_____FIBONACCI\n",
    "        lows=list(candlesDataBase_BigQuery[i-FIBONACCI_PERIOD:i].LOW.values)\n",
    "        highs=list(candlesDataBase_BigQuery[i-FIBONACCI_PERIOD:i].HIGH.values)\n",
    "        Price_Min = min(lows)\n",
    "        Price_Max = max(highs)\n",
    "        Diff = Price_Max-Price_Min\n",
    "        level1 = Price_Max - 0.236 * Diff\n",
    "        level2 = Price_Max - 0.382 * Diff\n",
    "        level3 = Price_Max - 0.618 * Diff\n",
    "        level4 = Price_Max - 0.786 * Diff\n",
    "        \n",
    "        candlesDataBase_BigQuery.at[i,\"FIBO_LEVEL_1\"]=level1\n",
    "        candlesDataBase_BigQuery.at[i,\"FIBO_LEVEL_2\"]=level2\n",
    "        candlesDataBase_BigQuery.at[i,\"FIBO_LEVEL_3\"]=level3\n",
    "        candlesDataBase_BigQuery.at[i,\"FIBO_LEVEL_4\"]=level4\n",
    "            \n",
    "    return candlesDataBase_BigQuery\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE CREA VARIABLES ENCONTRADAS EN ARTÍCULOS\n",
    "def newVariables(candlesDataBase_BigQuery):\n",
    "    \n",
    "    #_____VARIABLES NUEVAS\n",
    "    candlesDataBase_BigQuery['SMA5_VOL'] = candlesDataBase_BigQuery.groupby('MARKET')['VOLUME'].transform(lambda x: x.rolling(window = 5).mean())\n",
    "    candlesDataBase_BigQuery['SMA15_VOL'] = candlesDataBase_BigQuery.groupby('MARKET')['VOLUME'].transform(lambda x: x.rolling(window = 15).mean())\n",
    "    candlesDataBase_BigQuery['SMA_VOL_RATIO'] = candlesDataBase_BigQuery['SMA5_VOL']/candlesDataBase_BigQuery['SMA15_VOL']\n",
    "\n",
    "    #_____VARIABLES NUEVAS\n",
    "    candlesDataBase_BigQuery['LOWEST_5D'] = candlesDataBase_BigQuery.groupby('MARKET')['LOW'].transform(lambda x: x.rolling(window = 5).min())\n",
    "    candlesDataBase_BigQuery['HIGH_5D'] = candlesDataBase_BigQuery.groupby('MARKET')['HIGH'].transform(lambda x: x.rolling(window = 5).max())\n",
    "    candlesDataBase_BigQuery['LOWEST_15D'] = candlesDataBase_BigQuery.groupby('MARKET')['LOW'].transform(lambda x: x.rolling(window = 15).min())\n",
    "    candlesDataBase_BigQuery['HIGH_15D'] = candlesDataBase_BigQuery.groupby('MARKET')['HIGH'].transform(lambda x: x.rolling(window = 15).max())\n",
    "    candlesDataBase_BigQuery['STOCHASTIC_5'] = ((candlesDataBase_BigQuery['CLOSE'] - candlesDataBase_BigQuery['LOWEST_5D'])/(candlesDataBase_BigQuery['HIGH_5D'] - candlesDataBase_BigQuery['LOWEST_5D']))*100\n",
    "    candlesDataBase_BigQuery['STOCHASTIC_15'] = ((candlesDataBase_BigQuery['CLOSE'] - candlesDataBase_BigQuery['LOWEST_15D'])/(candlesDataBase_BigQuery['HIGH_15D'] - candlesDataBase_BigQuery['LOWEST_15D']))*100\n",
    "    candlesDataBase_BigQuery['STOCHASTIC_D_5'] = candlesDataBase_BigQuery['STOCHASTIC_5'].rolling(window = 5).mean()\n",
    "    candlesDataBase_BigQuery['STOCHASTIC_D_15'] = candlesDataBase_BigQuery['STOCHASTIC_5'].rolling(window = 15).mean()\n",
    "    candlesDataBase_BigQuery['STOCHASTIC_RATIO'] = candlesDataBase_BigQuery['STOCHASTIC_D_5']/candlesDataBase_BigQuery['STOCHASTIC_D_15']\n",
    "    \n",
    "    return candlesDataBase_BigQuery\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCIÓN SUPERTREND\n",
    "def superTrend(df, atr_period, multiplier):\n",
    "    \n",
    "    high = df['HIGH']\n",
    "    low = df['LOW']\n",
    "    close = df['CLOSE']\n",
    "    \n",
    "    # calculate ATR\n",
    "    price_diffs = [high - low, \n",
    "                   high - close.shift(), \n",
    "                   close.shift() - low]\n",
    "    true_range = pd.concat(price_diffs, axis=1)\n",
    "    true_range = true_range.abs().max(axis=1)\n",
    "    # default ATR calculation in supertrend indicator\n",
    "    atr = true_range.ewm(alpha=1/atr_period,min_periods=atr_period).mean() \n",
    "    # df['atr'] = df['tr'].rolling(atr_period).mean()\n",
    "    \n",
    "    # HL2 is simply the average of high and low prices\n",
    "    hl2 = (high + low) / 2\n",
    "    # upperband and lowerband calculation\n",
    "    # notice that final bands are set to be equal to the respective bands\n",
    "    final_upperband = upperband = hl2 + (multiplier * atr)\n",
    "    final_lowerband = lowerband = hl2 - (multiplier * atr)\n",
    "    \n",
    "    # initialize Supertrend column to True\n",
    "    supertrend = [True] * len(df)\n",
    "    \n",
    "    for i in range(1, len(df.index)):\n",
    "        curr, prev = i, i-1\n",
    "        \n",
    "        # if current close price crosses above upperband\n",
    "        if close[curr] > final_upperband[prev]:\n",
    "            supertrend[curr] = True\n",
    "        # if current close price crosses below lowerband\n",
    "        elif close[curr] < final_lowerband[prev]:\n",
    "            supertrend[curr] = False\n",
    "        # else, the trend continues\n",
    "        else:\n",
    "            supertrend[curr] = supertrend[prev]\n",
    "            \n",
    "            # adjustment to the final bands\n",
    "            if supertrend[curr] == True and final_lowerband[curr] < final_lowerband[prev]:\n",
    "                final_lowerband[curr] = final_lowerband[prev]\n",
    "            if supertrend[curr] == False and final_upperband[curr] > final_upperband[prev]:\n",
    "                final_upperband[curr] = final_upperband[prev]\n",
    "\n",
    "        # to remove bands according to the trend direction\n",
    "        if supertrend[curr] == True:\n",
    "            final_upperband[curr] = np.nan\n",
    "        else:\n",
    "            final_lowerband[curr] = np.nan\n",
    "    \n",
    "    #return pd.DataFrame({\n",
    "    #    'Supertrend': supertrend,\n",
    "    #    'Final Lowerband': final_lowerband,\n",
    "    #    'Final Upperband': final_upperband\n",
    "    #}, index=df.index)\n",
    "\n",
    "    df[\"SUPERTREND\"]=supertrend\n",
    "\n",
    "    return df\n",
    "\n",
    "#_____\n",
    "\n",
    "def suaviPlusDerivates(candlesDataBase_BigQuery):\n",
    "    \n",
    "    global config\n",
    "\n",
    "    #_____UPDATE CONFIG PREDICTION\n",
    "    updateConfig(\"/home/ubuntu/SurfNet/predictionModels/PREDICTION/predictionModels.ini\")\n",
    "\n",
    "    short_ma_hyper=int(get_config(\"PARAMETERS\",\"SHORT_MA_HYPER\"))\n",
    "    short_ma_normal=int(get_config(\"PARAMETERS\",\"SHORT_MA_NORMAL\"))\n",
    "    long_ma_normal=int(get_config(\"PARAMETERS\",\"LONG_MA_NORMAL\"))\n",
    "    long_ma_hyper=int(get_config(\"PARAMETERS\",\"LONG_MA_HYPER\"))\n",
    "    ultra_long_ma_normal=int(get_config(\"PARAMETERS\",\"ULTRA_LONG_MA_NORMAL\"))\n",
    "\n",
    "    #_____VECTOR DE PRECIOS\n",
    "    close_data_df=candlesDataBase_BigQuery.copy()\n",
    "    close_data_df.CLOSE=close_data_df.CLOSE.astype(float)\n",
    "    close_data_df=close_data_df[[\"CLOSE\"]]\n",
    "\n",
    "    #_____SUAVIZACIONES MA & EMA\n",
    "    close_rolling_short_ma_hyper=close_data_df.rolling(short_ma_hyper).mean()\n",
    "    close_rolling_short_ma_normal=close_data_df.rolling(short_ma_normal).mean()\n",
    "    close_rolling_long_ma_normal=close_data_df.ewm(span=long_ma_normal).mean()\n",
    "    close_rolling_long_ma_hyper=close_data_df.ewm(span=long_ma_hyper).mean()\n",
    "    close_rolling_ultra_long_ma_normal=close_data_df.ewm(span=ultra_long_ma_normal).mean()\n",
    "\n",
    "    #_____INSERTAR NUEVAS VARIABLES\n",
    "    candlesDataBase_BigQuery[\"ROLLING_SHORT_MA_HYPER\"]=close_rolling_short_ma_hyper\n",
    "    candlesDataBase_BigQuery[\"ROLLING_SHORT_MA_NORMAL\"]=close_rolling_short_ma_normal\n",
    "    candlesDataBase_BigQuery[\"ROLLING_LONG_MA_NORMAL\"]=close_rolling_long_ma_normal\n",
    "    candlesDataBase_BigQuery[\"ROLLING_LONG_MA_HYPER\"]=close_rolling_long_ma_hyper\n",
    "    candlesDataBase_BigQuery[\"ROLLING_ULTRA_LONG_MA_NORMAL\"]=close_rolling_ultra_long_ma_normal\n",
    "\n",
    "    #_____BOLLINGER\n",
    "    candlesDataBase_BigQuery['15MA'] = candlesDataBase_BigQuery.groupby('MARKET')['CLOSE'].transform(lambda x: x.rolling(window=15).mean())\n",
    "    candlesDataBase_BigQuery['SD'] = candlesDataBase_BigQuery.groupby('MARKET')['CLOSE'].transform(lambda x: x.rolling(window=15).std())\n",
    "    candlesDataBase_BigQuery['UPPERBAND'] = candlesDataBase_BigQuery['15MA'] + 2*candlesDataBase_BigQuery['SD']\n",
    "    candlesDataBase_BigQuery['LOWERBAND'] = candlesDataBase_BigQuery['15MA'] - 2*candlesDataBase_BigQuery['SD']\n",
    "\n",
    "    #_____RATE CHANGE\n",
    "    candlesDataBase_BigQuery['RC'] = candlesDataBase_BigQuery.groupby('MARKET')['CLOSE'].transform(lambda x: x.pct_change(periods = 15))\n",
    "\n",
    "    #_____ELIMINAR DATOS FALTANTES\n",
    "    candlesDataBase_BigQuery.dropna(inplace=True)\n",
    "    candlesDataBase_BigQuery.reset_index(inplace=True,drop=True)\n",
    "\n",
    "    #####\n",
    "\n",
    "    #_____CÁLCULO DE LA PRIMERA DERIVADA\n",
    "    x_CLOSE= np.arange(len(candlesDataBase_BigQuery))\n",
    "    y_spl_CLOSE = UnivariateSpline(x_CLOSE,candlesDataBase_BigQuery[[\"CLOSE\"]],s=0,k=3)\n",
    "    Y_1D_CLOSE=y_spl_CLOSE.derivative(n=1)\n",
    "    Y_1D_CLOSE=pd.DataFrame(Y_1D_CLOSE(x_CLOSE))\n",
    "    candlesDataBase_BigQuery[\"Y_1D_CLOSE\"]=Y_1D_CLOSE\n",
    "\n",
    "    #_____CÁLCULO DE LA PRIMERA DERIVADA\n",
    "    x_ROLLING_SHORT_MA_HYPER= np.arange(len(candlesDataBase_BigQuery))\n",
    "    y_spl_ROLLING_SHORT_MA_HYPER = UnivariateSpline(x_ROLLING_SHORT_MA_HYPER,candlesDataBase_BigQuery[[\"ROLLING_SHORT_MA_HYPER\"]],s=0,k=3)\n",
    "    Y_1D_ROLLING_SHORT_MA_HYPER=y_spl_ROLLING_SHORT_MA_HYPER.derivative(n=1)\n",
    "    Y_1D_ROLLING_SHORT_MA_HYPER=pd.DataFrame(Y_1D_ROLLING_SHORT_MA_HYPER(x_ROLLING_SHORT_MA_HYPER))\n",
    "    candlesDataBase_BigQuery[\"Y_1D_ROLLING_SHORT_MA_HYPER\"]=Y_1D_ROLLING_SHORT_MA_HYPER\n",
    "\n",
    "    #_____CÁLCULO DE LA PRIMERA DERIVADA\n",
    "    x_ROLLING_SHORT_MA_NORMAL= np.arange(len(candlesDataBase_BigQuery))\n",
    "    y_spl_ROLLING_SHORT_MA_NORMAL = UnivariateSpline(x_ROLLING_SHORT_MA_NORMAL,candlesDataBase_BigQuery[[\"ROLLING_SHORT_MA_NORMAL\"]],s=0,k=3)\n",
    "    Y_1D_ROLLING_SHORT_MA_NORMAL=y_spl_ROLLING_SHORT_MA_NORMAL.derivative(n=1)\n",
    "    Y_1D_ROLLING_SHORT_MA_NORMAL=pd.DataFrame(Y_1D_ROLLING_SHORT_MA_NORMAL(x_ROLLING_SHORT_MA_NORMAL))\n",
    "    candlesDataBase_BigQuery[\"Y_1D_ROLLING_SHORT_MA_NORMAL\"]=Y_1D_ROLLING_SHORT_MA_NORMAL\n",
    "\n",
    "    #_____CÁLCULO DE LA PRIMERA DERIVADA\n",
    "    x_ROLLING_LONG_MA_NORMAL= np.arange(len(candlesDataBase_BigQuery))\n",
    "    y_spl_ROLLING_LONG_MA_NORMAL = UnivariateSpline(x_ROLLING_LONG_MA_NORMAL,candlesDataBase_BigQuery[[\"ROLLING_LONG_MA_NORMAL\"]],s=0,k=3)\n",
    "    Y_1D_ROLLING_LONG_MA_NORMAL=y_spl_ROLLING_LONG_MA_NORMAL.derivative(n=1)\n",
    "    Y_1D_ROLLING_LONG_MA_NORMAL=pd.DataFrame(Y_1D_ROLLING_LONG_MA_NORMAL(x_ROLLING_LONG_MA_NORMAL))\n",
    "    candlesDataBase_BigQuery[\"Y_1D_ROLLING_LONG_MA_NORMAL\"]=Y_1D_ROLLING_LONG_MA_NORMAL\n",
    "\n",
    "    #_____CÁLCULO DE LA PRIMERA DERIVADA\n",
    "    x_ROLLING_LONG_MA_HYPER= np.arange(len(candlesDataBase_BigQuery))\n",
    "    y_spl_ROLLING_LONG_MA_HYPER = UnivariateSpline(x_ROLLING_LONG_MA_HYPER,candlesDataBase_BigQuery[[\"ROLLING_LONG_MA_HYPER\"]],s=0,k=3)\n",
    "    Y_1D_ROLLING_LONG_MA_HYPER=y_spl_ROLLING_LONG_MA_HYPER.derivative(n=1)\n",
    "    Y_1D_ROLLING_LONG_MA_HYPER=pd.DataFrame(Y_1D_ROLLING_LONG_MA_HYPER(x_ROLLING_LONG_MA_HYPER))\n",
    "    candlesDataBase_BigQuery[\"Y_1D_ROLLING_LONG_MA_HYPER\"]=Y_1D_ROLLING_LONG_MA_HYPER\n",
    "\n",
    "    #_____CÁLCULO DE LA PRIMERA DERIVADA\n",
    "    x_ROLLING_ULTRA_LONG_MA_NORMAL= np.arange(len(candlesDataBase_BigQuery))\n",
    "    y_spl_ROLLING_ULTRA_LONG_MA_NORMAL = UnivariateSpline(x_ROLLING_ULTRA_LONG_MA_NORMAL,candlesDataBase_BigQuery[[\"ROLLING_ULTRA_LONG_MA_NORMAL\"]],s=0,k=3)\n",
    "    Y_1D_ROLLING_ULTRA_LONG_MA_NORMAL=y_spl_ROLLING_ULTRA_LONG_MA_NORMAL.derivative(n=1)\n",
    "    Y_1D_ROLLING_ULTRA_LONG_MA_NORMAL=pd.DataFrame(Y_1D_ROLLING_ULTRA_LONG_MA_NORMAL(x_ROLLING_ULTRA_LONG_MA_NORMAL))\n",
    "    candlesDataBase_BigQuery[\"Y_1D_ROLLING_ULTRA_LONG_MA_NORMAL\"]=Y_1D_ROLLING_ULTRA_LONG_MA_NORMAL\n",
    "\n",
    "    #####\n",
    "\n",
    "    #_____CALCULAR VARIABLE RSI\n",
    "    RSI_ROLLING_SHORT_MA_HYPER = RSI_GENERAL(pd.Series(list(candlesDataBase_BigQuery.ROLLING_SHORT_MA_HYPER.values)), int(get_config(\"PARAMETERS\",\"RSI_LEN\")))\n",
    "    RSI_ROLLING_SHORT_MA_NORMAL = RSI_GENERAL(pd.Series(list(candlesDataBase_BigQuery.ROLLING_SHORT_MA_NORMAL.values)), int(get_config(\"PARAMETERS\",\"RSI_LEN\")))\n",
    "    RSI_ROLLING_LONG_MA_NORMAL = RSI_GENERAL(pd.Series(list(candlesDataBase_BigQuery.ROLLING_LONG_MA_NORMAL.values)), int(get_config(\"PARAMETERS\",\"RSI_LEN\")))\n",
    "    RSI_ROLLING_LONG_MA_HYPER = RSI_GENERAL(pd.Series(list(candlesDataBase_BigQuery.ROLLING_LONG_MA_HYPER.values)), int(get_config(\"PARAMETERS\",\"RSI_LEN\")))\n",
    "    RSI_ROLLING_ULTRA_LONG_MA_NORMAL = RSI_GENERAL(pd.Series(list(candlesDataBase_BigQuery.ROLLING_ULTRA_LONG_MA_NORMAL.values)), int(get_config(\"PARAMETERS\",\"RSI_LEN\")))\n",
    "\n",
    "    #_____AGRAGAR VARIABLE RSI A BASE DE DATOS\n",
    "    candlesDataBase_BigQuery[\"RSI_ROLLING_SHORT_MA_HYPER\"]=RSI_ROLLING_SHORT_MA_HYPER\n",
    "    candlesDataBase_BigQuery[\"RSI_ROLLING_SHORT_MA_NORMAL\"]=RSI_ROLLING_SHORT_MA_NORMAL\n",
    "    candlesDataBase_BigQuery[\"RSI_ROLLING_LONG_MA_NORMAL\"]=RSI_ROLLING_LONG_MA_NORMAL\n",
    "    candlesDataBase_BigQuery[\"RSI_ROLLING_LONG_MA_HYPER\"]=RSI_ROLLING_LONG_MA_HYPER\n",
    "    candlesDataBase_BigQuery[\"RSI_ROLLING_ULTRA_LONG_MA_NORMAL\"]=RSI_ROLLING_ULTRA_LONG_MA_NORMAL\n",
    "\n",
    "    #_____REESTRUCTURAR BASE DE DATOS\n",
    "    candlesDataBase_BigQuery=candlesDataBase_BigQuery[int(get_config(\"PARAMETERS\",\"ULTRA_LONG_MA_NORMAL\"))+1:]\n",
    "    candlesDataBase_BigQuery.reset_index(inplace=True,drop=True)\n",
    "    \n",
    "    return candlesDataBase_BigQuery\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE CALCULA MACD\n",
    "def LAGS(candlesDataBase_BigQuery):\n",
    "    \n",
    "    for j in list(candlesDataBase_BigQuery.columns)[3:]:\n",
    "        candlesDataBase_BigQuery[j+\"_1\"]=candlesDataBase_BigQuery[j].shift(1)\n",
    "        candlesDataBase_BigQuery[j+\"_2\"]=candlesDataBase_BigQuery[j].shift(2)\n",
    "        candlesDataBase_BigQuery[j+\"_3\"]=candlesDataBase_BigQuery[j].shift(3)\n",
    "        \n",
    "    candlesDataBase_BigQuery.dropna(inplace=True)\n",
    "    candlesDataBase_BigQuery.reset_index(inplace=True,drop=True)\n",
    "        \n",
    "    return candlesDataBase_BigQuery\n",
    "\n",
    "#_____\n",
    "\n",
    "#CREATE VARIABLES\n",
    "def variableCreation(candlesDataBase_BigQuery):\n",
    "    \n",
    "    global fractal\n",
    "    updateConfig(\"/home/ubuntu/SurfNet/predictionModels/PREDICTION/predictionModels.ini\")\n",
    "    \n",
    "    candlesDataBase_BigQuery=RSI(candlesDataBase_BigQuery)\n",
    "    candlesDataBase_BigQuery=MACD(candlesDataBase_BigQuery)\n",
    "    candlesDataBase_BigQuery=fibonacciLevels(candlesDataBase_BigQuery)\n",
    "    candlesDataBase_BigQuery=newVariables(candlesDataBase_BigQuery)\n",
    "    candlesDataBase_BigQuery=superTrend(candlesDataBase_BigQuery, int(get_config(\"PARAMETERS\",\"ATR_PERIOD\")), int(get_config(\"PARAMETERS\",\"ATR_MULTIP\")))\n",
    "    candlesDataBase_BigQuery=suaviPlusDerivates(candlesDataBase_BigQuery)\n",
    "    candlesDataBase_BigQuery=LAGS(candlesDataBase_BigQuery)\n",
    "    \n",
    "    candlesDataBase_BigQuery.dropna(inplace=True)\n",
    "    candlesDataBase_BigQuery.reset_index(inplace=True,drop=True)\n",
    "    \n",
    "    return candlesDataBase_BigQuery\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE ESCALA LAS VARIABLES DEL TEST CON LOS PARÁMETROS DEL TRAIN (MEDIA + SDT)\n",
    "def scaleTestVariables(candlesDataBase_BigQuery):\n",
    "    \n",
    "    global marketDict\n",
    "    \n",
    "    marketDict=readPickleVariable(\"/home/ubuntu/SurfNet/predictionModels/PREDICTION/marketDict\")\n",
    "    \n",
    "    #_____ESCALAR VARIABLES\n",
    "    continuous_variables=list(candlesDataBase_BigQuery.columns)[3:]\n",
    "    marketVariables=list(candlesDataBase_BigQuery.columns)[0:3]\n",
    "\n",
    "    #_____LISTA APPEND DE VARIABLES\n",
    "    listaAppend=[]\n",
    "\n",
    "    for i in continuous_variables:\n",
    "\n",
    "        try:\n",
    "\n",
    "            STD=marketDict[candlesDataBase_BigQuery.at[0,\"MARKET\"]][i][\"STD\"]\n",
    "            MEAN=marketDict[candlesDataBase_BigQuery.at[0,\"MARKET\"]][i][\"MEAN\"]\n",
    "            \n",
    "            candlesDataBase_BigQuery[str(i)] = candlesDataBase_BigQuery[str(i)]-MEAN\n",
    "            candlesDataBase_BigQuery[str(i)] = candlesDataBase_BigQuery[str(i)]/STD\n",
    "            listaAppend.append(i)\n",
    "\n",
    "        except:\n",
    "\n",
    "            pass\n",
    "\n",
    "    candlesDataBase_BigQuery=candlesDataBase_BigQuery[marketVariables+listaAppend]\n",
    "\n",
    "    #_____RETURN\n",
    "    return candlesDataBase_BigQuery\n",
    "    \n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE PREDICE SOBRE LOS DATOS TEST\n",
    "def predictFunction(myData_DataFrame):\n",
    "\n",
    "    global market_Model\n",
    "    global market_Parameters\n",
    "    \n",
    "    #_____COLUMNAS VARIABLE X\n",
    "    continuous_variables=ast.literal_eval(market_Parameters.at[0,\"TRAIN_COLUMNS\"])\n",
    "    \n",
    "    #_____DATOS\n",
    "    X_test=myData_DataFrame.copy()\n",
    "    X_test=X_test[continuous_variables]\n",
    "    X_test=X_test.values\n",
    "    \n",
    "    #_____PREDICTION\n",
    "    prediction = market_Model.predict(np.array(X_test))\n",
    "    \n",
    "    #_____RETURN\n",
    "    return prediction\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE CORRIGE PREDICCIÓN DADO QUE EL PRECIO EN EL QUE ME ENCUENTRO ES MENOR AL PRECIO ANTERIOR\n",
    "def correctPredict(test_sample,PERIODS_EVALUATION_PAST,MAX_PERIODS_EVALUATION_QUANTILE,PERIODS_LINEAREG_BEFORE):\n",
    "    \n",
    "    global myRSI\n",
    "    \n",
    "    #_____ACTUALIZAR CONFIG\n",
    "    updateConfig(\"/home/ubuntu/SurfNet/predictionModels/PREDICTION/predictionModels.ini\")\n",
    "    \n",
    "    #_____VARAIABLE QUE PARAMETRIZA PSADO DE EVALUACIÓN\n",
    "    past_evaluation=PERIODS_EVALUATION_PAST\n",
    "    \n",
    "    #_____QUANLIT DE AVIALUACIÓN DE PRECIO MÁXIMO\n",
    "    max_past_evaluation_quantile=MAX_PERIODS_EVALUATION_QUANTILE\n",
    "    \n",
    "    #_____SI RSI ES MAYOR A THRESHOLD, NO COMPRAR\n",
    "    for i in range(0,len(test_sample)):\n",
    "        if (test_sample.at[i,\"PRED\"]==\"SI\") and (myRSI[i]>float(get_config(\"PARAMETERS\",\"MY_RSI\"))):\n",
    "            test_sample.at[i,\"PRED\"]=\"NO\"\n",
    "    \n",
    "    #_____RECORRER DATOS DE TEST\n",
    "    for i in range(past_evaluation,len(test_sample)):\n",
    "        \n",
    "        #_____SI LA PREDICCIÓN FUE COMPRAR & SI CLOSE ANTERIOR ES MAYOR\n",
    "        if (test_sample.at[i,\"PRED\"]==\"SI\") and (test_sample.at[i,\"CLOSE\"]>=np.quantile(test_sample[i-past_evaluation:i].CLOSE.values,max_past_evaluation_quantile)):\n",
    "            \n",
    "            #_____CONVERTIR OBSERVACIÓN EN NO COMRPAR\n",
    "            test_sample.at[i,\"PRED\"]=\"NO\"\n",
    "            \n",
    "    #_____RECORRER DATOS DE TEST\n",
    "    periods_lineareg=PERIODS_LINEAREG_BEFORE\n",
    "    for i in range(periods_lineareg,len(test_sample)):\n",
    "            \n",
    "        if (test_sample.at[i,\"PRED\"]==\"SI\"):\n",
    "\n",
    "            periods_lineareg=PERIODS_LINEAREG_BEFORE\n",
    "\n",
    "            X=np.arange(periods_lineareg).reshape(-1, 1)\n",
    "            Y=test_sample[i-periods_lineareg:i].CLOSE.values.reshape(-1, 1)\n",
    "\n",
    "            linear_regressor = LinearRegression()\n",
    "            nuevaVariable=linear_regressor.fit(X, Y)\n",
    "            Y_pred = linear_regressor.predict(X)\n",
    "\n",
    "            #_____CORREGIR\n",
    "            if nuevaVariable.coef_ < 0:\n",
    "\n",
    "                #_____CONVERTIR OBSERVACIÓN EN NO COMRPAR\n",
    "                test_sample.at[i,\"PRED\"]=\"NO\"\n",
    "                \n",
    "    #_____REESTRUCTURAR TEST SAMPLE\n",
    "    test_sample=test_sample[max(past_evaluation,periods_lineareg)+1:]\n",
    "    test_sample.reset_index(inplace=True,drop=True)\n",
    "                \n",
    "    return test_sample\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE DECIDE SI COMPRO O NO COMPRO\n",
    "def shouldIMyFriend(fractal):\n",
    "    \n",
    "    global myRSI\n",
    "    global market\n",
    "    global market_Model\n",
    "    global market_Parameters\n",
    "\n",
    "    #_____BIANNCE CANDLES LIST\n",
    "    binanceCandleList=[1,3,5,15,30]\n",
    "\n",
    "    #_____DESCARGAR DATOS DEL MOMENTO\n",
    "    myData = binance.fetch_ohlcv(market,str(min(binanceCandleList, key=lambda x:abs(x-int(fractal))))+\"m\",limit=1000)\n",
    "\n",
    "    #_____CREAR DATAFRAME\n",
    "    myData_DataFrame =pd.DataFrame(columns=[\"ID\",\"TIME\",\"MARKET\",\"OPEN\",\"HIGH\",\"LOW\",\"CLOSE\",\"VOLUME\"])\n",
    "\n",
    "    #_____LLENAR BASE DE DATOS\n",
    "    for i in range(0,len(myData)):\n",
    "        myData_DataFrame.at[i,\"ID\"]=myData[i][0]\n",
    "        myData_DataFrame.at[i,\"TIME\"]=datetime.fromtimestamp(myData[i][0]/1000.0)\n",
    "        myData_DataFrame.at[i,\"MARKET\"]=market\n",
    "        myData_DataFrame.at[i,\"OPEN\"]=myData[i][1]\n",
    "        myData_DataFrame.at[i,\"HIGH\"]=myData[i][2]\n",
    "        myData_DataFrame.at[i,\"LOW\"]=myData[i][3]\n",
    "        myData_DataFrame.at[i,\"CLOSE\"]=myData[i][4]\n",
    "        myData_DataFrame.at[i,\"VOLUME\"]=myData[i][5]\n",
    "\n",
    "    #_____CALCULAR TODAS LAS VARIABLES\n",
    "    myData_DataFrame=variableCreation(myData_DataFrame)\n",
    "    \n",
    "    #_____RSI\n",
    "    myRSI=list(myData_DataFrame.RSI.values)\n",
    "\n",
    "    #_____ESCALAR VARIABLES\n",
    "    myData_DataFrame=scaleTestVariables(myData_DataFrame)\n",
    "\n",
    "    #_____DESCARGAR MODELO DE PREDICCIÓN DEL MERCADO\n",
    "    market_Model=readPickleVariable(\"/home/ubuntu/SurfNet/predictionModels/PREDICTION/train_model\")\n",
    "\n",
    "    #_____DESCARGAR PARÁMETROS DE CORRECCIÓN\n",
    "    market_Parameters=readPickleVariable(\"/home/ubuntu/SurfNet/predictionModels/MODELS/\"+market.replace(\"/\",\"_\")+\"_PARAMETERS\"+\"_\"+fractal)\n",
    "    \n",
    "    #_____PREDECIR\n",
    "    myData_DataFrame[\"PRED\"]=predictFunction(myData_DataFrame)\n",
    "\n",
    "    #_____ASIGNAR VALORES DE CORRECCIÓN\n",
    "    PERIODS_EVALUATION_PAST=int(market_Parameters.at[0,\"PERIODS_EVALUATION_PAST\"])\n",
    "    MAX_PERIODS_EVALUATION_QUANTILE=market_Parameters.at[0,\"MAX_PERIODS_EVALUATION_QUANTILE\"]\n",
    "    PERIODS_LINEAREG_BEFORE=int(market_Parameters.at[0,\"PERIODS_LINEAREG_BEFORE\"])\n",
    "\n",
    "    #_____CORREGIR PREDICCIÓN\n",
    "    myData_DataFrame=correctPredict(myData_DataFrame,PERIODS_EVALUATION_PAST,MAX_PERIODS_EVALUATION_QUANTILE,PERIODS_LINEAREG_BEFORE)\n",
    "\n",
    "    #_____RETURN\n",
    "    if market_Parameters.at[0,\"NET_UTILITY\"]==0:\n",
    "        return \"NO\"\n",
    "    else:\n",
    "        return myData_DataFrame.at[len(myData_DataFrame)-1,\"PRED\"]\n",
    "    \n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE ESTIMA LA CANTIDAD DE DECIMALES A REDONDEAR\n",
    "def marketFloats(value): \n",
    "    Completo = str(value)\n",
    "    Entero= str(math.floor(value))\n",
    "    lenCompleto = len(Completo)\n",
    "    lenEntero = len(Entero)\n",
    "    if lenEntero != lenCompleto:\n",
    "        decimalVector=Completo.split(\".\")\n",
    "        for i in decimalVector[1]:\n",
    "            if i != \"0\":\n",
    "                tengoDecimales=True\n",
    "            else:\n",
    "                tengoDecimales=False\n",
    "        if tengoDecimales:\n",
    "            decimales=lenCompleto-lenEntero-1\n",
    "        else:\n",
    "            decimales=0\n",
    "    else:\n",
    "        decimales = 0\n",
    "    \n",
    "    return decimales\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE SIMULA COMPRA/VENTA MARKET EN BINANCE SEGÚN MERCADO -> SI SIDE==BUY, TRADINGAMOUNT==USDT // SI SIDE==SELL, TRADINGAMOUNT==CRYPTO\n",
    "def simulateMarket(exchange,market,tradingAmount,side):\n",
    "    \n",
    "    global comission\n",
    "    global decimales\n",
    "    \n",
    "    #_____ACTUALIZAR CONFIG\n",
    "    updateConfig('config_surfNet_MonoBot.ini')\n",
    "    \n",
    "    #_____CHECKEAR PARA PRIMERA ITERACIÓN Y EVITAR NAN\n",
    "    if math.isnan(comission):\n",
    "        comission=float(get_config(\"BINANCE\",\"BUY_MARKET_FEE\"))\n",
    "    \n",
    "    #_____ACTUALIZAR ARCHIVO CONFIG\n",
    "    updateConfig('config_surfNet_MonoBot.ini')\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        try:\n",
    "    \n",
    "            #EN CASO DE QUE SEA COMPRA\n",
    "            if side==\"buy\":\n",
    "\n",
    "                #VALIDAR QUE ORDERBOOK ALCANCE PARA HACER LA SIMULACIÓN\n",
    "                while_break=0\n",
    "                while while_break<tradingAmount*1.5:\n",
    "                    #DESCARGAR BUYINGBOOK\n",
    "                    buyingBook=pd.DataFrame(exchange.fetch_order_book(market)[\"asks\"],columns=[\"ASK_VALUE\",\"ASK_SIZE\"])\n",
    "                    buyingBook[\"ASK_PRICE\"]=buyingBook[\"ASK_VALUE\"]*buyingBook[\"ASK_SIZE\"]\n",
    "\n",
    "                    #ACTUALIZAR SUMA DE VOLUMENES DE ORDENES EN ORDERBOOK DESCARGADO\n",
    "                    while_break=sum(buyingBook.ASK_PRICE.values)\n",
    "\n",
    "                    #SI VOLUMEN TOTAL ES MAYOR A LO BUSCADO, SEGUIR CON SIMULACIÓN -> DLC, PRINT + ESPERAR\n",
    "                    if while_break<tradingAmount*1.5:\n",
    "                        print(\"[ERROR]: buyingBook(binance,\"+market+\",\"+str(tradingAmount)+\")\")\n",
    "                        time.sleep(1)\n",
    "\n",
    "                #_____\n",
    "\n",
    "                #SIMULACIÓN DE COMPRA CON USDT -> RETORNA VALOR DE CRYPTO ADQUIRIDO NETO\n",
    "                usdt_used=0\n",
    "                crypto_buyed=0\n",
    "                usdt_used_acum=0\n",
    "                crypto_buyed_acum=0\n",
    "                contador_buying_book=0\n",
    "\n",
    "                while usdt_used_acum<tradingAmount:\n",
    "\n",
    "                    usdt_used=buyingBook.at[contador_buying_book,\"ASK_PRICE\"]\n",
    "                    crypto_buyed=buyingBook.at[contador_buying_book,\"ASK_SIZE\"]\n",
    "                        \n",
    "                    #_____SIMULACIÓN\n",
    "                    if usdt_used_acum+usdt_used < tradingAmount:\n",
    "                        usdt_used_acum=usdt_used_acum+usdt_used\n",
    "                        crypto_buyed_acum=crypto_buyed_acum+crypto_buyed\n",
    "                    else:\n",
    "                        diferencia=tradingAmount-usdt_used_acum\n",
    "                        usdt_used_acum=usdt_used_acum+diferencia\n",
    "\n",
    "                        porcentaje_diferencia=diferencia/usdt_used\n",
    "                        crypto_buyed_acum=crypto_buyed_acum+crypto_buyed*porcentaje_diferencia\n",
    "                        \n",
    "                \n",
    "                #_____REVISAR DECIMALES\n",
    "                decimales=0\n",
    "                for i in range(0,10):\n",
    "                    crypto_buyed=buyingBook.at[i,\"ASK_SIZE\"]\n",
    "                    if marketFloats(crypto_buyed)>decimales:\n",
    "                        decimales=marketFloats(crypto_buyed)\n",
    "\n",
    "                #crypto_buyed_acum=round_decimals_down(crypto_buyed_acum*(1-comission),decimales)\n",
    "                crypto_buyed_acum=round_decimals_down(crypto_buyed_acum,decimales)\n",
    "                \n",
    "                response = crypto_buyed_acum\n",
    "\n",
    "            #_____\n",
    "\n",
    "            #EN CASO DE QUE SEA VENTA\n",
    "            if side==\"sell\":\n",
    "\n",
    "                #VALIDAR QUE ORDERBOOK ALCANCE PARA HACER LA SIMULACIÓN\n",
    "                while_break=0\n",
    "                while while_break<tradingAmount*1.5:\n",
    "                    #DESCARGAR SELLINGBOOK\n",
    "                    sellingBook=pd.DataFrame(exchange.fetch_order_book(market)[\"bids\"],columns=[\"BID_VALUE\",\"BID_SIZE\"])\n",
    "\n",
    "                    #ACTUALIZAR SUMA DE VOLUMENES DE ORDENES EN ORDERBOOK DESCARGADO\n",
    "                    while_break=sum(sellingBook.BID_SIZE.values)\n",
    "\n",
    "                    #SI VOLUMEN TOTAL ES MAYOR A LO BUSCADO, SEGUIR CON SIMULACIÓN -> DLC, PRINT + ESPERAR\n",
    "                    if while_break<tradingAmount*1.5:\n",
    "                        print(\"[ERROR]: buyingBook(\"+exchange.name+\",\"+market+\",\"+str(tradingAmount)+\")\")\n",
    "                        time.sleep(1)\n",
    "\n",
    "                #_____\n",
    "\n",
    "                #INICIALIZAR PARÁMETROS PARA LA SIMULACIÓN\n",
    "                sellAmount=0.0\n",
    "                sellCounter=0\n",
    "                sellPriceACUM=0.0\n",
    "                sellAmountACUM=0.0\n",
    "\n",
    "                #SIMULAR VENTA\n",
    "                while sellAmountACUM<tradingAmount:\n",
    "                    sellAmount=float(sellingBook.at[sellCounter,\"BID_SIZE\"])\n",
    "                    sellAmountACUM=sellAmountACUM+sellAmount\n",
    "                    if sellAmountACUM<tradingAmount:\n",
    "                        sellPriceACUM=sellPriceACUM+(sellAmount*float(sellingBook.iloc[sellCounter,0]))\n",
    "                        sellCounter=sellCounter+1\n",
    "                    else:\n",
    "                        printCRY=sellAmountACUM-sellAmount+tradingAmount-(sellAmountACUM-sellAmount)\n",
    "                        sellPriceACUM=sellPriceACUM+((tradingAmount-(sellAmountACUM-sellAmount))*float(sellingBook.iloc[sellCounter,0]))\n",
    "\n",
    "                response = sellPriceACUM*(1-comission)\n",
    "            \n",
    "            break\n",
    "            \n",
    "        except Exception as e: \n",
    "            print(f\"[ERROR]: simulateMarket() {e}\")\n",
    "            time.sleep(1)\n",
    "            \n",
    "    return response\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE CREA UNA COMPRA TIPO MARKET\n",
    "def createMarketBuy(market,money):\n",
    "    \n",
    "    global amount\n",
    "    global binance\n",
    "    global marketBuyOrder\n",
    "    \n",
    "    amount=simulateMarket(binance,market,money,\"buy\")\n",
    "    marketBuyOrder=binance.create_market_buy_order(symbol=market,amount=amount)\n",
    "            \n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE CREA ORDEN DE COMPRA MARKET Y ACTUALIZA BASE DE DATOS DE TRADEO\n",
    "def buyMyFriend(market,money):\n",
    "    \n",
    "    global decimales\n",
    "    global comission\n",
    "    global row_index\n",
    "    global market_TP\n",
    "    global market_SL\n",
    "    global cryptoAmount\n",
    "    global marketBuyCost\n",
    "    global stopSellPrice\n",
    "    global marketBuyOrder\n",
    "    global marketSellPrice\n",
    "    global binance_machine\n",
    "    global marketBuyOrder_ID\n",
    "    global tradingBook_MonoBot_1\n",
    "    \n",
    "    #_____ACTUALIZAR CONFIG\n",
    "    updateConfig('config_surfNet_MonoBot.ini')\n",
    "    \n",
    "    #_____LEER BASE DE DATOS\n",
    "    tradingBook_MonoBot_1=readPickleVariable(\"tradingBook_MonoBot_1\")\n",
    "\n",
    "    #_____DETERMINAR FILA DE INTEGRACIÓN DE DATOS\n",
    "    row_index=len(tradingBook_MonoBot_1)\n",
    "\n",
    "    #_____CREAR COMPRA MARKET\n",
    "    createMarketBuy(market,money)\n",
    "\n",
    "    #_____AGREGAR DATOS A BASE DE DATOS DE TRADEO\n",
    "    tradingBook_MonoBot_1.at[row_index,\"MACHINE\"]=binance_machine\n",
    "    tradingBook_MonoBot_1.at[row_index,\"TRANSACTION_ID\"]=marketBuyOrder[\"info\"][\"transactTime\"]\n",
    "    tradingBook_MonoBot_1.at[row_index,\"MARKET\"]=market\n",
    "    tradingBook_MonoBot_1.at[row_index,\"BUY_ID\"]=marketBuyOrder[\"id\"]\n",
    "    tradingBook_MonoBot_1.at[row_index,\"DATE_BUY\"]=str(datetime.fromtimestamp(int(marketBuyOrder[\"info\"][\"transactTime\"])/1000))\n",
    "    tradingBook_MonoBot_1.at[row_index,\"BUY_CRYPTO_AMOUNT\"]=float(marketBuyOrder[\"info\"][\"executedQty\"])\n",
    "    \n",
    "    try:\n",
    "        tradingBook_MonoBot_1.at[row_index,\"BUY_FEE\"]=float(marketBuyOrder[\"fee\"][\"cost\"])\n",
    "        tradingBook_MonoBot_1.at[row_index,\"BUY_CURRENCY_FEE\"]=marketBuyOrder[\"fee\"][\"currency\"]\n",
    "    except:\n",
    "        tradingBook_MonoBot_1.at[row_index,\"BUY_FEE\"]=float(get_config(\"BINANCE\",\"BUY_MARKET_FEE\"))*tradingBook_MonoBot_1.at[row_index,\"BUY_CRYPTO_AMOUNT\"]\n",
    "        tradingBook_MonoBot_1.at[row_index,\"BUY_CURRENCY_FEE\"]=market\n",
    "    \n",
    "    \n",
    "    #_____GUARDAR ID PARA FUTURO CRUCE CON VENTA\n",
    "    marketBuyOrder_ID=marketBuyOrder[\"id\"]\n",
    "    \n",
    "    #_____DESCARGAR PARÁMETROS DE ITERACIÓN\n",
    "    market_Parameters=readPickleVariable(\"/home/ubuntu/SurfNet/predictionModels/MODELS/\"+market.replace(\"/\",\"_\")+\"_PARAMETERS\"+\"_\"+get_config(\"ITERATION\",\"BUY_CANDLE\"))\n",
    "    market_TP=float(market_Parameters.at[0,\"TP\"])\n",
    "    market_SL=float(market_Parameters.at[0,\"SL\"])\n",
    "    \n",
    "    #_____ACTUALIZAR CONFIG\n",
    "    updateConfig('config_surfNet_MonoBot.ini')\n",
    "    \n",
    "    #_____ACTUALIZAR PRECIOS DE VENTA\n",
    "    comission=float(get_config(\"BINANCE\",\"BUY_MARKET_FEE\"))\n",
    "    tradingBook_MonoBot_1.at[row_index,\"BUY_FEE_PERCET\"]=comission\n",
    "    tradingBook_MonoBot_1.at[row_index,\"NET_BUY_COST\"]=float(marketBuyOrder[\"cost\"])*(1+comission)\n",
    "    cryptoAmount=tradingBook_MonoBot_1.at[row_index,\"BUY_CRYPTO_AMOUNT\"]\n",
    "    cryptoAmount=round_decimals_down(cryptoAmount,decimales)\n",
    "    marketBuyCost=tradingBook_MonoBot_1.at[row_index,\"NET_BUY_COST\"]\n",
    "    #marketSellPrice=tradingBook_MonoBot_1.at[row_index,\"AVG_BUY_COST\"]*(1+market_TP+comission)\n",
    "    #stopSellPrice=tradingBook_MonoBot_1.at[row_index,\"AVG_BUY_COST\"]*(1-market_SL+comission)\n",
    "    \n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE RETORNA BALANCE USDC EN BINANCE\n",
    "def getCryptoBinance(market):\n",
    "    global binance\n",
    "    \n",
    "    my_market=market.replace(\"/USDT\",\"\")\n",
    "    while True:\n",
    "        try:\n",
    "            return float(binance.fetch_balance()[my_market][\"total\"])\n",
    "            break\n",
    "        except:\n",
    "            print(\"ERROR: getCryptoBinance()\")\n",
    "            time.sleep(1)\n",
    "            \n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE CREA ORDEN MARKET DE VENTA\n",
    "def createMarketSell(market):\n",
    "    \n",
    "    global check\n",
    "    global amount\n",
    "    global binance\n",
    "    global decimales\n",
    "    global cryptoAmount\n",
    "    global marketSellOrder\n",
    "    \n",
    "    check=getCryptoBinance(market)\n",
    "    amount=round_decimals_down(getCryptoBinance(market),decimales)\n",
    "    #marketSellOrder=binance.create_market_sell_order(symbol=market,amount=amount)\n",
    "    #marketSellOrder=binance.create_market_sell_order(symbol=market,amount=cryptoAmount)\n",
    "    try:\n",
    "        marketSellOrder=binance.create_market_sell_order(symbol=market,amount=amount)\n",
    "    except:\n",
    "        if (getCryptoBinance(market)==0) and (type(marketSellOrder)==dict):\n",
    "            pass\n",
    "        else:\n",
    "            ERROR_createMarketSell\n",
    "    \n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE CREA ORDEN DE VENTA MARKET Y ACTUALIZA BASE DE DATOS DE TRADEO\n",
    "def sellMyFriend(market):\n",
    "    \n",
    "    global marketSellOrder\n",
    "    global marketBuyOrder_ID\n",
    "    global tradingBook_MonoBot_1\n",
    "\n",
    "    #_____DETERMINAR FILA DE INTEGRACIÓN DE DATOS\n",
    "    row_index=tradingBook_MonoBot_1.loc[tradingBook_MonoBot_1.BUY_ID==marketBuyOrder_ID].index.values[0]\n",
    "\n",
    "    #_____CREAR VENTA MARKET\n",
    "    createMarketSell(market)\n",
    "\n",
    "    #_____AGREGAR DATOS A BASE DE DATOS DE TRADEO\n",
    "    tradingBook_MonoBot_1.at[row_index,\"SELL_ID\"]=marketSellOrder[\"id\"]\n",
    "    tradingBook_MonoBot_1.at[row_index,\"DATE_SELL\"]=str(datetime.fromtimestamp(int(marketSellOrder[\"info\"][\"transactTime\"])/1000))\n",
    "    tradingBook_MonoBot_1.at[row_index,\"SELL_FEE\"]=float(marketSellOrder[\"fee\"][\"cost\"])\n",
    "    tradingBook_MonoBot_1.at[row_index,\"SELL_CURRENCY_FEE\"]=marketSellOrder[\"fee\"][\"currency\"]\n",
    "    tradingBook_MonoBot_1.at[row_index,\"SELL_CRYPTO_AMOUNT\"]=float(marketSellOrder[\"info\"][\"executedQty\"])\n",
    "    \n",
    "    #_____ACTUALIZAR CONFIG\n",
    "    updateConfig('config_surfNet_MonoBot.ini')\n",
    "    \n",
    "    #_____CALCULAR COMISIÓN\n",
    "    comission=float(get_config(\"BINANCE\",\"BUY_MARKET_FEE\"))\n",
    "    tradingBook_MonoBot_1.at[row_index,\"NET_SELL_COST\"]=float(marketSellOrder[\"cost\"])*(1-comission)\n",
    "    tradingBook_MonoBot_1.at[row_index,\"NET_UTILITY\"]=tradingBook_MonoBot_1.at[row_index,\"NET_SELL_COST\"]/tradingBook_MonoBot_1.at[row_index,\"NET_BUY_COST\"]-1\n",
    "    \n",
    "    #_____ESCRIBIR PICKLE\n",
    "    writePickleVariable(tradingBook_MonoBot_1,\"tradingBook_MonoBot_1\")\n",
    "    \n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE BALANCEA SALDO DE BNB PARA PAGO DE COMISIONES\n",
    "def balanceBNB():\n",
    "\n",
    "    if simulateMarket(binance,\"BNB/USDT\",getCryptoBinance(\"BNB\")/int(get_config(\"ITERATION\",\"MACHINES\")),\"sell\") < myUSDT*0.01:\n",
    "        #_____DECIMALES BNB\n",
    "        buyingBook=pd.DataFrame(binance.fetch_order_book(\"BNB/USDT\")[\"asks\"],columns=[\"ASK_VALUE\",\"ASK_SIZE\"])\n",
    "        decimales=0\n",
    "        for i in range(0,10):\n",
    "            crypto_buyed=buyingBook.at[i,\"ASK_SIZE\"]\n",
    "            if marketFloats(crypto_buyed)>decimales:\n",
    "                decimales=marketFloats(crypto_buyed)\n",
    "        #_____VALIDAR MONTO\n",
    "        amount_BNB=round_decimals_down(simulateMarket(binance,\"BNB/USDT\",max(myUSDT*0.01,11),\"buy\"),decimales)\n",
    "        marketBuyOrder_BNB=binance.create_market_buy_order(symbol=\"BNB/USDT\",amount=amount_BNB)\n",
    "        \n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE ACTUALIZA LOS MERCADOS DISPONIBLES\n",
    "def uptadeAvailableMarkets():\n",
    "\n",
    "    global activeMarkets_List\n",
    "    \n",
    "    #_____LEER MERCADOS ACTIVOS DE LOS DEMÁS BOTS\n",
    "    while True:\n",
    "        try:\n",
    "            activeMarket_1=readPickleVariable(\"activeMarket_1\")\n",
    "            activeMarket_2=readPickleVariable(\"activeMarket_2\")\n",
    "            activeMarket_3=readPickleVariable(\"activeMarket_3\")\n",
    "            activeMarket_4=readPickleVariable(\"activeMarket_4\")\n",
    "            break\n",
    "        except:\n",
    "            time.sleep(1)\n",
    "    \n",
    "    #_____CREAR LISTA DE MERCADOS ACTIVOS\n",
    "    activeMarkets_List=[activeMarket_1,activeMarket_2,activeMarket_3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d416dc27",
   "metadata": {},
   "source": [
    "# PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4921ecec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#_____ACTUALIZAR ARCHIVO CONFIG\n",
    "updateConfig('config_surfNet_MonoBot.ini')\n",
    "\n",
    "#_____BINANCE\n",
    "binance = ccxt.binance()\n",
    "binance.apiKey = get_config('BINANCE', 'API_KEY_4')\n",
    "binance.secret = get_config('BINANCE', 'API_SECRET_4')\n",
    "binance.options['createMarketBuyOrderRequiresPrice'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38d533f",
   "metadata": {},
   "source": [
    "# START"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a2f642f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#_____BASE DE DATOS LIMPIA\n",
    "# tradingBook_MonoBot_4=pd.DataFrame(columns=[\"MACHINE\",\"TRANSACTION_ID\",\"MARKET\",\"BUY_ID\",\"DATE_BUY\",\"SELL_ID\",\"DATE_SELL\",\"BUY_CRYPTO_AMOUNT\",\"NET_BUY_COST\",\"BUY_FEE\",\"BUY_FEE_PERCET\",\"BUY_CURRENCY_FEE\",\"SELL_CRYPTO_AMOUNT\",\"NET_SELL_COST\",\"SELL_FEE\",\"SELL_CURRENCY_FEE\",\"NET_UTILITY\"])\n",
    "# writePickleVariable(tradingBook_MonoBot_4,\"tradingBook_MonoBot_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ead821d",
   "metadata": {},
   "source": [
    "# CHECKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ca80539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #_____ID DE LA MAQUINA\n",
    "# binance_machine=4\n",
    "\n",
    "# #_____ACTUALIZAR CONFIG\n",
    "# updateConfig('config_surfNet_MonoBot.ini')\n",
    "\n",
    "# #_____INICIALIZAR COMISIÓN\n",
    "# comission=float(get_config(\"BINANCE\",\"BUY_MARKET_FEE\"))\n",
    "\n",
    "# #_____COMPRA-VENTA\n",
    "# market=\"ZEC/USDT\"\n",
    "# money=100\n",
    "# buyMyFriend(market,money)\n",
    "# time.sleep(5)\n",
    "# sellMyFriend(market)\n",
    "# tradingBook_MonoBot_4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ed8048",
   "metadata": {},
   "source": [
    "# RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5edbbfc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4901/1223752113.py:535: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  candlesDataBase_BigQuery[j+\"_2\"]=candlesDataBase_BigQuery[j].shift(2)\n",
      "/tmp/ipykernel_4901/1223752113.py:536: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  candlesDataBase_BigQuery[j+\"_3\"]=candlesDataBase_BigQuery[j].shift(3)\n",
      "/tmp/ipykernel_4901/1223752113.py:534: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  candlesDataBase_BigQuery[j+\"_1\"]=candlesDataBase_BigQuery[j].shift(1)\n",
      "/home/ubuntu/anaconda3/lib/python3.8/site-packages/sklearn/base.py:324: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.24.2 when using version 1.0.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/lib/python3.8/site-packages/sklearn/base.py:324: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.24.2 when using version 1.0.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/lib/python3.8/site-packages/sklearn/base.py:324: UserWarning: Trying to unpickle estimator BaggingClassifier from version 0.24.2 when using version 1.0.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['MACD_12', 'MACD_26', 'MACD_12_1', 'MACD_12_2', 'MACD_12_3'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4901/4153418530.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                                 \u001b[0;31m#_____DETERMINAR SI COMPRO O NO COMPRO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m                                 \u001b[0mshouldIMy_List\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshouldIMyFriend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfractal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                             \u001b[0;31m#_____PRINT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_4901/1223752113.py\u001b[0m in \u001b[0;36mshouldIMyFriend\u001b[0;34m(fractal)\u001b[0m\n\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m     \u001b[0;31m#_____PREDECIR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m     \u001b[0mmyData_DataFrame\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"PRED\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredictFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyData_DataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m     \u001b[0;31m#_____ASIGNAR VALORES DE CORRECCIÓN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_4901/1223752113.py\u001b[0m in \u001b[0;36mpredictFunction\u001b[0;34m(myData_DataFrame)\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[0;31m#_____DATOS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[0mX_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmyData_DataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m     \u001b[0mX_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcontinuous_variables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m     \u001b[0mX_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3462\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3463\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3464\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3466\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1312\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1314\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m         if needs_i8_conversion(ax.dtype) or isinstance(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis)\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1377\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['MACD_12', 'MACD_26', 'MACD_12_1', 'MACD_12_2', 'MACD_12_3'] not in index\""
     ]
    }
   ],
   "source": [
    "#_____ID DE LA MAQUINA\n",
    "binance_machine=4\n",
    "\n",
    "#_____ACTUALIZAR CONFIG\n",
    "updateConfig('config_surfNet_MonoBot.ini')\n",
    "\n",
    "#_____INICIALIZAR COMISIÓN\n",
    "comission=float(get_config(\"BINANCE\",\"BUY_MARKET_FEE\"))\n",
    "\n",
    "#_____FRACTAL\n",
    "fractal=\"15\"\n",
    "\n",
    "#_____TEXTO DE MERCADO ACTIVO\n",
    "activeMarket_4=\"\"\n",
    "writePickleVariable(activeMarket_4,\"activeMarket_4\")\n",
    "\n",
    "#_____WHILE INFINITO\n",
    "while True:\n",
    "    \n",
    "    #_____TRY DE CONTINGENCIA\n",
    "    #try:\n",
    "    \n",
    "    #_____CLEAR OUTPUT\n",
    "    clear_output()\n",
    "    \n",
    "    #_____PRINT\n",
    "    uptadeAvailableMarkets()\n",
    "    print(activeMarket_4,activeMarkets_List)\n",
    "    \n",
    "    #_____ACTUALIZAR CONFIG\n",
    "    updateConfig('config_surfNet_MonoBot.ini')\n",
    "    \n",
    "    #_____SI QUIERO APAGARME\n",
    "    if int(get_config(\"ITERATION\",\"SHUTDOWN_4\"))==1:\n",
    "        \n",
    "        #_____TEXTO DE MERCADO ACTIVO\n",
    "        activeMarket_4=\"\"\n",
    "        writePickleVariable(activeMarket_4,\"activeMarket_4\")\n",
    "\n",
    "        #_____BREAK\n",
    "        break\n",
    "\n",
    "    #_____CREAR PORTAFOLIO PARA ITERACIÓN\n",
    "    portfolio=cargarPortafolio()\n",
    "    \n",
    "    #_____SI PORTAFOLIO TIENE POR LO MENOS UN MERCADO ABIERTO\n",
    "    if len(portfolio)>=1:\n",
    "        \n",
    "        #_____EXIT PORTFOLIO\n",
    "        exitPortfolio=0\n",
    "        \n",
    "        for market in list(portfolio.MARKET.values):\n",
    "            \n",
    "            if exitPortfolio==0:\n",
    "            \n",
    "                #_____ACTUALIZAR PORTAFOLIO DE EJECUCIÓN\n",
    "                uptadeAvailableMarkets()\n",
    "\n",
    "                #_____DESCARGAR PARÁMETROS DE CORRECCIÓN\n",
    "                market_Parameters=readPickleVariable(\"/home/ubuntu/SurfNet/predictionModels/MODELS/\"+market.replace(\"/\",\"_\")+\"_PARAMETERS\"+\"_\"+fractal)\n",
    "\n",
    "                #_____RETURN\n",
    "                if market_Parameters.at[0,\"NET_UTILITY\"]!=0:\n",
    "\n",
    "                    #_____SI MERCADO ESTÁ DISPONIBLE\n",
    "                    if market not in activeMarkets_List:\n",
    "\n",
    "                        #_____TEXTO DE MERCADO ACTIVO\n",
    "                        activeMarket_4=market\n",
    "                        writePickleVariable(activeMarket_4,\"activeMarket_4\")\n",
    "\n",
    "                        #_____CLEAR OUTPUT\n",
    "                        clear_output()\n",
    "\n",
    "                        #_____DEFINIR MERCADO\n",
    "                        #market=list(portfolio.MARKET.values)[binance_machine-1]\n",
    "\n",
    "                        #_____ACTUALIZAR CONFIG\n",
    "                        updateConfig('config_surfNet_MonoBot.ini')\n",
    "\n",
    "                        #_____REVISAR PRESUPUESTO\n",
    "                        myUSDT=int(min(round_decimals_down(getUsdtBinance()-float(get_config(\"ITERATION\",\"MIN_INVESTMENT\")),0),float(get_config(\"ITERATION\",\"MIN_INVESTMENT\"))))\n",
    "\n",
    "                        #_____SI CUENTO CON PRESUPUESTO MÍNIMO\n",
    "                        if myUSDT>=float(get_config(\"ITERATION\",\"MIN_INVESTMENT\")):\n",
    "\n",
    "                            #_____AJUSTAR PRESUPUESTO SI TENGO MAS DEL MÁXIMO\n",
    "                            if myUSDT>=float(get_config(\"ITERATION\",\"MAX_INVESTMENT\")):\n",
    "\n",
    "                                #_____NUEVO PRESUPUESTO\n",
    "                                myUSDT=float(get_config(\"ITERATION\",\"MAX_INVESTMENT\"))\n",
    "\n",
    "                            #_____SI MYUSDT ES MAYOR A MI PRESUPUESTO\n",
    "                            if myUSDT>=float(get_config(\"ITERATION\",\"BUDGET\")):\n",
    "\n",
    "                                #_____NUEVO PRESUPUESTO\n",
    "                                myUSDT=float(get_config(\"ITERATION\",\"BUDGET\"))\n",
    "\n",
    "                            #_____UPDATE CONFIG PREDICTION\n",
    "                            updateConfig(\"/home/ubuntu/SurfNet/predictionModels/PREDICTION/predictionModels.ini\")\n",
    "\n",
    "                            #_____LISTA DE RESPUESTAS DE MODELOS\n",
    "                            shouldIMy_List=[]\n",
    "\n",
    "                            #_____LISTA DE FRACTALES\n",
    "                            fractal_List=ast.literal_eval(get_config(\"PARAMETERS\",\"FRACTAL_BUY\"))\n",
    "\n",
    "                            #_____ACTUALIZAR CONFIG\n",
    "                            updateConfig('config_surfNet_MonoBot.ini')\n",
    "\n",
    "                            #_____RECORRER FRACTALES\n",
    "                            for fractal in fractal_List:\n",
    "\n",
    "                                #_____DETERMINAR SI COMPRO O NO COMPRO\n",
    "                                shouldIMy_List.append(shouldIMyFriend(fractal))\n",
    "\n",
    "                            #_____PRINT\n",
    "                            clear_output()\n",
    "                            uptadeAvailableMarkets()\n",
    "                            print(activeMarket_4,activeMarkets_List,shouldIMy_List)\n",
    "\n",
    "                            #_____SI MERCADO ESTÁ DISPONIBLE\n",
    "                            if market not in activeMarkets_List:\n",
    "\n",
    "                                #_____SI DECIDO COMPRAR\n",
    "                                if \"NO\" not in shouldIMy_List:\n",
    "\n",
    "                                    #_____TEXTO DE MERCADO ACTIVO\n",
    "                                    activeMarket_4=market\n",
    "                                    writePickleVariable(activeMarket_4,\"activeMarket_4\")\n",
    "                                    \n",
    "                                    #_____PRINT\n",
    "                                    clear_output()\n",
    "                                    uptadeAvailableMarkets()\n",
    "                                    print(activeMarket_4,activeMarkets_List,shouldIMy_List)\n",
    "\n",
    "                                    #_____CREO COMPRA + VENTA (STOP LOSS) & ACTUALIZO BASE DE DATOS\n",
    "                                    buyMyFriend(market,myUSDT)\n",
    "                                    ejecuto_venta=0\n",
    "\n",
    "                                    #_____NO PARAR HASTA VENDER\n",
    "                                    while ejecuto_venta==0:\n",
    "                                        \n",
    "                                        #_____EXIT PORTFOLIO\n",
    "                                        exitPortfolio=1\n",
    "\n",
    "                                        #_____SLEEP\n",
    "                                        time.sleep(int(get_config(\"ITERATION\",\"SLEEP\")))\n",
    "\n",
    "                                        #_____ACTUALIZAR PRECIO SIMULADO DE VENTA                                                        \n",
    "                                        precio_venta_simulado=simulateMarket(binance,market,cryptoAmount,\"sell\")\n",
    "                                        margenUtilidad=(precio_venta_simulado/marketBuyCost)-1\n",
    "\n",
    "                                        #_____PRINT\n",
    "                                        clear_output()\n",
    "                                        print(market,margenUtilidad)\n",
    "\n",
    "                                        #_____SI MARGEN DE UTILIDAD CALCULADO LLEGA A ALGUNO DE LOS LÍMITES\n",
    "                                        if (margenUtilidad >= market_TP) or (margenUtilidad <= -market_SL):\n",
    "\n",
    "                                            #_____EJECUTAR ORDEN DE VENTA\n",
    "                                            sellMyFriend(market)\n",
    "                                            ejecuto_venta=1\n",
    "\n",
    "                                            #_____CLEAR OUTPUT\n",
    "                                            clear_output()\n",
    "\n",
    "        #_____TEXTO DE MERCADO ACTIVO\n",
    "        activeMarket_4=\"\"\n",
    "        writePickleVariable(activeMarket_4,\"activeMarket_4\")\n",
    "        \n",
    "        #_____PRINT\n",
    "        clear_output()\n",
    "        uptadeAvailableMarkets()\n",
    "        print(activeMarket_4,activeMarkets_List)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        #_____TEXTO DE MERCADO ACTIVO\n",
    "        activeMarket_4=\"\"\n",
    "        writePickleVariable(activeMarket_4,\"activeMarket_4\")\n",
    "        \n",
    "        #_____PRINT\n",
    "        clear_output()\n",
    "        uptadeAvailableMarkets()\n",
    "        print(activeMarket_4,activeMarkets_List)\n",
    "                        \n",
    "    #_____SLEEP\n",
    "    time.sleep(300)\n",
    "    \n",
    "    ##_____EXCEPT DE CONTINGENCIA\n",
    "    #except Exception as e:\n",
    "    #    \n",
    "    #    #_____PRINT\n",
    "    #    print(e)\n",
    "    #    \n",
    "    #    #_____BREAK\n",
    "    #    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
