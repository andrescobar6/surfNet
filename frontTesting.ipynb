{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33cc4c68",
   "metadata": {},
   "source": [
    "# LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9050c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import math\n",
    "import ccxt\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import configparser\n",
    "import pandas as pd\n",
    "import google.cloud\n",
    "from pandas_gbq import gbq\n",
    "import matplotlib.cm as cm\n",
    "from boruta import BorutaPy\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from google.cloud import bigquery\n",
    "from sklearn import preprocessing\n",
    "from IPython.display import clear_output\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#_____\n",
    "\n",
    "pd.set_option('display.max_rows', 5000)\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fba23eb",
   "metadata": {},
   "source": [
    "# FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ae54bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCIÓN QUE LEE EL ARCHIVO CONFIG\n",
    "def get_config(category, key):\n",
    "    \n",
    "    global config\n",
    "    return config[category][key]\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE GENERA CONEXIÓN CON ARCHIVO CONFIG\n",
    "def updateConfig(config_name):\n",
    "    \n",
    "    global config\n",
    "    \n",
    "    config = configparser.ConfigParser()\n",
    "    config.sections()\n",
    "    config.read(config_name)\n",
    "    \n",
    "#_____\n",
    "    \n",
    "#REDONDEAR HACIA ABAJO\n",
    "def round_decimals_down(number:float, decimals:int=2):\n",
    "    \"\"\"\n",
    "    Returns a value rounded down to a specific number of decimal places.\n",
    "    \"\"\"\n",
    "    if not isinstance(decimals, int):\n",
    "        raise TypeError(\"decimal places must be an integer\")\n",
    "    elif decimals < 0:\n",
    "        raise ValueError(\"decimal places has to be 0 or more\")\n",
    "    elif decimals == 0:\n",
    "        return math.floor(number)\n",
    "\n",
    "    factor = 10 ** decimals\n",
    "    return math.floor(number * factor) / factor\n",
    "\n",
    "#_____\n",
    "\n",
    "#REDONDEAR HACIA ARRIBA\n",
    "def round_decimals_up(number:float, decimals:int=2):\n",
    "    \"\"\"\n",
    "    Returns a value rounded down to a specific number of decimal places.\n",
    "    \"\"\"\n",
    "    if not isinstance(decimals, int):\n",
    "        raise TypeError(\"decimal places must be an integer\")\n",
    "    elif decimals < 0:\n",
    "        raise ValueError(\"decimal places has to be 0 or more\")\n",
    "    elif decimals == 0:\n",
    "        return math.ceil(number)\n",
    "\n",
    "    factor = 10 ** decimals\n",
    "    return math.ceil(number * factor) / factor\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE ESCRIBE PICKLE DE VARIABLE\n",
    "def writePickleVariable(variable,variable_name):\n",
    "    pickle_out = open(variable_name+\".pickle\",\"wb\")\n",
    "    pickle.dump(variable, pickle_out)\n",
    "    pickle_out.close()\n",
    "    \n",
    "#_____\n",
    "    \n",
    "#FUNCIÓN QUE LEE PICKLE DE VARIABLE\n",
    "def readPickleVariable(variable_name):    \n",
    "    return pickle.load(open(variable_name+\".pickle\",\"rb\"))\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE DESCARGA BASE DE DATOS DE MERCADO DE BIGQUERY\n",
    "def downloadDataBaseBigQuery(market_model,rows=None):\n",
    "    \n",
    "    #_____GOOGLE CLOUD CONECTION\n",
    "    os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"/home/ubuntu/SurfNet/predictionModels/bigQueryAccess.json\"\n",
    "\n",
    "    #_____SI NO SE DA UN NÚMERO ESPECÍFICO DE FILAS POR PARÁMETRO\n",
    "    if rows==None:\n",
    "    \n",
    "        #_____DESCARGAR BASE DE DATOS\n",
    "        candlesDataBase_BigQuery=gbq.read_gbq(\"SELECT * FROM [dogwood-terra-308100:surfNet.\"+market_model.replace(\"/\",\"_\")+\"_1M] ORDER BY TIME DESC\",project_id=\"dogwood-terra-308100\",dialect=\"legacy\").sort_values(by=\"TIME\")\n",
    "        candlesDataBase_BigQuery.reset_index(inplace=True,drop=True)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        #_____DESCARGAR BASE DE DATOS\n",
    "        candlesDataBase_BigQuery=gbq.read_gbq(\"SELECT * FROM [dogwood-terra-308100:surfNet.\"+market_model.replace(\"/\",\"_\")+\"_1M] ORDER BY TIME DESC LIMIT \"+str(rows),project_id=\"dogwood-terra-308100\",dialect=\"legacy\").sort_values(by=\"TIME\")\n",
    "        candlesDataBase_BigQuery.reset_index(inplace=True,drop=True)\n",
    "\n",
    "    candlesDataBase_BigQuery.OPEN=candlesDataBase_BigQuery.OPEN.astype(float)\n",
    "    candlesDataBase_BigQuery.HIGH=candlesDataBase_BigQuery.HIGH.astype(float)\n",
    "    candlesDataBase_BigQuery.LOW=candlesDataBase_BigQuery.LOW.astype(float)\n",
    "    candlesDataBase_BigQuery.CLOSE=candlesDataBase_BigQuery.CLOSE.astype(float)\n",
    "    candlesDataBase_BigQuery.VOLUME=candlesDataBase_BigQuery.VOLUME.astype(float)\n",
    "    \n",
    "    #_____REESTRUCTURAR BASE DE DATOS\n",
    "    candlesDataBase_BigQuery.reset_index(inplace=True,drop=True)\n",
    "    \n",
    "    #_____RETURN\n",
    "    return candlesDataBase_BigQuery\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE DEVUELVE EL RSI DADO UN PERIODO DETERMINADO\n",
    "def RSI(series, period):\n",
    "    delta = series.diff().dropna()\n",
    "    u = delta * 0\n",
    "    d = u.copy()\n",
    "    u[delta > 0] = delta[delta > 0]\n",
    "    d[delta < 0] = -delta[delta < 0]\n",
    "    u[u.index[period-1]] = np.mean( u[:period] ) #first value is sum of avg gains\n",
    "    u = u.drop(u.index[:(period-1)])\n",
    "    d[d.index[period-1]] = np.mean( d[:period] ) #first value is sum of avg losses\n",
    "    d = d.drop(d.index[:(period-1)])\n",
    "    rs = pd.DataFrame.ewm(u, com=period-1, adjust=False).mean() / \\\n",
    "         pd.DataFrame.ewm(d, com=period-1, adjust=False).mean()\n",
    "    return 100 - 100 / (1 + rs)\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE CREA LAS VARIABLES SOBRE UNA BASE DE DATOS DADA\n",
    "def variableCreation(candlesDataBase_BigQuery):\n",
    "    \n",
    "    global config\n",
    "    \n",
    "    #_____UPDATE CONFIG PREDICTION\n",
    "    updateConfig(\"/home/ubuntu/SurfNet/predictionModels/ETH_FUT_1M/predictionModels_ETH_FUT_1M.ini\")\n",
    "\n",
    "    short_ma_hyper=int(get_config(\"PARAMETERS\",\"SHORT_MA_HYPER\"))\n",
    "    short_ma_normal=int(get_config(\"PARAMETERS\",\"SHORT_MA_NORMAL\"))\n",
    "    long_ma_normal=int(get_config(\"PARAMETERS\",\"LONG_MA_NORMAL\"))\n",
    "    long_ma_hyper=int(get_config(\"PARAMETERS\",\"LONG_MA_HYPER\"))\n",
    "    ultra_long_ma_normal=int(get_config(\"PARAMETERS\",\"ULTRA_LONG_MA_NORMAL\"))\n",
    "\n",
    "    #_____VECTOR DE PRECIOS\n",
    "    close_data_df=candlesDataBase_BigQuery.copy()\n",
    "    close_data_df.CLOSE=close_data_df.CLOSE.astype(float)\n",
    "    close_data_df=close_data_df[[\"CLOSE\"]]\n",
    "\n",
    "    #_____SUAVIZACIONES MA & EMA\n",
    "    close_rolling_short_ma_hyper=close_data_df.rolling(short_ma_hyper).mean()\n",
    "    close_rolling_short_ma_normal=close_data_df.rolling(short_ma_normal).mean()\n",
    "    close_rolling_long_ma_normal=close_data_df.ewm(span=long_ma_normal).mean()\n",
    "    close_rolling_long_ma_hyper=close_data_df.ewm(span=long_ma_hyper).mean()\n",
    "    close_rolling_ultra_long_ma_normal=close_data_df.ewm(span=ultra_long_ma_normal).mean()\n",
    "\n",
    "    #_____INSERTAR NUEVAS VARIABLES\n",
    "    candlesDataBase_BigQuery[\"ROLLING_SHORT_MA_HYPER\"]=close_rolling_short_ma_hyper\n",
    "    candlesDataBase_BigQuery[\"ROLLING_SHORT_MA_NORMAL\"]=close_rolling_short_ma_normal\n",
    "    candlesDataBase_BigQuery[\"ROLLING_LONG_MA_NORMAL\"]=close_rolling_long_ma_normal\n",
    "    candlesDataBase_BigQuery[\"ROLLING_LONG_MA_HYPER\"]=close_rolling_long_ma_hyper\n",
    "    candlesDataBase_BigQuery[\"ROLLING_ULTRA_LONG_MA_NORMAL\"]=close_rolling_ultra_long_ma_normal\n",
    "\n",
    "    #_____ELIMINAR DATOS FALTANTES\n",
    "\n",
    "    candlesDataBase_BigQuery.dropna(inplace=True)\n",
    "    candlesDataBase_BigQuery.reset_index(inplace=True,drop=True)\n",
    "    \n",
    "    #####\n",
    "    \n",
    "    #_____CÁLCULO DE LA PRIMERA DERIVADA\n",
    "    x_CLOSE= np.arange(len(candlesDataBase_BigQuery))\n",
    "    y_spl_CLOSE = UnivariateSpline(x_CLOSE,candlesDataBase_BigQuery[[\"CLOSE\"]],s=0,k=3)\n",
    "    Y_1D_CLOSE=y_spl_CLOSE.derivative(n=1)\n",
    "    Y_1D_CLOSE=pd.DataFrame(Y_1D_CLOSE(x_CLOSE))\n",
    "    candlesDataBase_BigQuery[\"Y_1D_CLOSE\"]=Y_1D_CLOSE\n",
    "\n",
    "    #_____CÁLCULO DE LA PRIMERA DERIVADA\n",
    "    x_ROLLING_SHORT_MA_HYPER= np.arange(len(candlesDataBase_BigQuery))\n",
    "    y_spl_ROLLING_SHORT_MA_HYPER = UnivariateSpline(x_ROLLING_SHORT_MA_HYPER,candlesDataBase_BigQuery[[\"ROLLING_SHORT_MA_HYPER\"]],s=0,k=3)\n",
    "    Y_1D_ROLLING_SHORT_MA_HYPER=y_spl_ROLLING_SHORT_MA_HYPER.derivative(n=1)\n",
    "    Y_1D_ROLLING_SHORT_MA_HYPER=pd.DataFrame(Y_1D_ROLLING_SHORT_MA_HYPER(x_ROLLING_SHORT_MA_HYPER))\n",
    "    candlesDataBase_BigQuery[\"Y_1D_ROLLING_SHORT_MA_HYPER\"]=Y_1D_ROLLING_SHORT_MA_HYPER\n",
    "\n",
    "    #_____CÁLCULO DE LA PRIMERA DERIVADA\n",
    "    x_ROLLING_SHORT_MA_NORMAL= np.arange(len(candlesDataBase_BigQuery))\n",
    "    y_spl_ROLLING_SHORT_MA_NORMAL = UnivariateSpline(x_ROLLING_SHORT_MA_NORMAL,candlesDataBase_BigQuery[[\"ROLLING_SHORT_MA_NORMAL\"]],s=0,k=3)\n",
    "    Y_1D_ROLLING_SHORT_MA_NORMAL=y_spl_ROLLING_SHORT_MA_NORMAL.derivative(n=1)\n",
    "    Y_1D_ROLLING_SHORT_MA_NORMAL=pd.DataFrame(Y_1D_ROLLING_SHORT_MA_NORMAL(x_ROLLING_SHORT_MA_NORMAL))\n",
    "    candlesDataBase_BigQuery[\"Y_1D_ROLLING_SHORT_MA_NORMAL\"]=Y_1D_ROLLING_SHORT_MA_NORMAL\n",
    "\n",
    "    #_____CÁLCULO DE LA PRIMERA DERIVADA\n",
    "    x_ROLLING_LONG_MA_NORMAL= np.arange(len(candlesDataBase_BigQuery))\n",
    "    y_spl_ROLLING_LONG_MA_NORMAL = UnivariateSpline(x_ROLLING_LONG_MA_NORMAL,candlesDataBase_BigQuery[[\"ROLLING_LONG_MA_NORMAL\"]],s=0,k=3)\n",
    "    Y_1D_ROLLING_LONG_MA_NORMAL=y_spl_ROLLING_LONG_MA_NORMAL.derivative(n=1)\n",
    "    Y_1D_ROLLING_LONG_MA_NORMAL=pd.DataFrame(Y_1D_ROLLING_LONG_MA_NORMAL(x_ROLLING_LONG_MA_NORMAL))\n",
    "    candlesDataBase_BigQuery[\"Y_1D_ROLLING_LONG_MA_NORMAL\"]=Y_1D_ROLLING_LONG_MA_NORMAL\n",
    "\n",
    "    #_____CÁLCULO DE LA PRIMERA DERIVADA\n",
    "    x_ROLLING_LONG_MA_HYPER= np.arange(len(candlesDataBase_BigQuery))\n",
    "    y_spl_ROLLING_LONG_MA_HYPER = UnivariateSpline(x_ROLLING_LONG_MA_HYPER,candlesDataBase_BigQuery[[\"ROLLING_LONG_MA_HYPER\"]],s=0,k=3)\n",
    "    Y_1D_ROLLING_LONG_MA_HYPER=y_spl_ROLLING_LONG_MA_HYPER.derivative(n=1)\n",
    "    Y_1D_ROLLING_LONG_MA_HYPER=pd.DataFrame(Y_1D_ROLLING_LONG_MA_HYPER(x_ROLLING_LONG_MA_HYPER))\n",
    "    candlesDataBase_BigQuery[\"Y_1D_ROLLING_LONG_MA_HYPER\"]=Y_1D_ROLLING_LONG_MA_HYPER\n",
    "\n",
    "    #_____CÁLCULO DE LA PRIMERA DERIVADA\n",
    "    x_ROLLING_ULTRA_LONG_MA_NORMAL= np.arange(len(candlesDataBase_BigQuery))\n",
    "    y_spl_ROLLING_ULTRA_LONG_MA_NORMAL = UnivariateSpline(x_ROLLING_ULTRA_LONG_MA_NORMAL,candlesDataBase_BigQuery[[\"ROLLING_ULTRA_LONG_MA_NORMAL\"]],s=0,k=3)\n",
    "    Y_1D_ROLLING_ULTRA_LONG_MA_NORMAL=y_spl_ROLLING_ULTRA_LONG_MA_NORMAL.derivative(n=1)\n",
    "    Y_1D_ROLLING_ULTRA_LONG_MA_NORMAL=pd.DataFrame(Y_1D_ROLLING_ULTRA_LONG_MA_NORMAL(x_ROLLING_ULTRA_LONG_MA_NORMAL))\n",
    "    candlesDataBase_BigQuery[\"Y_1D_ROLLING_ULTRA_LONG_MA_NORMAL\"]=Y_1D_ROLLING_ULTRA_LONG_MA_NORMAL\n",
    "    \n",
    "    #####\n",
    "\n",
    "    #_____CALCULAR VARIABLE RSI\n",
    "    RSI_CLOSE = RSI(pd.Series(list(candlesDataBase_BigQuery.CLOSE.values)), int(get_config(\"PARAMETERS\",\"RSI_LEN\")))\n",
    "    RSI_ROLLING_SHORT_MA_HYPER = RSI(pd.Series(list(candlesDataBase_BigQuery.ROLLING_SHORT_MA_HYPER.values)), int(get_config(\"PARAMETERS\",\"RSI_LEN\")))\n",
    "    RSI_ROLLING_SHORT_MA_NORMAL = RSI(pd.Series(list(candlesDataBase_BigQuery.ROLLING_SHORT_MA_NORMAL.values)), int(get_config(\"PARAMETERS\",\"RSI_LEN\")))\n",
    "    RSI_ROLLING_LONG_MA_NORMAL = RSI(pd.Series(list(candlesDataBase_BigQuery.ROLLING_LONG_MA_NORMAL.values)), int(get_config(\"PARAMETERS\",\"RSI_LEN\")))\n",
    "    RSI_ROLLING_LONG_MA_HYPER = RSI(pd.Series(list(candlesDataBase_BigQuery.ROLLING_LONG_MA_HYPER.values)), int(get_config(\"PARAMETERS\",\"RSI_LEN\")))\n",
    "    RSI_ROLLING_ULTRA_LONG_MA_NORMAL = RSI(pd.Series(list(candlesDataBase_BigQuery.ROLLING_ULTRA_LONG_MA_NORMAL.values)), int(get_config(\"PARAMETERS\",\"RSI_LEN\")))\n",
    "\n",
    "    #_____AGRAGAR VARIABLE RSI A BASE DE DATOS\n",
    "    candlesDataBase_BigQuery[\"RSI_CLOSE\"]=RSI_CLOSE\n",
    "    candlesDataBase_BigQuery[\"RSI_ROLLING_SHORT_MA_HYPER\"]=RSI_ROLLING_SHORT_MA_HYPER\n",
    "    candlesDataBase_BigQuery[\"RSI_ROLLING_SHORT_MA_NORMAL\"]=RSI_ROLLING_SHORT_MA_NORMAL\n",
    "    candlesDataBase_BigQuery[\"RSI_ROLLING_LONG_MA_NORMAL\"]=RSI_ROLLING_LONG_MA_NORMAL\n",
    "    candlesDataBase_BigQuery[\"RSI_ROLLING_LONG_MA_HYPER\"]=RSI_ROLLING_LONG_MA_HYPER\n",
    "    candlesDataBase_BigQuery[\"RSI_ROLLING_ULTRA_LONG_MA_NORMAL\"]=RSI_ROLLING_ULTRA_LONG_MA_NORMAL\n",
    "    \n",
    "    #####\n",
    "\n",
    "    #_____CREAR VARIABLE MACD\n",
    "    macd_12 = close_data_df.ewm(span=int(get_config(\"PARAMETERS\",\"MACD_SHORT\")), adjust=False).mean()\n",
    "    macd_26 = close_data_df.ewm(span=int(get_config(\"PARAMETERS\",\"MACD_LONG\")), adjust=False).mean()\n",
    "    macd = macd_12 - macd_26\n",
    "    macd_9 = macd.ewm(span=int(get_config(\"PARAMETERS\",\"MACD_TRIGGER\")), adjust=False).mean()\n",
    "\n",
    "    #_____AGREGAR VARIABLES A LA BASE DE DATOS\n",
    "    candlesDataBase_BigQuery[\"MACD\"]=macd\n",
    "    candlesDataBase_BigQuery[\"MACD_TRIGGER\"]=macd_9\n",
    "    \n",
    "    #_____REESTRUCTURAR BASE DE DATOS\n",
    "    candlesDataBase_BigQuery=candlesDataBase_BigQuery[int(get_config(\"PARAMETERS\",\"ULTRA_LONG_MA_NORMAL\"))+1:]\n",
    "    candlesDataBase_BigQuery.reset_index(inplace=True,drop=True)\n",
    "    \n",
    "    return candlesDataBase_BigQuery\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE ESCALA LAS VARIABLES CONTINUAS DE LA BASE DE DATOS\n",
    "def scaleVariables(candlesDataBase_BigQuery):\n",
    "    \n",
    "    #_____ESCALAR VARIABLES\n",
    "    continuous_variables=list(candlesDataBase_BigQuery.columns)\n",
    "\n",
    "    scaler=preprocessing.StandardScaler(with_mean=True).fit(np.array(candlesDataBase_BigQuery[continuous_variables]))\n",
    "    scaled_data=pd.DataFrame(scaler.transform(candlesDataBase_BigQuery[continuous_variables]))\n",
    "    scaled_data.columns=continuous_variables\n",
    "\n",
    "    for var in continuous_variables:\n",
    "        candlesDataBase_BigQuery[str(var)] = scaled_data[str(var)]\n",
    "    \n",
    "    #_____RETURN\n",
    "    return candlesDataBase_BigQuery\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE PREDICE SOBRE LOS DATOS TEST\n",
    "def predictFunction(candlesDataBase_Actual,market_model):\n",
    "\n",
    "    #_____DESCARGAR MODELO\n",
    "    train_model=readPickleVariable(\"/home/ubuntu/SurfNet/predictionModels/MODELS/ETH_1M/TRAIN_MODEL_\"+market_model.replace(\"/\",\"_\")+\"_1M\")\n",
    "    \n",
    "    #_____DATOS\n",
    "    X_test=candlesDataBase_Actual.copy()\n",
    "    X_test=X_test.values\n",
    "    \n",
    "    #_____PREDICTION\n",
    "    prediction = train_model.predict(np.array(X_test))\n",
    "    \n",
    "    #_____RETURN\n",
    "    return prediction\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE NOS DE AUTORIZACIÓN DE COMPRA EN MARKET MODEL\n",
    "def autorizarCompra(market_model):\n",
    "    \n",
    "    #_____ACTUALIZAR ARCHIVO CONFIG\n",
    "    updateConfig('frontTesting_ETH_FUT_1M_05K.ini')\n",
    "    \n",
    "    #_____CREAR BASE DE DATOS DE OBSERVACIÓN\n",
    "    candlesDataBase_Binance = binance.fetch_ohlcv(market_model,\"1m\",limit=1000)\n",
    "    candlesDataBase_Actual = pd.DataFrame(columns=[\"ID\",\"TIME\",\"MARKET\",\"OPEN\",\"HIGH\",\"LOW\",\"CLOSE\",\"VOLUME\"])\n",
    "\n",
    "    for i in range(0,len(candlesDataBase_Binance)):\n",
    "        candlesDataBase_Actual.at[i,\"ID\"]=candlesDataBase_Binance[i][0]\n",
    "        candlesDataBase_Actual.at[i,\"TIME\"]=datetime.fromtimestamp(candlesDataBase_Binance[i][0]/1000.0)\n",
    "        candlesDataBase_Actual.at[i,\"MARKET\"]=market_model\n",
    "        candlesDataBase_Actual.at[i,\"OPEN\"]=candlesDataBase_Binance[i][1]\n",
    "        candlesDataBase_Actual.at[i,\"HIGH\"]=candlesDataBase_Binance[i][2]\n",
    "        candlesDataBase_Actual.at[i,\"LOW\"]=candlesDataBase_Binance[i][3]\n",
    "        candlesDataBase_Actual.at[i,\"CLOSE\"]=candlesDataBase_Binance[i][4]\n",
    "        candlesDataBase_Actual.at[i,\"VOLUME\"]=candlesDataBase_Binance[i][5]\n",
    "\n",
    "    #_____DAR FORMATO A LAS COLUMNAS DE LA BASE DE DATOS CREADA\n",
    "    candlesDataBase_Actual[\"ID\"]=candlesDataBase_Actual[\"ID\"].astype(str)\n",
    "    candlesDataBase_Actual[\"TIME\"]=pd.to_datetime(candlesDataBase_Actual[\"TIME\"])\n",
    "    candlesDataBase_Actual[\"MARKET\"]=candlesDataBase_Actual[\"MARKET\"].astype(str)\n",
    "    candlesDataBase_Actual[\"OPEN\"]=candlesDataBase_Actual[\"OPEN\"].astype(float)\n",
    "    candlesDataBase_Actual[\"HIGH\"]=candlesDataBase_Actual[\"HIGH\"].astype(float)\n",
    "    candlesDataBase_Actual[\"LOW\"]=candlesDataBase_Actual[\"LOW\"].astype(float)\n",
    "    candlesDataBase_Actual[\"CLOSE\"]=candlesDataBase_Actual[\"CLOSE\"].astype(float)\n",
    "    \n",
    "    #_____DESCARGAR 10.000 DATOS DE GOOGLE CLOUD\n",
    "    candlesDataBase_BigQuery=downloadDataBaseBigQuery(market_model,rows=int(get_config(\"FRONTTESTING\",\"BIGQUERY_ROWS\")))\n",
    "\n",
    "    #_____UNIR BASE DE DATOS BIGQUERY CON BASE DE DATOS ACTUAL + QUITAR DUPLICADOS\n",
    "    candlesDataBase_BigQuery=candlesDataBase_BigQuery.append(candlesDataBase_Actual)\n",
    "    candlesDataBase_BigQuery.reset_index(inplace=True,drop=True)\n",
    "    candlesDataBase_BigQuery.drop_duplicates(subset=[\"ID\"],inplace=True)\n",
    "    candlesDataBase_BigQuery.reset_index(inplace=True,drop=True)\n",
    "\n",
    "    #_____CREAR VARIABLES INPUT\n",
    "    candlesDataBase_BigQuery=variableCreation(candlesDataBase_BigQuery)\n",
    "\n",
    "    #_____SELECCIONAR VARIABLES NECESARIAS PARA CORRER EL MODELO\n",
    "    variableList=readPickleVariable(\"/home/ubuntu/SurfNet/predictionModels/MODELS/ETH_1M/COLUMNS_\"+market_model.replace(\"/\",\"_\")+\"_1M\")[3:-1]\n",
    "    candlesDataBase_BigQuery=candlesDataBase_BigQuery[variableList]\n",
    "\n",
    "    #_____ESCALAR VARIABLES SELECCIONADAS\n",
    "    candlesDataBase_BigQuery=scaleVariables(candlesDataBase_BigQuery)\n",
    "\n",
    "    #_____PREDECIR COMPRA O NO-COMPRA\n",
    "    candlesDataBase_BigQuery[\"PRED\"]=predictFunction(candlesDataBase_BigQuery,market_model)\n",
    "    prediction_Actual=candlesDataBase_BigQuery.at[len(candlesDataBase_BigQuery)-1,\"PRED\"]\n",
    "    \n",
    "#     #_____SI LA PREDICCIÓN ME DICE QUE COMPRE\n",
    "#     if prediction_Actual==\"SI\":\n",
    "        \n",
    "#         #_____CREAR BASE DE DATOS DE CLOSE PRICE\n",
    "#         candles = binance.fetch_ohlcv(market_model, \"1m\",limit=1000)\n",
    "#         close_data = []\n",
    "#         for candle in candles:\n",
    "#             close_data.append(candle[4])\n",
    "#         close_data_df=pd.DataFrame(close_data,columns=[\"CLOSE\"])\n",
    "\n",
    "#         #_____HACER SUAVIZACIÓN NORMAL A CLOSE PRICE\n",
    "#         last_minute_short=close_data_df.rolling(int(get_config(\"FRONTTESTING\",\"ROLLING\"))).mean()[-int(get_config(\"FRONTTESTING\",\"TAIL\")):]\n",
    "#         last_minute_short.reset_index(inplace=True,drop=True)\n",
    "\n",
    "#         #_____HALLAR PROPORCIÓN DE DATOS MENORES A VALOR ACTUAL\n",
    "#         contador_close=0\n",
    "#         for close in range(0,len(last_minute_short)):\n",
    "#             if last_minute_short.at[len(last_minute_short)-1,\"CLOSE\"]>last_minute_short.at[close,\"CLOSE\"]:\n",
    "#                 contador_close=contador_close+1\n",
    "\n",
    "#         #_____SI LA OBSERVACIÓN ACTUAL MUESTRA UN CRECIMIENTO RESPECTO A LAS ANTERIORES OBSERVACIONES\n",
    "#         if contador_close/len(last_minute_short) < float(get_config(\"FRONTTESTING\",\"PROPORTION\")):\n",
    "#             prediction_Actual=\"NO\"\n",
    "#         else:\n",
    "#             prediction_Actual=\"SI\"\n",
    "    \n",
    "    return prediction_Actual\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE AUTORIZA VENTA\n",
    "def autorizarVenta(market_model):\n",
    "    \n",
    "    global config\n",
    "    global index_row\n",
    "    global tradingBook\n",
    "    global netSellPrice\n",
    "    global netBuyAmount\n",
    "    global markets_Utility\n",
    "    global possibleUtility\n",
    "    global sellAuthorization\n",
    "    \n",
    "    #_____ACTUALIZAR ARCHIVO CONFIG\n",
    "    updateConfig('frontTesting_ETH_FUT_1M_05K.ini')\n",
    "\n",
    "    #_____SIMULAR VENTA EN MERCADO SELECCIONADO CON CRYPTOS OBTENIDAS\n",
    "    netSellPrice=simulateMarketSellCrypto(netBuyAmount,market_model)\n",
    "\n",
    "    #_____CALCULAR UTILIDAD A OBTENER\n",
    "    possibleUtility=round_decimals_down(netSellPrice/float(get_config(\"FRONTTESTING\",\"BUDGET\"))-1,6)\n",
    "\n",
    "    #____IMPRIMIR RESULTADO PARCIAL\n",
    "    tradingBook.at[index_row,\"NET_SELL_PRICE\"]=netSellPrice\n",
    "    tradingBook.at[index_row,\"NET_UTILITY\"]=possibleUtility\n",
    "    \n",
    "    #____IMPRIMIR RESULTADO PARCIAL\n",
    "    print(tradingBook[-1:])\n",
    "    print(\"\")\n",
    "    print(\"[[UTILITY]]\")\n",
    "    print(markets_Utility)\n",
    "    \n",
    "    #_____SI DECIDO USAR O NO DATOS DE BACKTESTING\n",
    "    if int(get_config(\"FRONTTESTING\",\"BACKTESTING\"))==0:\n",
    "        UTILITY_THRESHOLD=float(get_config(\"FRONTTESTING\",\"UTILITY_THRESHOLD\"))\n",
    "        STOPLOSS_THRESHOLD=float(get_config(\"FRONTTESTING\",\"STOPLOSS_THRESHOLD\"))\n",
    "    else:\n",
    "        UTILITY_THRESHOLD=readPickleVariable(\"/home/ubuntu/SurfNet/predictionModels/MODELS/ETH_1M/TAKEPROF_\"+market_model.replace(\"/\",\"_\")+\"_1M\")\n",
    "        STOPLOSS_THRESHOLD=readPickleVariable(\"/home/ubuntu/SurfNet/predictionModels/MODELS/ETH_1M/STOPLOSS_\"+market_model.replace(\"/\",\"_\")+\"_1M\")\n",
    "\n",
    "    #_____SI LA ALCANZA YA SEA EL TOPE ESTIPULADO O STOP-LOSS\n",
    "    if (possibleUtility >= UTILITY_THRESHOLD) or (possibleUtility <= STOPLOSS_THRESHOLD):\n",
    "\n",
    "        #_____ACTUALIZAR VARIABLE VENTA\n",
    "        sellAuthorization=1\n",
    "\n",
    "    #_____SI NO LA ALCANZA TOPES\n",
    "    else:\n",
    "\n",
    "        #_____ACTUALIZAR VARIABLE VENTA\n",
    "        sellAuthorization=0\n",
    "        \n",
    "    #_____RETURN\n",
    "    return sellAuthorization\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE SIMULA COMPRA DE CRYPTO CON FIAT/USDT\n",
    "def simulateMarketBuyCrypto(tradingAmount,market_model):\n",
    "\n",
    "    global config\n",
    "    global binance\n",
    "    \n",
    "    #_____ACTUALIZAR ARCHIVO CONFIG\n",
    "    updateConfig('frontTesting_ETH_FUT_1M_05K.ini')\n",
    "\n",
    "    #_____VALIDAR QUE ORDERBOOK ALCANCE PARA HACER LA SIMULACIÓN\n",
    "    while_break=0\n",
    "    while while_break<tradingAmount*1.5:\n",
    "\n",
    "        #_____DESCARGAR BUYINGBOOK\n",
    "        buyingBook=pd.DataFrame(binance.fetch_order_book(market_model)[\"asks\"],columns=[\"ASK_VALUE\",\"ASK_SIZE\"])\n",
    "        buyingBook[\"ASK_PRICE\"]=buyingBook[\"ASK_VALUE\"]*buyingBook[\"ASK_SIZE\"]\n",
    "\n",
    "        #_____ACTUALIZAR SUMA DE VOLUMENES DE ORDENES EN ORDERBOOK DESCARGADO\n",
    "        while_break=sum(buyingBook.ASK_PRICE.values)\n",
    "\n",
    "        #_____SI VOLUMEN TOTAL ES MAYOR A LO BUSCADO, SEGUIR CON SIMULACIÓN -> DLC, PRINT + ESPERAR\n",
    "        if while_break<tradingAmount*1.5:\n",
    "            print(\"[ERROR]: simulateMarketBuyCrypto()\")\n",
    "            time.sleep(int(get_config(\"FRONTTESTING\",\"TIME_SLEEP\")))\n",
    "\n",
    "    #_____SIMULACIÓN DE COMPRA CON USDT -> RETORNA VALOR DE CRYPTO ADQUIRIDO NETO\n",
    "    usdt_used=0\n",
    "    crypto_buyed=0\n",
    "    usdt_used_acum=0\n",
    "    crypto_buyed_acum=0\n",
    "    contador_buying_book=0\n",
    "\n",
    "    while usdt_used_acum<tradingAmount:\n",
    "\n",
    "        usdt_used=buyingBook.at[contador_buying_book,\"ASK_PRICE\"]\n",
    "        crypto_buyed=buyingBook.at[contador_buying_book,\"ASK_SIZE\"]\n",
    "\n",
    "        if usdt_used_acum+usdt_used < tradingAmount:\n",
    "            usdt_used_acum=usdt_used_acum+usdt_used\n",
    "            crypto_buyed_acum=crypto_buyed_acum+crypto_buyed\n",
    "            contador_buying_book=contador_buying_book+1\n",
    "        else:\n",
    "            diferencia=tradingAmount-usdt_used_acum\n",
    "            usdt_used_acum=usdt_used_acum+diferencia\n",
    "\n",
    "            porcentaje_diferencia=diferencia/usdt_used\n",
    "            crypto_buyed_acum=crypto_buyed_acum+crypto_buyed*porcentaje_diferencia\n",
    "\n",
    "    return crypto_buyed_acum*(1-float(get_config(\"FRONTTESTING\",\"BUY_FEE\")))\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE SIMULA ORDEN MARKET DE VENTA EN KRAKEN BTC-USDC\n",
    "def simulateMarketSellCrypto(tradingAmount,market_model):\n",
    "    \n",
    "    global config\n",
    "    global binance\n",
    "    \n",
    "    #_____ACTUALIZAR ARCHIVO CONFIG\n",
    "    updateConfig('frontTesting_ETH_FUT_1M_05K.ini')\n",
    "\n",
    "    #_____VARIABLES\n",
    "    sellAmount=0.0\n",
    "    sellCounter=0\n",
    "    sellPriceACUM=0.0\n",
    "    sellAmountACUM=0.0\n",
    "\n",
    "    #_____VALIDAR QUE ORDERBOOK ALCANCE PARA HACER LA SIMULACIÓN\n",
    "    while_break=0\n",
    "    while while_break<tradingAmount*1.5:\n",
    "\n",
    "        sellingBook=pd.DataFrame(binance.fetch_order_book(market_model)[\"bids\"],columns=[\"BID_VALUE\",\"BID_SIZE\"])\n",
    "\n",
    "        #ACTUALIZAR SUMA DE VOLUMENES DE ORDENES EN ORDERBOOK DESCARGADO\n",
    "        while_break=sum(list(sellingBook.BID_SIZE.values))\n",
    "\n",
    "        #SI VOLUMEN TOTAL ES MAYOR A LO BUSCADO, SEGUIR CON SIMULACIÓN -> DLC, PRINT + ESPERAR\n",
    "        if while_break<tradingAmount*1.5:\n",
    "            print(\"[ERROR]: simulateMarketSellCrypto()\")\n",
    "            time.sleep(int(get_config(\"FRONTTESTING\",\"TIME_SLEEP\")))\n",
    "\n",
    "    #_____SIMULAR VENTA\n",
    "    while sellAmountACUM<tradingAmount:\n",
    "        sellAmount=float(sellingBook.iloc[sellCounter,1])\n",
    "        sellAmountACUM=sellAmountACUM+sellAmount\n",
    "        if sellAmountACUM<tradingAmount:\n",
    "            sellPriceACUM=sellPriceACUM+(sellAmount*float(sellingBook.iloc[sellCounter,0]))\n",
    "            sellCounter=sellCounter+1\n",
    "        else:\n",
    "            sellPriceACUM=sellPriceACUM+((tradingAmount-(sellAmountACUM-sellAmount))*float(sellingBook.iloc[sellCounter,0]))\n",
    "            \n",
    "    return sellPriceACUM*(1-float(get_config(\"FRONTTESTING\",\"SELL_FEE\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d43f3e",
   "metadata": {},
   "source": [
    "# PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0630d36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ACTUALIZAR ARCHIVO CONFIG\n",
    "updateConfig('frontTesting_ETH_FUT_1M_05K.ini')\n",
    "\n",
    "#BINANCE\n",
    "binance = ccxt.binance()\n",
    "binance.apiKey = get_config('FRONTTESTING', 'API_KEY')\n",
    "binance.secret = get_config('FRONTTESTING', 'API_SECRET')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75053105",
   "metadata": {},
   "source": [
    "# CHECK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb2a5dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b161b18c",
   "metadata": {},
   "source": [
    "# START"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf9ebb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#_____MARKET MODEL DE PRUEBA\n",
    "market_models=ast.literal_eval(get_config(\"FRONTTESTING\",\"MARKET_MODELS\"))\n",
    "\n",
    "#_____LOOP DE ITERACIÓN\n",
    "for market_model in market_models:\n",
    "    \n",
    "    tradingBook=pd.DataFrame(columns=[\"DATE_BUY\",\"DATE_SELL\",\"MARKET\",\"NET_BUY_PRICE\",\"NET_SELL_PRICE\",\"AMOUNT\",\"NET_UTILITY\"])\n",
    "    writePickleVariable(tradingBook,\"/home/ubuntu/SurfNet/predictionModels/RESULTS/ETH_1M/\"+(\"TRADINGBOOK_\"+market_model.replace(\"/\",\"_\")+\"_1M_05K\").lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73b9a29",
   "metadata": {},
   "source": [
    "# RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c053693",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#_____INICIALIZAR VARIABLES GLOBALES\n",
    "netSellPrice=0\n",
    "netBuyAmount=0\n",
    "possibleUtility=0\n",
    "sellAuthorization=0\n",
    "\n",
    "#_____ACTUALIZAR ARCHIVO CONFIG\n",
    "updateConfig('frontTesting_ETH_FUT_1M_05K.ini')\n",
    "\n",
    "#_____MARKET MODEL DE PRUEBA\n",
    "market_models=ast.literal_eval(get_config(\"FRONTTESTING\",\"MARKET_MODELS\"))\n",
    "\n",
    "#_____UTILIDAD GLOBAL PARA IMPRESIÓN\n",
    "markets_Utility=dict()\n",
    "for key in market_models:\n",
    "    markets_Utility[key]=0.0\n",
    "\n",
    "#_____LOOP INFINITO\n",
    "while True:\n",
    "    \n",
    "    #_____TRY DE CONTINGENCIA\n",
    "    try:\n",
    "    \n",
    "        #_____LOOP DE ITERACIÓN\n",
    "        for market_model in market_models:\n",
    "\n",
    "            #_____LIMPIAR OUTPUT\n",
    "            clear_output()\n",
    "\n",
    "            #_____ACTUALIZAR ARCHIVO CONFIG\n",
    "            updateConfig('frontTesting_ETH_FUT_1M_05K.ini')\n",
    "\n",
    "            #_____DETERMINAR SI COMPRO O NO-COMPRO\n",
    "            buyAuthorization=autorizarCompra(market_model)\n",
    "\n",
    "            #_____PRINT\n",
    "            print(\"MARKET: \"+market_model+\" , \"+\"BUY: \"+buyAuthorization)\n",
    "            print(\"[[UTILITY]]\")\n",
    "            print(markets_Utility)\n",
    "\n",
    "            #_____ACTUALIZAR ARCHIVO CONFIG\n",
    "            updateConfig('frontTesting_ETH_FUT_1M_05K.ini')\n",
    "\n",
    "            #_____SI DECIDO COMPRAR\n",
    "            if buyAuthorization==\"SI\":\n",
    "\n",
    "                #_____SIMULAR COMPRA EN MERCADO SELECCIONADO CON BUDGET PROPUESTO\n",
    "                netBuyAmount=simulateMarketBuyCrypto(float(get_config(\"FRONTTESTING\",\"BUDGET\")),market_model)\n",
    "\n",
    "                #_____LEER BASE DE DATOS TRADING BOOK\n",
    "                tradingBook=readPickleVariable(\"/home/ubuntu/SurfNet/predictionModels/RESULTS/ETH_1M/\"+(\"TRADINGBOOK_\"+market_model.replace(\"/\",\"_\")+\"_1M_05K\").lower())\n",
    "\n",
    "                #_____ASIGNAR POSICIONAMIENTO DE FILAS\n",
    "                index_row=len(tradingBook)\n",
    "\n",
    "                #_____AGREGAR DATOS A BASE DE DATOS TRADE\n",
    "                tradingBook.at[index_row,\"DATE_BUY\"]=(datetime.now()-timedelta(hours=5)).strftime(\"%d/%m/%y %H:%M:%S\")\n",
    "                tradingBook.at[index_row,\"MARKET\"]=market_model.replace(\"/\",\"_\")+\"_1M\"\n",
    "                tradingBook.at[index_row,\"NET_BUY_PRICE\"]=float(get_config(\"FRONTTESTING\",\"BUDGET\"))\n",
    "                tradingBook.at[index_row,\"AMOUNT\"]=netBuyAmount\n",
    "\n",
    "                #_____ACTUALIZAR VARIABLE VENTA\n",
    "                sellAuthorization=0\n",
    "\n",
    "                #_____LOOP INFINITO DE VENTA\n",
    "                while sellAuthorization==0:\n",
    "\n",
    "                    #_____ESPERAR UN TIEMPO\n",
    "                    time.sleep(int(get_config(\"FRONTTESTING\",\"TIME_SLEEP\")))\n",
    "\n",
    "                    #_____LIMPIAR OUTPUT\n",
    "                    clear_output()\n",
    "\n",
    "                    #_____DETERMINAR SI VENDO O NO VENDO\n",
    "                    sellAuthorization = autorizarVenta(market_model)\n",
    "\n",
    "                #_____AGREGAR DATOS A BASE DE DATOS TRADE\n",
    "                tradingBook.at[index_row,\"DATE_SELL\"]=(datetime.now()-timedelta(hours=5)).strftime(\"%d/%m/%y %H:%M:%S\")\n",
    "                tradingBook.at[index_row,\"NET_SELL_PRICE\"]=netSellPrice\n",
    "                tradingBook.at[index_row,\"NET_UTILITY\"]=possibleUtility\n",
    "\n",
    "                #_____EXPORTAR BASE DE DATOS DE COMPRA-VENTA\n",
    "                writePickleVariable(tradingBook,\"/home/ubuntu/SurfNet/predictionModels/RESULTS/ETH_1M/\"+(\"TRADINGBOOK_\"+market_model.replace(\"/\",\"_\")+\"_1M_05K\").lower())\n",
    "\n",
    "                #_____ACTUALIZAR DICCIONARIO DE UTILIDADES\n",
    "                markets_Utility[market_model]=sum(list(tradingBook.NET_UTILITY.values))\n",
    "\n",
    "            #_____ESPERAR UN MOMENTO\n",
    "            time.sleep(int(get_config(\"FRONTTESTING\",\"TIME_SLEEP\")))\n",
    "        \n",
    "    #_____EN CASO DE ERROR\n",
    "    except:\n",
    "        \n",
    "        #_____ESPERAR UN RATO\n",
    "        time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a165035e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tradingBook.to_excel()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
