{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b26fb9e",
   "metadata": {},
   "source": [
    "# LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b29600",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import math\n",
    "import ccxt\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import configparser\n",
    "import pandas as pd\n",
    "import google.cloud\n",
    "from pandas_gbq import gbq\n",
    "import matplotlib.cm as cm\n",
    "from boruta import BorutaPy\n",
    "import statsmodels.api as sm\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from google.cloud import bigquery\n",
    "from sklearn import preprocessing\n",
    "from IPython.display import clear_output\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#_____\n",
    "\n",
    "pd.set_option('display.max_rows', 5000)\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb82d8c",
   "metadata": {},
   "source": [
    "# FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea35eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCIÓN QUE LEE EL ARCHIVO CONFIG\n",
    "def get_config(category, key):\n",
    "    \n",
    "    global config\n",
    "    return config[category][key]\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE GENERA CONEXIÓN CON ARCHIVO CONFIG\n",
    "def updateConfig(config_name):\n",
    "    \n",
    "    global config\n",
    "    \n",
    "    config = configparser.ConfigParser()\n",
    "    config.sections()\n",
    "    config.read(config_name)\n",
    "    \n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE GRAFICA POR COLORES SEGUN COMPRAS Y NO COMRPAS\n",
    "def plot_colourline(x,y,c):\n",
    "    c = c\n",
    "    ax = plt.gca()\n",
    "    for i in np.arange(len(x)-1):\n",
    "        ax.plot([x[i],x[i+1]], [y[i],y[i+1]], c=c[i])\n",
    "    return\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE ESCRIBE PICKLE DE VARIABLE\n",
    "def writePickleVariable(variable,variable_name):\n",
    "    pickle_out = open(variable_name+\".pickle\",\"wb\")\n",
    "    pickle.dump(variable, pickle_out)\n",
    "    pickle_out.close()\n",
    "    \n",
    "#_____\n",
    "    \n",
    "#FUNCIÓN QUE LEE PICKLE DE VARIABLE\n",
    "def readPickleVariable(variable_name):    \n",
    "    return pickle.load(open(variable_name+\".pickle\",\"rb\"))\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE REDONDEA FLOAT HACIA ABAJO SEGÚN DECIMALES\n",
    "def round_decimals_down(number:float, decimals:int=2):\n",
    "    \"\"\"\n",
    "    Returns a value rounded down to a specific number of decimal places.\n",
    "    \"\"\"\n",
    "    if not isinstance(decimals, int):\n",
    "        raise TypeError(\"decimal places must be an integer\")\n",
    "    elif decimals < 0:\n",
    "        raise ValueError(\"decimal places has to be 0 or more\")\n",
    "    elif decimals == 0:\n",
    "        return math.floor(number)\n",
    "\n",
    "    factor = 10 ** decimals\n",
    "    return math.floor(number * factor) / factor\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE REDONDEA FLOAT HACIA ARRIBA SEGÚN DECIMALES\n",
    "def round_decimals_up(number:float, decimals:int=2):\n",
    "    \"\"\"\n",
    "    Returns a value rounded down to a specific number of decimal places.\n",
    "    \"\"\"\n",
    "    if not isinstance(decimals, int):\n",
    "        raise TypeError(\"decimal places must be an integer\")\n",
    "    elif decimals < 0:\n",
    "        raise ValueError(\"decimal places has to be 0 or more\")\n",
    "    elif decimals == 0:\n",
    "        return math.ceil(number)\n",
    "\n",
    "    factor = 10 ** decimals\n",
    "    return math.ceil(number * factor) / factor\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE DESCARGA BASE DE DATOS DE MERCADO DE BIGQUERY\n",
    "def downloadDataBaseBigQuery(market_model,time,rows=None):\n",
    "    \n",
    "    #_____GOOGLE CLOUD CONECTION\n",
    "    os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"/home/ubuntu/SurfNet/predictionModels/PREDICTION/bigQueryAccess.json\"\n",
    "\n",
    "    #_____SI NO SE DA UN NÚMERO ESPECÍFICO DE FILAS POR PARÁMETRO\n",
    "    if rows==None:\n",
    "\n",
    "        #_____DESCARGAR BASE DE DATOS\n",
    "        candlesDataBase_BigQuery=gbq.read_gbq(\"SELECT * FROM [dogwood-terra-308100:surfNet.\"+market_model.replace(\"/\",\"_\")+\"] ORDER BY TIME DESC\",project_id=\"dogwood-terra-308100\",dialect=\"legacy\").sort_values(by=\"TIME\")\n",
    "        candlesDataBase_BigQuery.reset_index(inplace=True,drop=True)\n",
    "\n",
    "    else:\n",
    "\n",
    "        #_____DESCARGAR BASE DE DATOS\n",
    "        candlesDataBase_BigQuery=gbq.read_gbq(\"SELECT * FROM [dogwood-terra-308100:surfNet.\"+market_model.replace(\"/\",\"_\")+\"] ORDER BY TIME DESC LIMIT \"+str(rows),project_id=\"dogwood-terra-308100\",dialect=\"legacy\").sort_values(by=\"TIME\")\n",
    "        candlesDataBase_BigQuery.reset_index(inplace=True,drop=True)\n",
    "\n",
    "    candlesDataBase_BigQuery.OPEN=candlesDataBase_BigQuery.OPEN.astype(float)\n",
    "    candlesDataBase_BigQuery.HIGH=candlesDataBase_BigQuery.HIGH.astype(float)\n",
    "    candlesDataBase_BigQuery.LOW=candlesDataBase_BigQuery.LOW.astype(float)\n",
    "    candlesDataBase_BigQuery.CLOSE=candlesDataBase_BigQuery.CLOSE.astype(float)\n",
    "    candlesDataBase_BigQuery.VOLUME=candlesDataBase_BigQuery.VOLUME.astype(float)\n",
    "\n",
    "    #_____REESTRUCTURAR BASE DE DATOS\n",
    "    candlesDataBase_BigQuery.reset_index(inplace=True,drop=True)\n",
    "\n",
    "    if time != \"1\":\n",
    "\n",
    "        #_____UPDATE CONFIG PREDICTION\n",
    "        updateConfig(\"/home/ubuntu/SurfNet/predictionModels/PREDICTION/predictionModels.ini\")\n",
    "\n",
    "        #_____CREAR COLUMNAS\n",
    "        candlesDataBase_BigQuery_copy=candlesDataBase_BigQuery.copy()\n",
    "        candlesDataBase_BigQuery_copy=candlesDataBase_BigQuery_copy.set_index('TIME')\n",
    "        candlesDataBase_BigQuery_copy_total=candlesDataBase_BigQuery_copy[[\"ID\"]].groupby(pd.Grouper(freq=time+'min', offset=time+'min')).min()\n",
    "        candlesDataBase_BigQuery_copy_total=candlesDataBase_BigQuery_copy_total.join(candlesDataBase_BigQuery_copy[[\"VOLUME\"]].groupby(pd.Grouper(freq=time+'min', offset=time+'min')).sum())\n",
    "        candlesDataBase_BigQuery_copy_total=candlesDataBase_BigQuery_copy_total.join(candlesDataBase_BigQuery_copy[[\"LOW\"]].groupby(pd.Grouper(freq=time+'min', offset=time+'min')).min())\n",
    "        candlesDataBase_BigQuery_copy_total=candlesDataBase_BigQuery_copy_total.join(candlesDataBase_BigQuery_copy[[\"HIGH\"]].groupby(pd.Grouper(freq=time+'min', offset=time+'min')).max())\n",
    "\n",
    "        #_____AGREAR DATOS\n",
    "        for i in list(candlesDataBase_BigQuery_copy_total.index.values):\n",
    "            try:\n",
    "                candlesDataBase_BigQuery_copy_total.at[i,\"OPEN\"]=candlesDataBase_BigQuery.loc[candlesDataBase_BigQuery.TIME==i][\"OPEN\"].values[0]\n",
    "                final_time = i + np.timedelta64(int(time),'m')\n",
    "                if final_time in list(candlesDataBase_BigQuery_copy_total.index.values):\n",
    "                    candlesDataBase_BigQuery_copy_total.at[i,\"CLOSE\"]=candlesDataBase_BigQuery.loc[candlesDataBase_BigQuery.TIME==final_time][\"OPEN\"].values[0]\n",
    "                else:\n",
    "                    candlesDataBase_BigQuery_copy_total.at[i,\"CLOSE\"]=candlesDataBase_BigQuery.at[len(candlesDataBase_BigQuery)-1,\"CLOSE\"]\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        #_____RESET INDEX\n",
    "        candlesDataBase_BigQuery_copy_total.reset_index(level=['TIME'],inplace=True)\n",
    "\n",
    "        #_____COLUMNA MARKET\n",
    "        for i in range(0,len(candlesDataBase_BigQuery_copy_total)):\n",
    "            candlesDataBase_BigQuery_copy_total.at[i,\"MARKET\"]=candlesDataBase_BigQuery.MARKET.values[0]\n",
    "\n",
    "        #_____ORDENAR COLUMNAS\n",
    "        column_names = list(candlesDataBase_BigQuery.columns)\n",
    "        candlesDataBase_BigQuery_copy_total = candlesDataBase_BigQuery_copy_total.reindex(columns=column_names)\n",
    "        candlesDataBase_BigQuery_copy_total.dropna(inplace=True)\n",
    "        candlesDataBase_BigQuery_copy_total.reset_index(inplace=True,drop=True)\n",
    "        candlesDataBase_BigQuery=candlesDataBase_BigQuery_copy_total.copy()\n",
    "\n",
    "    #_____RETURN\n",
    "    return candlesDataBase_BigQuery\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE DEVUELVE EL RSI DADO UN PERIODO DETERMINADO\n",
    "def RSI(candlesDataBase_BigQuery):\n",
    "    \n",
    "    global config\n",
    "    updateConfig(\"/home/ubuntu/SurfNet/predictionModels/PREDICTION/predictionModels.ini\")\n",
    "    \n",
    "    series=pd.Series(list(candlesDataBase_BigQuery.CLOSE.values))\n",
    "    period=int(get_config(\"PARAMETERS\",\"RSI_LEN\"))\n",
    "    \n",
    "    delta = series.diff().dropna()\n",
    "    u = delta * 0\n",
    "    d = u.copy()\n",
    "    u[delta > 0] = delta[delta > 0]\n",
    "    d[delta < 0] = -delta[delta < 0]\n",
    "    u[u.index[period-1]] = np.mean( u[:period] ) #first value is sum of avg gains\n",
    "    u = u.drop(u.index[:(period-1)])\n",
    "    d[d.index[period-1]] = np.mean( d[:period] ) #first value is sum of avg losses\n",
    "    d = d.drop(d.index[:(period-1)])\n",
    "    rs = pd.DataFrame.ewm(u, com=period-1, adjust=False).mean() / \\\n",
    "         pd.DataFrame.ewm(d, com=period-1, adjust=False).mean()\n",
    "    \n",
    "    rsi=100 - 100 / (1 + rs)\n",
    "    \n",
    "    for i in list(rsi.index.values):\n",
    "        candlesDataBase_BigQuery.at[i,\"RSI\"]=rsi[i]\n",
    "                                        \n",
    "    return candlesDataBase_BigQuery\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE DEVUELVE EL RSI DADO UN PERIODO DETERMINADO\n",
    "def RSI_GENERAL(series, period):\n",
    "    delta = series.diff().dropna()\n",
    "    u = delta * 0\n",
    "    d = u.copy()\n",
    "    u[delta > 0] = delta[delta > 0]\n",
    "    d[delta < 0] = -delta[delta < 0]\n",
    "    u[u.index[period-1]] = np.mean( u[:period] ) #first value is sum of avg gains\n",
    "    u = u.drop(u.index[:(period-1)])\n",
    "    d[d.index[period-1]] = np.mean( d[:period] ) #first value is sum of avg losses\n",
    "    d = d.drop(d.index[:(period-1)])\n",
    "    rs = pd.DataFrame.ewm(u, com=period-1, adjust=False).mean() / \\\n",
    "         pd.DataFrame.ewm(d, com=period-1, adjust=False).mean()\n",
    "    return 100 - 100 / (1 + rs)\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE CALCULA MACD\n",
    "def MACD(candlesDataBase_BigQuery):\n",
    "    \n",
    "    global config\n",
    "    updateConfig(\"/home/ubuntu/SurfNet/predictionModels/PREDICTION/predictionModels.ini\")\n",
    "    \n",
    "    close_data_df=candlesDataBase_BigQuery.copy()\n",
    "    close_data_df.CLOSE=close_data_df.CLOSE.astype(float)\n",
    "    close_data_df=close_data_df[[\"CLOSE\"]]\n",
    "    \n",
    "    #_____CREAR VARIABLE MACD\n",
    "    macd_12 = close_data_df.ewm(span=int(get_config(\"PARAMETERS\",\"MACD_SHORT\")), adjust=False).mean()\n",
    "    macd_26 = close_data_df.ewm(span=int(get_config(\"PARAMETERS\",\"MACD_LONG\")), adjust=False).mean()\n",
    "    macd = macd_12 - macd_26\n",
    "    macd_9 = macd.ewm(span=int(get_config(\"PARAMETERS\",\"MACD_TRIGGER\")), adjust=False).mean()\n",
    "\n",
    "    #_____AGREGAR VARIABLES A LA BASE DE DATOS\n",
    "    candlesDataBase_BigQuery[\"MACD\"]=macd\n",
    "    candlesDataBase_BigQuery[\"MACD_\"+get_config(\"PARAMETERS\",\"MACD_SHORT\")]=macd_12\n",
    "    candlesDataBase_BigQuery[\"MACD_\"+get_config(\"PARAMETERS\",\"MACD_LONG\")]=macd_26\n",
    "    candlesDataBase_BigQuery[\"MACD_TRIGGER\"]=macd_9\n",
    "    \n",
    "    return candlesDataBase_BigQuery\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE BRINDA LOS NIVELES DE FIBONACCI\n",
    "def fibonacciLevels(candlesDataBase_BigQuery):\n",
    "    \n",
    "    global config\n",
    "    global fractal\n",
    "    \n",
    "    #_____UPDATE CONFIG PREDICTION\n",
    "    updateConfig(\"/home/ubuntu/SurfNet/predictionModels/PREDICTION/predictionModels.ini\")\n",
    "    \n",
    "    #_____ACTUALIZAR PARÁMETROS\n",
    "    FIBONACCI_PERIOD=int(int(get_config(\"PARAMETERS\",\"FIBONACCI_PERIOD\"))/int(fractal))\n",
    "\n",
    "    #_____RECORRER DATOS DE TEST\n",
    "    for i in range(FIBONACCI_PERIOD,len(candlesDataBase_BigQuery)):\n",
    "        \n",
    "        #_____FIBONACCI\n",
    "        lows=list(candlesDataBase_BigQuery[i-FIBONACCI_PERIOD:i].LOW.values)\n",
    "        highs=list(candlesDataBase_BigQuery[i-FIBONACCI_PERIOD:i].HIGH.values)\n",
    "        Price_Min = min(lows)\n",
    "        Price_Max = max(highs)\n",
    "        Diff = Price_Max-Price_Min\n",
    "        level1 = Price_Max - 0.236 * Diff\n",
    "        level2 = Price_Max - 0.382 * Diff\n",
    "        level3 = Price_Max - 0.618 * Diff\n",
    "        level4 = Price_Max - 0.786 * Diff\n",
    "        \n",
    "        candlesDataBase_BigQuery.at[i,\"FIBO_LEVEL_1\"]=level1\n",
    "        candlesDataBase_BigQuery.at[i,\"FIBO_LEVEL_2\"]=level2\n",
    "        candlesDataBase_BigQuery.at[i,\"FIBO_LEVEL_3\"]=level3\n",
    "        candlesDataBase_BigQuery.at[i,\"FIBO_LEVEL_4\"]=level4\n",
    "            \n",
    "    return candlesDataBase_BigQuery\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE CREA VARIABLES ENCONTRADAS EN ARTÍCULOS\n",
    "def newVariables(candlesDataBase_BigQuery):\n",
    "    \n",
    "    #_____VARIABLES NUEVAS\n",
    "    candlesDataBase_BigQuery['SMA5_VOL'] = candlesDataBase_BigQuery.groupby('MARKET')['VOLUME'].transform(lambda x: x.rolling(window = 5).mean())\n",
    "    candlesDataBase_BigQuery['SMA15_VOL'] = candlesDataBase_BigQuery.groupby('MARKET')['VOLUME'].transform(lambda x: x.rolling(window = 15).mean())\n",
    "    candlesDataBase_BigQuery['SMA_VOL_RATIO'] = candlesDataBase_BigQuery['SMA5_VOL']/candlesDataBase_BigQuery['SMA15_VOL']\n",
    "\n",
    "    #_____VARIABLES NUEVAS\n",
    "    candlesDataBase_BigQuery['LOWEST_5D'] = candlesDataBase_BigQuery.groupby('MARKET')['LOW'].transform(lambda x: x.rolling(window = 5).min())\n",
    "    candlesDataBase_BigQuery['HIGH_5D'] = candlesDataBase_BigQuery.groupby('MARKET')['HIGH'].transform(lambda x: x.rolling(window = 5).max())\n",
    "    candlesDataBase_BigQuery['LOWEST_15D'] = candlesDataBase_BigQuery.groupby('MARKET')['LOW'].transform(lambda x: x.rolling(window = 15).min())\n",
    "    candlesDataBase_BigQuery['HIGH_15D'] = candlesDataBase_BigQuery.groupby('MARKET')['HIGH'].transform(lambda x: x.rolling(window = 15).max())\n",
    "    candlesDataBase_BigQuery['STOCHASTIC_5'] = ((candlesDataBase_BigQuery['CLOSE'] - candlesDataBase_BigQuery['LOWEST_5D'])/(candlesDataBase_BigQuery['HIGH_5D'] - candlesDataBase_BigQuery['LOWEST_5D']))*100\n",
    "    candlesDataBase_BigQuery['STOCHASTIC_15'] = ((candlesDataBase_BigQuery['CLOSE'] - candlesDataBase_BigQuery['LOWEST_15D'])/(candlesDataBase_BigQuery['HIGH_15D'] - candlesDataBase_BigQuery['LOWEST_15D']))*100\n",
    "    candlesDataBase_BigQuery['STOCHASTIC_D_5'] = candlesDataBase_BigQuery['STOCHASTIC_5'].rolling(window = 5).mean()\n",
    "    candlesDataBase_BigQuery['STOCHASTIC_D_15'] = candlesDataBase_BigQuery['STOCHASTIC_5'].rolling(window = 15).mean()\n",
    "    candlesDataBase_BigQuery['STOCHASTIC_RATIO'] = candlesDataBase_BigQuery['STOCHASTIC_D_5']/candlesDataBase_BigQuery['STOCHASTIC_D_15']\n",
    "    \n",
    "    return candlesDataBase_BigQuery\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCIÓN SUPERTREND\n",
    "def superTrend(df, atr_period, multiplier):\n",
    "    \n",
    "    high = df['HIGH']\n",
    "    low = df['LOW']\n",
    "    close = df['CLOSE']\n",
    "    \n",
    "    # calculate ATR\n",
    "    price_diffs = [high - low, \n",
    "                   high - close.shift(), \n",
    "                   close.shift() - low]\n",
    "    true_range = pd.concat(price_diffs, axis=1)\n",
    "    true_range = true_range.abs().max(axis=1)\n",
    "    # default ATR calculation in supertrend indicator\n",
    "    atr = true_range.ewm(alpha=1/atr_period,min_periods=atr_period).mean() \n",
    "    # df['atr'] = df['tr'].rolling(atr_period).mean()\n",
    "    \n",
    "    # HL2 is simply the average of high and low prices\n",
    "    hl2 = (high + low) / 2\n",
    "    # upperband and lowerband calculation\n",
    "    # notice that final bands are set to be equal to the respective bands\n",
    "    final_upperband = upperband = hl2 + (multiplier * atr)\n",
    "    final_lowerband = lowerband = hl2 - (multiplier * atr)\n",
    "    \n",
    "    # initialize Supertrend column to True\n",
    "    supertrend = [True] * len(df)\n",
    "    \n",
    "    for i in range(1, len(df.index)):\n",
    "        curr, prev = i, i-1\n",
    "        \n",
    "        # if current close price crosses above upperband\n",
    "        if close[curr] > final_upperband[prev]:\n",
    "            supertrend[curr] = True\n",
    "        # if current close price crosses below lowerband\n",
    "        elif close[curr] < final_lowerband[prev]:\n",
    "            supertrend[curr] = False\n",
    "        # else, the trend continues\n",
    "        else:\n",
    "            supertrend[curr] = supertrend[prev]\n",
    "            \n",
    "            # adjustment to the final bands\n",
    "            if supertrend[curr] == True and final_lowerband[curr] < final_lowerband[prev]:\n",
    "                final_lowerband[curr] = final_lowerband[prev]\n",
    "            if supertrend[curr] == False and final_upperband[curr] > final_upperband[prev]:\n",
    "                final_upperband[curr] = final_upperband[prev]\n",
    "\n",
    "        # to remove bands according to the trend direction\n",
    "        if supertrend[curr] == True:\n",
    "            final_upperband[curr] = np.nan\n",
    "        else:\n",
    "            final_lowerband[curr] = np.nan\n",
    "    \n",
    "    #return pd.DataFrame({\n",
    "    #    'Supertrend': supertrend,\n",
    "    #    'Final Lowerband': final_lowerband,\n",
    "    #    'Final Upperband': final_upperband\n",
    "    #}, index=df.index)\n",
    "\n",
    "    df[\"SUPERTREND\"]=supertrend\n",
    "\n",
    "    return df\n",
    "\n",
    "#_____\n",
    "\n",
    "def suaviPlusDerivates(candlesDataBase_BigQuery):\n",
    "    \n",
    "    global config\n",
    "\n",
    "    #_____UPDATE CONFIG PREDICTION\n",
    "    updateConfig(\"/home/ubuntu/SurfNet/predictionModels/PREDICTION/predictionModels.ini\")\n",
    "\n",
    "    short_ma_hyper=int(get_config(\"PARAMETERS\",\"SHORT_MA_HYPER\"))\n",
    "    short_ma_normal=int(get_config(\"PARAMETERS\",\"SHORT_MA_NORMAL\"))\n",
    "    long_ma_normal=int(get_config(\"PARAMETERS\",\"LONG_MA_NORMAL\"))\n",
    "    long_ma_hyper=int(get_config(\"PARAMETERS\",\"LONG_MA_HYPER\"))\n",
    "    ultra_long_ma_normal=int(get_config(\"PARAMETERS\",\"ULTRA_LONG_MA_NORMAL\"))\n",
    "\n",
    "    #_____VECTOR DE PRECIOS\n",
    "    close_data_df=candlesDataBase_BigQuery.copy()\n",
    "    close_data_df.CLOSE=close_data_df.CLOSE.astype(float)\n",
    "    close_data_df=close_data_df[[\"CLOSE\"]]\n",
    "\n",
    "    #_____SUAVIZACIONES MA & EMA\n",
    "    close_rolling_short_ma_hyper=close_data_df.rolling(short_ma_hyper).mean()\n",
    "    close_rolling_short_ma_normal=close_data_df.rolling(short_ma_normal).mean()\n",
    "    close_rolling_long_ma_normal=close_data_df.ewm(span=long_ma_normal).mean()\n",
    "    close_rolling_long_ma_hyper=close_data_df.ewm(span=long_ma_hyper).mean()\n",
    "    close_rolling_ultra_long_ma_normal=close_data_df.ewm(span=ultra_long_ma_normal).mean()\n",
    "\n",
    "    #_____INSERTAR NUEVAS VARIABLES\n",
    "    candlesDataBase_BigQuery[\"ROLLING_SHORT_MA_HYPER\"]=close_rolling_short_ma_hyper\n",
    "    candlesDataBase_BigQuery[\"ROLLING_SHORT_MA_NORMAL\"]=close_rolling_short_ma_normal\n",
    "    candlesDataBase_BigQuery[\"ROLLING_LONG_MA_NORMAL\"]=close_rolling_long_ma_normal\n",
    "    candlesDataBase_BigQuery[\"ROLLING_LONG_MA_HYPER\"]=close_rolling_long_ma_hyper\n",
    "    candlesDataBase_BigQuery[\"ROLLING_ULTRA_LONG_MA_NORMAL\"]=close_rolling_ultra_long_ma_normal\n",
    "\n",
    "    #_____BOLLINGER\n",
    "    candlesDataBase_BigQuery['15MA'] = candlesDataBase_BigQuery.groupby('MARKET')['CLOSE'].transform(lambda x: x.rolling(window=15).mean())\n",
    "    candlesDataBase_BigQuery['SD'] = candlesDataBase_BigQuery.groupby('MARKET')['CLOSE'].transform(lambda x: x.rolling(window=15).std())\n",
    "    candlesDataBase_BigQuery['UPPERBAND'] = candlesDataBase_BigQuery['15MA'] + 2*candlesDataBase_BigQuery['SD']\n",
    "    candlesDataBase_BigQuery['LOWERBAND'] = candlesDataBase_BigQuery['15MA'] - 2*candlesDataBase_BigQuery['SD']\n",
    "\n",
    "    #_____RATE CHANGE\n",
    "    candlesDataBase_BigQuery['RC'] = candlesDataBase_BigQuery.groupby('MARKET')['CLOSE'].transform(lambda x: x.pct_change(periods = 15))\n",
    "\n",
    "    #_____ELIMINAR DATOS FALTANTES\n",
    "    candlesDataBase_BigQuery.dropna(inplace=True)\n",
    "    candlesDataBase_BigQuery.reset_index(inplace=True,drop=True)\n",
    "\n",
    "    #####\n",
    "\n",
    "    #_____CÁLCULO DE LA PRIMERA DERIVADA\n",
    "    x_CLOSE= np.arange(len(candlesDataBase_BigQuery))\n",
    "    y_spl_CLOSE = UnivariateSpline(x_CLOSE,candlesDataBase_BigQuery[[\"CLOSE\"]],s=0,k=3)\n",
    "    Y_1D_CLOSE=y_spl_CLOSE.derivative(n=1)\n",
    "    Y_1D_CLOSE=pd.DataFrame(Y_1D_CLOSE(x_CLOSE))\n",
    "    candlesDataBase_BigQuery[\"Y_1D_CLOSE\"]=Y_1D_CLOSE\n",
    "\n",
    "    #_____CÁLCULO DE LA PRIMERA DERIVADA\n",
    "    x_ROLLING_SHORT_MA_HYPER= np.arange(len(candlesDataBase_BigQuery))\n",
    "    y_spl_ROLLING_SHORT_MA_HYPER = UnivariateSpline(x_ROLLING_SHORT_MA_HYPER,candlesDataBase_BigQuery[[\"ROLLING_SHORT_MA_HYPER\"]],s=0,k=3)\n",
    "    Y_1D_ROLLING_SHORT_MA_HYPER=y_spl_ROLLING_SHORT_MA_HYPER.derivative(n=1)\n",
    "    Y_1D_ROLLING_SHORT_MA_HYPER=pd.DataFrame(Y_1D_ROLLING_SHORT_MA_HYPER(x_ROLLING_SHORT_MA_HYPER))\n",
    "    candlesDataBase_BigQuery[\"Y_1D_ROLLING_SHORT_MA_HYPER\"]=Y_1D_ROLLING_SHORT_MA_HYPER\n",
    "\n",
    "    #_____CÁLCULO DE LA PRIMERA DERIVADA\n",
    "    x_ROLLING_SHORT_MA_NORMAL= np.arange(len(candlesDataBase_BigQuery))\n",
    "    y_spl_ROLLING_SHORT_MA_NORMAL = UnivariateSpline(x_ROLLING_SHORT_MA_NORMAL,candlesDataBase_BigQuery[[\"ROLLING_SHORT_MA_NORMAL\"]],s=0,k=3)\n",
    "    Y_1D_ROLLING_SHORT_MA_NORMAL=y_spl_ROLLING_SHORT_MA_NORMAL.derivative(n=1)\n",
    "    Y_1D_ROLLING_SHORT_MA_NORMAL=pd.DataFrame(Y_1D_ROLLING_SHORT_MA_NORMAL(x_ROLLING_SHORT_MA_NORMAL))\n",
    "    candlesDataBase_BigQuery[\"Y_1D_ROLLING_SHORT_MA_NORMAL\"]=Y_1D_ROLLING_SHORT_MA_NORMAL\n",
    "\n",
    "    #_____CÁLCULO DE LA PRIMERA DERIVADA\n",
    "    x_ROLLING_LONG_MA_NORMAL= np.arange(len(candlesDataBase_BigQuery))\n",
    "    y_spl_ROLLING_LONG_MA_NORMAL = UnivariateSpline(x_ROLLING_LONG_MA_NORMAL,candlesDataBase_BigQuery[[\"ROLLING_LONG_MA_NORMAL\"]],s=0,k=3)\n",
    "    Y_1D_ROLLING_LONG_MA_NORMAL=y_spl_ROLLING_LONG_MA_NORMAL.derivative(n=1)\n",
    "    Y_1D_ROLLING_LONG_MA_NORMAL=pd.DataFrame(Y_1D_ROLLING_LONG_MA_NORMAL(x_ROLLING_LONG_MA_NORMAL))\n",
    "    candlesDataBase_BigQuery[\"Y_1D_ROLLING_LONG_MA_NORMAL\"]=Y_1D_ROLLING_LONG_MA_NORMAL\n",
    "\n",
    "    #_____CÁLCULO DE LA PRIMERA DERIVADA\n",
    "    x_ROLLING_LONG_MA_HYPER= np.arange(len(candlesDataBase_BigQuery))\n",
    "    y_spl_ROLLING_LONG_MA_HYPER = UnivariateSpline(x_ROLLING_LONG_MA_HYPER,candlesDataBase_BigQuery[[\"ROLLING_LONG_MA_HYPER\"]],s=0,k=3)\n",
    "    Y_1D_ROLLING_LONG_MA_HYPER=y_spl_ROLLING_LONG_MA_HYPER.derivative(n=1)\n",
    "    Y_1D_ROLLING_LONG_MA_HYPER=pd.DataFrame(Y_1D_ROLLING_LONG_MA_HYPER(x_ROLLING_LONG_MA_HYPER))\n",
    "    candlesDataBase_BigQuery[\"Y_1D_ROLLING_LONG_MA_HYPER\"]=Y_1D_ROLLING_LONG_MA_HYPER\n",
    "\n",
    "    #_____CÁLCULO DE LA PRIMERA DERIVADA\n",
    "    x_ROLLING_ULTRA_LONG_MA_NORMAL= np.arange(len(candlesDataBase_BigQuery))\n",
    "    y_spl_ROLLING_ULTRA_LONG_MA_NORMAL = UnivariateSpline(x_ROLLING_ULTRA_LONG_MA_NORMAL,candlesDataBase_BigQuery[[\"ROLLING_ULTRA_LONG_MA_NORMAL\"]],s=0,k=3)\n",
    "    Y_1D_ROLLING_ULTRA_LONG_MA_NORMAL=y_spl_ROLLING_ULTRA_LONG_MA_NORMAL.derivative(n=1)\n",
    "    Y_1D_ROLLING_ULTRA_LONG_MA_NORMAL=pd.DataFrame(Y_1D_ROLLING_ULTRA_LONG_MA_NORMAL(x_ROLLING_ULTRA_LONG_MA_NORMAL))\n",
    "    candlesDataBase_BigQuery[\"Y_1D_ROLLING_ULTRA_LONG_MA_NORMAL\"]=Y_1D_ROLLING_ULTRA_LONG_MA_NORMAL\n",
    "\n",
    "    #####\n",
    "\n",
    "    #_____CALCULAR VARIABLE RSI\n",
    "    RSI_ROLLING_SHORT_MA_HYPER = RSI_GENERAL(pd.Series(list(candlesDataBase_BigQuery.ROLLING_SHORT_MA_HYPER.values)), int(get_config(\"PARAMETERS\",\"RSI_LEN\")))\n",
    "    RSI_ROLLING_SHORT_MA_NORMAL = RSI_GENERAL(pd.Series(list(candlesDataBase_BigQuery.ROLLING_SHORT_MA_NORMAL.values)), int(get_config(\"PARAMETERS\",\"RSI_LEN\")))\n",
    "    RSI_ROLLING_LONG_MA_NORMAL = RSI_GENERAL(pd.Series(list(candlesDataBase_BigQuery.ROLLING_LONG_MA_NORMAL.values)), int(get_config(\"PARAMETERS\",\"RSI_LEN\")))\n",
    "    RSI_ROLLING_LONG_MA_HYPER = RSI_GENERAL(pd.Series(list(candlesDataBase_BigQuery.ROLLING_LONG_MA_HYPER.values)), int(get_config(\"PARAMETERS\",\"RSI_LEN\")))\n",
    "    RSI_ROLLING_ULTRA_LONG_MA_NORMAL = RSI_GENERAL(pd.Series(list(candlesDataBase_BigQuery.ROLLING_ULTRA_LONG_MA_NORMAL.values)), int(get_config(\"PARAMETERS\",\"RSI_LEN\")))\n",
    "\n",
    "    #_____AGRAGAR VARIABLE RSI A BASE DE DATOS\n",
    "    candlesDataBase_BigQuery[\"RSI_ROLLING_SHORT_MA_HYPER\"]=RSI_ROLLING_SHORT_MA_HYPER\n",
    "    candlesDataBase_BigQuery[\"RSI_ROLLING_SHORT_MA_NORMAL\"]=RSI_ROLLING_SHORT_MA_NORMAL\n",
    "    candlesDataBase_BigQuery[\"RSI_ROLLING_LONG_MA_NORMAL\"]=RSI_ROLLING_LONG_MA_NORMAL\n",
    "    candlesDataBase_BigQuery[\"RSI_ROLLING_LONG_MA_HYPER\"]=RSI_ROLLING_LONG_MA_HYPER\n",
    "    candlesDataBase_BigQuery[\"RSI_ROLLING_ULTRA_LONG_MA_NORMAL\"]=RSI_ROLLING_ULTRA_LONG_MA_NORMAL\n",
    "\n",
    "    #_____REESTRUCTURAR BASE DE DATOS\n",
    "    candlesDataBase_BigQuery=candlesDataBase_BigQuery[int(get_config(\"PARAMETERS\",\"ULTRA_LONG_MA_NORMAL\"))+1:]\n",
    "    candlesDataBase_BigQuery.reset_index(inplace=True,drop=True)\n",
    "    \n",
    "    return candlesDataBase_BigQuery\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE CALCULA MACD\n",
    "def LAGS(candlesDataBase_BigQuery):\n",
    "    \n",
    "    for j in list(candlesDataBase_BigQuery.columns)[3:]:\n",
    "        candlesDataBase_BigQuery[j+\"_1\"]=candlesDataBase_BigQuery[j].shift(1)\n",
    "        candlesDataBase_BigQuery[j+\"_2\"]=candlesDataBase_BigQuery[j].shift(2)\n",
    "        candlesDataBase_BigQuery[j+\"_3\"]=candlesDataBase_BigQuery[j].shift(3)\n",
    "        \n",
    "    candlesDataBase_BigQuery.dropna(inplace=True)\n",
    "    candlesDataBase_BigQuery.reset_index(inplace=True,drop=True)\n",
    "        \n",
    "    return candlesDataBase_BigQuery\n",
    "\n",
    "#_____\n",
    "\n",
    "#CREATE VARIABLES\n",
    "def variableCreation(candlesDataBase_BigQuery):\n",
    "    \n",
    "    global fractal\n",
    "    updateConfig(\"/home/ubuntu/SurfNet/predictionModels/PREDICTION/predictionModels.ini\")\n",
    "    \n",
    "    candlesDataBase_BigQuery=RSI(candlesDataBase_BigQuery)\n",
    "    candlesDataBase_BigQuery=MACD(candlesDataBase_BigQuery)\n",
    "#     candlesDataBase_BigQuery=fibonacciLevels(candlesDataBase_BigQuery)\n",
    "#     candlesDataBase_BigQuery=newVariables(candlesDataBase_BigQuery)\n",
    "    candlesDataBase_BigQuery=superTrend(candlesDataBase_BigQuery, int(get_config(\"PARAMETERS\",\"ATR_PERIOD\")), int(get_config(\"PARAMETERS\",\"ATR_MULTIP\")))\n",
    "#     candlesDataBase_BigQuery=suaviPlusDerivates(candlesDataBase_BigQuery)\n",
    "#     candlesDataBase_BigQuery=LAGS(candlesDataBase_BigQuery)\n",
    "    \n",
    "    candlesDataBase_BigQuery.dropna(inplace=True)\n",
    "    candlesDataBase_BigQuery.reset_index(inplace=True,drop=True)\n",
    "    \n",
    "    return candlesDataBase_BigQuery\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE SIMULA COMPRA/VENTA MARKET EN BINANCE SEGÚN MERCADO -> SI SIDE==BUY, TRADINGAMOUNT==USDT // SI SIDE==SELL, TRADINGAMOUNT==CRYPTO\n",
    "def simulateMarket(exchange,market,tradingAmount,side,comission):\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        try:\n",
    "    \n",
    "            #EN CASO DE QUE SEA COMPRA\n",
    "            if side==\"buy\":\n",
    "\n",
    "                #VALIDAR QUE ORDERBOOK ALCANCE PARA HACER LA SIMULACIÓN\n",
    "                while_break=0\n",
    "                while while_break<tradingAmount*1.5:\n",
    "                    #DESCARGAR BUYINGBOOK\n",
    "                    buyingBook=pd.DataFrame(exchange.fetch_order_book(market)[\"asks\"],columns=[\"ASK_VALUE\",\"ASK_SIZE\"])\n",
    "                    buyingBook[\"ASK_PRICE\"]=buyingBook[\"ASK_VALUE\"]*buyingBook[\"ASK_SIZE\"]\n",
    "\n",
    "                    #ACTUALIZAR SUMA DE VOLUMENES DE ORDENES EN ORDERBOOK DESCARGADO\n",
    "                    while_break=sum(buyingBook.ASK_PRICE.values)\n",
    "\n",
    "                    #SI VOLUMEN TOTAL ES MAYOR A LO BUSCADO, SEGUIR CON SIMULACIÓN -> DLC, PRINT + ESPERAR\n",
    "                    if while_break<tradingAmount*1.5:\n",
    "                        print(\"[ERROR]: buyingBook(binance,\"+market+\",\"+str(tradingAmount)+\")\")\n",
    "                        time.sleep(1)\n",
    "\n",
    "                #_____\n",
    "\n",
    "                #SIMULACIÓN DE COMPRA CON USDT -> RETORNA VALOR DE CRYPTO ADQUIRIDO NETO\n",
    "                usdt_used=0\n",
    "                crypto_buyed=0\n",
    "                usdt_used_acum=0\n",
    "                crypto_buyed_acum=0\n",
    "                contador_buying_book=0\n",
    "\n",
    "                while usdt_used_acum<tradingAmount:\n",
    "\n",
    "                    usdt_used=buyingBook.at[contador_buying_book,\"ASK_PRICE\"]\n",
    "                    crypto_buyed=buyingBook.at[contador_buying_book,\"ASK_SIZE\"]\n",
    "                        \n",
    "                    #_____SIMULACIÓN\n",
    "                    if usdt_used_acum+usdt_used < tradingAmount:\n",
    "                        usdt_used_acum=usdt_used_acum+usdt_used\n",
    "                        crypto_buyed_acum=crypto_buyed_acum+crypto_buyed\n",
    "                    else:\n",
    "                        diferencia=tradingAmount-usdt_used_acum\n",
    "                        usdt_used_acum=usdt_used_acum+diferencia\n",
    "\n",
    "                        porcentaje_diferencia=diferencia/usdt_used\n",
    "                        crypto_buyed_acum=crypto_buyed_acum+crypto_buyed*porcentaje_diferencia\n",
    "                        \n",
    "                \n",
    "                #_____REVISAR DECIMALES\n",
    "                decimales=0\n",
    "                for i in range(0,10):\n",
    "                    crypto_buyed=buyingBook.at[i,\"ASK_SIZE\"]\n",
    "                    if marketFloats(crypto_buyed)>decimales:\n",
    "                        decimales=marketFloats(crypto_buyed)\n",
    "\n",
    "                #crypto_buyed_acum=round_decimals_down(crypto_buyed_acum*(1-comission),decimales)\n",
    "                crypto_buyed_acum=round_decimals_down(crypto_buyed_acum,decimales)\n",
    "                \n",
    "                response = crypto_buyed_acum\n",
    "\n",
    "            #_____\n",
    "\n",
    "            #EN CASO DE QUE SEA VENTA\n",
    "            if side==\"sell\":\n",
    "\n",
    "                #VALIDAR QUE ORDERBOOK ALCANCE PARA HACER LA SIMULACIÓN\n",
    "                while_break=0\n",
    "                while while_break<tradingAmount*1.5:\n",
    "                    #DESCARGAR SELLINGBOOK\n",
    "                    sellingBook=pd.DataFrame(exchange.fetch_order_book(market)[\"bids\"],columns=[\"BID_VALUE\",\"BID_SIZE\"])\n",
    "\n",
    "                    #ACTUALIZAR SUMA DE VOLUMENES DE ORDENES EN ORDERBOOK DESCARGADO\n",
    "                    while_break=sum(sellingBook.BID_SIZE.values)\n",
    "\n",
    "                    #SI VOLUMEN TOTAL ES MAYOR A LO BUSCADO, SEGUIR CON SIMULACIÓN -> DLC, PRINT + ESPERAR\n",
    "                    if while_break<tradingAmount*1.5:\n",
    "                        print(\"[ERROR]: buyingBook(\"+exchange.name+\",\"+market+\",\"+str(tradingAmount)+\")\")\n",
    "                        time.sleep(1)\n",
    "\n",
    "                #_____\n",
    "\n",
    "                #INICIALIZAR PARÁMETROS PARA LA SIMULACIÓN\n",
    "                sellAmount=0.0\n",
    "                sellCounter=0\n",
    "                sellPriceACUM=0.0\n",
    "                sellAmountACUM=0.0\n",
    "\n",
    "                #SIMULAR VENTA\n",
    "                while sellAmountACUM<tradingAmount:\n",
    "                    sellAmount=float(sellingBook.at[sellCounter,\"BID_SIZE\"])\n",
    "                    sellAmountACUM=sellAmountACUM+sellAmount\n",
    "                    if sellAmountACUM<tradingAmount:\n",
    "                        sellPriceACUM=sellPriceACUM+(sellAmount*float(sellingBook.iloc[sellCounter,0]))\n",
    "                        sellCounter=sellCounter+1\n",
    "                    else:\n",
    "                        printCRY=sellAmountACUM-sellAmount+tradingAmount-(sellAmountACUM-sellAmount)\n",
    "                        sellPriceACUM=sellPriceACUM+((tradingAmount-(sellAmountACUM-sellAmount))*float(sellingBook.iloc[sellCounter,0]))\n",
    "\n",
    "                response = sellPriceACUM*(1-comission)\n",
    "            \n",
    "            break\n",
    "            \n",
    "        except Exception as e: \n",
    "            print(f\"[ERROR]: simulateMarket() {e}\")\n",
    "            time.sleep(1)\n",
    "            \n",
    "    return response\n",
    "            \n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE CREA UNA COMPRA TIPO MARKET\n",
    "def createMarketBuy(market,money):\n",
    "    \n",
    "    global amount\n",
    "    global binance\n",
    "    global comission\n",
    "    global marketBuyOrder\n",
    "    \n",
    "    amount=simulateMarket(binance,market,money,\"buy\",comission)\n",
    "    marketBuyOrder=binance.create_market_buy_order(symbol=market,amount=amount)\n",
    "            \n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE CREA ORDEN DE COMPRA MARKET Y ACTUALIZA BASE DE DATOS DE TRADEO\n",
    "def buyMyFriend(market,money):\n",
    "    \n",
    "    global decimales\n",
    "    global comission\n",
    "    global row_index\n",
    "    global cryptoAmount\n",
    "    global marketBuyCost\n",
    "    global marketBuyOrder\n",
    "    global marketSellPrice\n",
    "    global marketBuyOrder_ID\n",
    "    global tradingBook_MonoBot\n",
    "    \n",
    "    #_____LEER BASE DE DATOS\n",
    "    tradingBook_MonoBot=readPickleVariable(\"tradingBook_MonoBot\")\n",
    "\n",
    "    #_____DETERMINAR FILA DE INTEGRACIÓN DE DATOS\n",
    "    row_index=len(tradingBook_MonoBot)\n",
    "\n",
    "    #_____CREAR COMPRA MARKET\n",
    "    createMarketBuy(market,money)\n",
    "\n",
    "    #_____AGREGAR DATOS A BASE DE DATOS DE TRADEO\n",
    "    tradingBook_MonoBot.at[row_index,\"MACHINE\"]=\"manual\"\n",
    "    tradingBook_MonoBot.at[row_index,\"TRANSACTION_ID\"]=marketBuyOrder[\"info\"][\"transactTime\"]\n",
    "    tradingBook_MonoBot.at[row_index,\"MARKET\"]=market\n",
    "    tradingBook_MonoBot.at[row_index,\"BUY_ID\"]=marketBuyOrder[\"id\"]\n",
    "    tradingBook_MonoBot.at[row_index,\"DATE_BUY\"]=str(datetime.fromtimestamp(int(marketBuyOrder[\"info\"][\"transactTime\"])/1000))\n",
    "    tradingBook_MonoBot.at[row_index,\"BUY_CRYPTO_AMOUNT\"]=float(marketBuyOrder[\"info\"][\"executedQty\"])\n",
    "    \n",
    "    try:\n",
    "        tradingBook_MonoBot.at[row_index,\"BUY_FEE\"]=float(marketBuyOrder[\"fee\"][\"cost\"])\n",
    "        tradingBook_MonoBot.at[row_index,\"BUY_CURRENCY_FEE\"]=marketBuyOrder[\"fee\"][\"currency\"]\n",
    "    except:\n",
    "        tradingBook_MonoBot.at[row_index,\"BUY_FEE\"]=comission*tradingBook_MonoBot.at[row_index,\"BUY_CRYPTO_AMOUNT\"]\n",
    "        tradingBook_MonoBot.at[row_index,\"BUY_CURRENCY_FEE\"]=market\n",
    "    \n",
    "    \n",
    "    #_____GUARDAR ID PARA FUTURO CRUCE CON VENTA\n",
    "    marketBuyOrder_ID=marketBuyOrder[\"id\"]\n",
    "    \n",
    "    #_____ACTUALIZAR PRECIOS DE VENTA\n",
    "    tradingBook_MonoBot.at[row_index,\"BUY_FEE_PERCET\"]=comission\n",
    "    tradingBook_MonoBot.at[row_index,\"NET_BUY_COST\"]=float(marketBuyOrder[\"cost\"])*(1+comission)\n",
    "    cryptoAmount=tradingBook_MonoBot.at[row_index,\"BUY_CRYPTO_AMOUNT\"]\n",
    "    cryptoAmount=round_decimals_down(cryptoAmount,decimales)\n",
    "    marketBuyCost=tradingBook_MonoBot.at[row_index,\"NET_BUY_COST\"]\n",
    "    \n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE RETORNA BALANCE USDC EN BINANCE\n",
    "def getCryptoBinance(market):\n",
    "    global binance\n",
    "    \n",
    "    my_market=market.replace(\"/USDT\",\"\")\n",
    "    while True:\n",
    "        try:\n",
    "            return float(binance.fetch_balance()[my_market][\"total\"])\n",
    "            break\n",
    "        except:\n",
    "            print(\"ERROR: getCryptoBinance()\")\n",
    "            time.sleep(1)\n",
    "            \n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE CREA ORDEN MARKET DE VENTA\n",
    "def createMarketSell(market):\n",
    "    \n",
    "    global check\n",
    "    global amount\n",
    "    global binance\n",
    "    global decimales\n",
    "    global cryptoAmount\n",
    "    global marketSellOrder\n",
    "    \n",
    "    check=getCryptoBinance(market)\n",
    "    amount=round_decimals_down(getCryptoBinance(market),decimales)\n",
    "    #marketSellOrder=binance.create_market_sell_order(symbol=market,amount=amount)\n",
    "    #marketSellOrder=binance.create_market_sell_order(symbol=market,amount=cryptoAmount)\n",
    "    try:\n",
    "        marketSellOrder=binance.create_market_sell_order(symbol=market,amount=amount)\n",
    "    except:\n",
    "        if (getCryptoBinance(market)==0) and (type(marketSellOrder)==dict):\n",
    "            pass\n",
    "        else:\n",
    "            ERROR_createMarketSell\n",
    "    \n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE CREA ORDEN DE VENTA MARKET Y ACTUALIZA BASE DE DATOS DE TRADEO\n",
    "def sellMyFriend(market):\n",
    "    \n",
    "    global comission\n",
    "    global marketSellOrder\n",
    "    global marketBuyOrder_ID\n",
    "    global tradingBook_MonoBot\n",
    "\n",
    "    #_____DETERMINAR FILA DE INTEGRACIÓN DE DATOS\n",
    "    row_index=tradingBook_MonoBot.loc[tradingBook_MonoBot.BUY_ID==marketBuyOrder_ID].index.values[0]\n",
    "\n",
    "    #_____CREAR VENTA MARKET\n",
    "    createMarketSell(market)\n",
    "\n",
    "    #_____AGREGAR DATOS A BASE DE DATOS DE TRADEO\n",
    "    tradingBook_MonoBot.at[row_index,\"SELL_ID\"]=marketSellOrder[\"id\"]\n",
    "    tradingBook_MonoBot.at[row_index,\"DATE_SELL\"]=str(datetime.fromtimestamp(int(marketSellOrder[\"info\"][\"transactTime\"])/1000))\n",
    "    tradingBook_MonoBot.at[row_index,\"SELL_FEE\"]=float(marketSellOrder[\"fee\"][\"cost\"])\n",
    "    tradingBook_MonoBot.at[row_index,\"SELL_CURRENCY_FEE\"]=marketSellOrder[\"fee\"][\"currency\"]\n",
    "    tradingBook_MonoBot.at[row_index,\"SELL_CRYPTO_AMOUNT\"]=float(marketSellOrder[\"info\"][\"executedQty\"])\n",
    "    \n",
    "    #_____ACTUALIZAR CONFIG\n",
    "    updateConfig('config_surfNet_MonoBot.ini')\n",
    "    \n",
    "    #_____CALCULAR COMISIÓN\n",
    "    tradingBook_MonoBot.at[row_index,\"NET_SELL_COST\"]=float(marketSellOrder[\"cost\"])*(1-comission)\n",
    "    tradingBook_MonoBot.at[row_index,\"NET_UTILITY\"]=tradingBook_MonoBot.at[row_index,\"NET_SELL_COST\"]/tradingBook_MonoBot.at[row_index,\"NET_BUY_COST\"]-1\n",
    "    \n",
    "    #_____ESCRIBIR PICKLE\n",
    "    writePickleVariable(tradingBook_MonoBot,\"tradingBook_MonoBot\")\n",
    "    \n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE RETORNA BALANCE USDC EN BINANCE\n",
    "def getUsdtBinance():\n",
    "    global binance\n",
    "    while True:\n",
    "        try:\n",
    "            return float(binance.fetch_balance()[\"USDT\"][\"total\"])\n",
    "            break\n",
    "        except:\n",
    "            print(\"ERROR: getUsdtBinance()\")\n",
    "            time.sleep(1)\n",
    "            \n",
    "#_____\n",
    "\n",
    "#FUNCIÓN QUE ESTIMA LA CANTIDAD DE DECIMALES A REDONDEAR\n",
    "def marketFloats(value): \n",
    "    Completo = str(value)\n",
    "    Entero= str(math.floor(value))\n",
    "    lenCompleto = len(Completo)\n",
    "    lenEntero = len(Entero)\n",
    "    if lenEntero != lenCompleto:\n",
    "        decimalVector=Completo.split(\".\")\n",
    "        for i in decimalVector[1]:\n",
    "            if i != \"0\":\n",
    "                tengoDecimales=True\n",
    "            else:\n",
    "                tengoDecimales=False\n",
    "        if tengoDecimales:\n",
    "            decimales=lenCompleto-lenEntero-1\n",
    "        else:\n",
    "            decimales=0\n",
    "    else:\n",
    "        decimales = 0\n",
    "    \n",
    "    return decimales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c42bda8",
   "metadata": {},
   "source": [
    "# PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433602b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#_____ACTUALIZAR ARCHIVO CONFIG\n",
    "updateConfig('config_surfNet_MonoBot.ini')\n",
    "\n",
    "#_____BINANCE\n",
    "binance = ccxt.binance()\n",
    "binance.apiKey = \"AClVXKNa29UOHZLQJOclsqxmIwB3ytGiLdqJv9tRqDAnBa1igFrR8lZdii77rto1\"\n",
    "binance.secret = \"VxNazwB9y57Kz4ydF4IFckypW3WYM90qjWzb925itZPU909VKjGrR4MBKvMevYZz\"\n",
    "binance.options['createMarketBuyOrderRequiresPrice'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f431aa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#_____BASE DE DATOS LIMPIA\n",
    "# tradingBook_MonoBot=pd.DataFrame(columns=[\"MACHINE\",\"TRANSACTION_ID\",\"MARKET\",\"BUY_ID\",\"DATE_BUY\",\"SELL_ID\",\"DATE_SELL\",\"BUY_CRYPTO_AMOUNT\",\"NET_BUY_COST\",\"BUY_FEE\",\"BUY_FEE_PERCET\",\"BUY_CURRENCY_FEE\",\"SELL_CRYPTO_AMOUNT\",\"NET_SELL_COST\",\"SELL_FEE\",\"SELL_CURRENCY_FEE\",\"NET_UTILITY\"])\n",
    "# writePickleVariable(tradingBook_MonoBot,\"tradingBook_MonoBot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51facb9",
   "metadata": {},
   "source": [
    "# PORTFOLIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca6b2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#_____PORTFOLIO\n",
    "portfolio=readPickleVariable(\"/home/ubuntu/SurfNet/surfNetRun/portfolio\")\n",
    "portfolio.reset_index(inplace=True,drop=True)\n",
    "\n",
    "#_____RELEVANT VARIABLES\n",
    "contador=0\n",
    "for market_model in list(portfolio.MARKET.values):\n",
    "\n",
    "    #_____CARGAR BASE DE DATOS\n",
    "    myData = binance.fetch_ohlcv(market_model,\"15\"+\"m\",limit=1000)\n",
    "    candlesDataBase_BigQuery =pd.DataFrame(columns=[\"ID\",\"TIME\",\"MARKET\",\"OPEN\",\"HIGH\",\"LOW\",\"CLOSE\",\"VOLUME\"])\n",
    "\n",
    "    for i in range(0,len(myData)):\n",
    "        candlesDataBase_BigQuery.at[i,\"ID\"]=myData[i][0]\n",
    "        candlesDataBase_BigQuery.at[i,\"TIME\"]=datetime.fromtimestamp(myData[i][0]/1000.0)\n",
    "        candlesDataBase_BigQuery.at[i,\"MARKET\"]=market_model\n",
    "        candlesDataBase_BigQuery.at[i,\"OPEN\"]=myData[i][1]\n",
    "        candlesDataBase_BigQuery.at[i,\"HIGH\"]=myData[i][2]\n",
    "        candlesDataBase_BigQuery.at[i,\"LOW\"]=myData[i][3]\n",
    "        candlesDataBase_BigQuery.at[i,\"CLOSE\"]=myData[i][4]\n",
    "        candlesDataBase_BigQuery.at[i,\"VOLUME\"]=myData[i][5]\n",
    "\n",
    "    #_____GUARDAR BASE DE DATOS PARA BACKTESTING FUTURO\n",
    "    backtestingDataFrame=candlesDataBase_BigQuery.copy()\n",
    "\n",
    "    #_____CREAR VARIABLES INPUT\n",
    "    candlesDataBase_BigQuery=variableCreation(candlesDataBase_BigQuery)\n",
    "\n",
    "    #####\n",
    "    \n",
    "    portfolio.at[contador,\"RSI\"]=candlesDataBase_BigQuery.at[len(candlesDataBase_BigQuery)-1,\"RSI\"]\n",
    "    portfolio.at[contador,\"MACD\"]=candlesDataBase_BigQuery.at[len(candlesDataBase_BigQuery)-1,\"MACD\"]\n",
    "    portfolio.at[contador,\"MACD_TRIGGER\"]=candlesDataBase_BigQuery.at[len(candlesDataBase_BigQuery)-1,\"MACD_TRIGGER\"]\n",
    "    portfolio.at[contador,\"SUPERTREND\"]=candlesDataBase_BigQuery.at[len(candlesDataBase_BigQuery)-1,\"SUPERTREND\"]\n",
    "    \n",
    "    #####\n",
    "    \n",
    "    checks=0\n",
    "    if portfolio.at[contador,\"RSI\"]<50:\n",
    "        checks+=1\n",
    "    if (portfolio.at[contador,\"MACD\"]<0) and (portfolio.at[contador,\"MACD_TRIGGER\"]<0) and (portfolio.at[contador,\"MACD\"]/portfolio.at[contador,\"MACD_TRIGGER\"]>=0.9) and (portfolio.at[contador,\"MACD\"]/portfolio.at[contador,\"MACD_TRIGGER\"]<=1.1):\n",
    "        checks+=1\n",
    "    if portfolio.at[contador,\"SUPERTREND\"]==True:\n",
    "        checks+=1\n",
    "    \n",
    "    portfolio.at[contador,\"BUY_FACTOR\"]=int(checks)\n",
    "    \n",
    "    #####\n",
    "    \n",
    "    contador+=1\n",
    "    \n",
    "portfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976da6bd",
   "metadata": {},
   "source": [
    "# BUY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111a2820",
   "metadata": {},
   "source": [
    "PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103bf806",
   "metadata": {},
   "outputs": [],
   "source": [
    "comission=0.001\n",
    "market=\"ETH/USDT\"\n",
    "money=49000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5682790",
   "metadata": {},
   "source": [
    "COGITO ERGO SUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e25f00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#_____COMPRAR\n",
    "buyMyFriend(market,money)\n",
    "ejecuto_venta=0\n",
    "\n",
    "#_____NO PARAR HASTA VENDER\n",
    "while ejecuto_venta==0:\n",
    "    \n",
    "    updateConfig(\"monoManual.ini\")\n",
    "\n",
    "    #_____SLEEP\n",
    "    time.sleep(5)\n",
    "    \n",
    "    #_____ACTUALIZAR PRECIO SIMULADO DE VENTA                                                        \n",
    "    precio_venta_simulado=simulateMarket(binance,market,cryptoAmount,\"sell\",comission)\n",
    "    margenUtilidad=(precio_venta_simulado/marketBuyCost)-1\n",
    "    \n",
    "    #_____PRINT\n",
    "    clear_output()\n",
    "    print(market,margenUtilidad)\n",
    "\n",
    "    #_____SI MARGEN DE UTILIDAD CALCULADO LLEGA A ALGUNO DE LOS LÍMITES\n",
    "    if (margenUtilidad >= float(get_config(\"PARAMETERS\",\"TP\"))) or (margenUtilidad <= float(get_config(\"PARAMETERS\",\"SL\"))):\n",
    "\n",
    "        #_____EJECUTAR ORDEN DE VENTA\n",
    "        sellMyFriend(market)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2bed7b",
   "metadata": {},
   "source": [
    "BALANCEAR BNB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed89fbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #_____DECIMALES BNB\n",
    "# buyingBook=pd.DataFrame(binance.fetch_order_book(\"BNB/USDT\")[\"asks\"],columns=[\"ASK_VALUE\",\"ASK_SIZE\"])\n",
    "# decimales=0\n",
    "# for i in range(0,10):\n",
    "#     crypto_buyed=buyingBook.at[i,\"ASK_SIZE\"]\n",
    "#     if marketFloats(crypto_buyed)>decimales:\n",
    "#         decimales=marketFloats(crypto_buyed)\n",
    "# #_____VALIDAR MONTO\n",
    "# # amount_BNB=round_decimals_down(simulateMarket(binance,\"BNB/USDT\",getUsdtBinance()*0.002,\"buy\",comission),decimales)\n",
    "# amount_BNB=round_decimals_down(simulateMarket(binance,\"BNB/USDT\",getUsdtBinance()*0.0015,\"buy\",comission),decimales)\n",
    "# marketBuyOrder_BNB=binance.create_market_buy_order(symbol=\"BNB/USDT\",amount=amount_BNB)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
